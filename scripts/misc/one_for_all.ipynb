{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QUayU6ve0s_"
      },
      "source": [
        "This notebook loads datasets of semantic proximity (Word-in-Context) for various languages the [WUG format](https://www.ims.uni-stuttgart.de/en/research/resources/experiment-data/wugs/). We provide the data in a minimal and an extended format. There are in total 4 dataframes: judgments_full, judgments_wug, uses_full and uses_wug. There are 20 transformed datasets. The notebook should run of-the-shelf in a colab environment with python 3.8. \n",
        "\n",
        "Many of the data sets are transformed when running the notebook. We cannot guarantee that there are no errors. Hence, please make sure that you compare the created data frames to the original data sets before doing serious research with them.\n",
        "\n",
        "Note: Please run this script without gpu on colab.\n",
        "\n",
        "The datasets and their versions are as follows:\n",
        "\n",
        "#RuDSI - Russian\n",
        "rudsi = 'https://github.com/kategavrishina/RuDSI/tree/main/data' \n",
        "\n",
        "#NorDiaChange - Norwegian\n",
        "nordia1 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset1/data'\n",
        "nordia2 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset2/data'\n",
        "\n",
        "#RuShiftEval - Russian\n",
        "rushifteval1 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval1/data'\n",
        "rushifteval2 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval2/data'\n",
        "rushifteval3 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval3/data'\n",
        "\n",
        "#RuSemShift - Russian\n",
        "rusemshift1 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_1/DWUG/data'\n",
        "rusemshift2 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_2/DWUG/data'\n",
        "\n",
        "#DiscoWUG - German (Version: 1.1.1)\n",
        "https://zenodo.org/record/7396225/files/discowug.zip\n",
        "\n",
        "\n",
        "\n",
        "#SURel - German (Version: 3.0.0)\n",
        "https://zenodo.org/record/5784569/files/surel.zip\n",
        "\n",
        "\n",
        "#DURel - German (Version: 3.0.0)\n",
        "https://zenodo.org/record/5784453/files/durel.zip\n",
        "\n",
        "\n",
        "#DWUG DE- German (Version: 2.3.0)\n",
        "https://zenodo.org/record/7441645/files/dwug_de.zip\n",
        "\n",
        "\n",
        "#RefWUG - German (Version: 1.1.0)\n",
        "https://zenodo.org/record/5791269/files/refwug.zip\n",
        "\n",
        "\n",
        "#DWUG EN - English (Version: 2.0.1)\n",
        "https://zenodo.org/record/7387261/files/dwug_en.zip\n",
        "\n",
        "\n",
        "#DWUG SV - Swedish(Version: 2.0.1)\n",
        "https://zenodo.org/record/7389506/files/dwug_sv.zip\n",
        "\n",
        "\n",
        "#DWUG ES - Spanish(Version: 4.0.0)\n",
        "https://zenodo.org/record/6433667/files/dwug_es.zip\n",
        "\n",
        "\n",
        "#DiaWUG - Spanish (Version: 1.1.0)\n",
        "https://zenodo.org/record/5791193/files/diawug.zip\n",
        "\n",
        "\n",
        "#DUPS_WUG - English (version 2.0.0)\n",
        "https://zenodo.org/record/5500223/files/DUPS-WUG.zip\n",
        "\n",
        "#WIC - English (version v1.0)\n",
        "https://pilehvar.github.io/wic/package/WiC_dataset.zip\n",
        "\n",
        "#TempoWIC - English\n",
        "https://codalab.lisn.upsaclay.fr/my/datasets/download/3e22f138-ca00-4b10-a0fd-2e914892200d\n",
        "\n",
        "#Raw-C - English\n",
        "https://raw.githubusercontent.com/seantrott/raw-c/main/data/processed/raw-c.csv\n",
        "\n",
        "#Usim - English\n",
        "http://www.dianamccarthy.co.uk/downloads/WordMeaningAnno2012/\n",
        "\n",
        "#CosimLex - English, Croatian, Finnish\n",
        "https://www.clarin.si/repository/xmlui/handle/11356/1308/allzip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "DF_EmVh_2LPF"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import os\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4IFGsLzzC5c",
        "outputId": "92f0a427-acd5-4b6d-82e5-bac39052fac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'WUGs' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Garrafao/WUGs.git #contains transformation scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xuXe6WIxrFm",
        "outputId": "7f83517c-d010-48da-aa59-fef4d1aa3fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.9/dist-packages (0.18.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy #needed for rawc script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKUnfomtawHa",
        "outputId": "baae9883-e1f4-4998-81c3-dacef5f5073a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1musim2data.sh\u001b[m\n",
            "--2023-03-24 11:27:06--  http://www.dianamccarthy.co.uk/downloads/WordMeaningAnno2012/cl-meaningincontext.tgz\n",
            "Resolving www.dianamccarthy.co.uk (www.dianamccarthy.co.uk)... 212.159.8.91, 212.159.9.91\n",
            "Connecting to www.dianamccarthy.co.uk (www.dianamccarthy.co.uk)|212.159.8.91|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253228 (247K) [application/x-gzip]\n",
            "Saving to: ‘./source/cl-meaningincontext.tgz’\n",
            "\n",
            "cl-meaningincontext 100%[===================>] 247.29K   437KB/s    in 0.6s    \n",
            "\n",
            "2023-03-24 11:27:07 (437 KB/s) - ‘./source/cl-meaningincontext.tgz’ saved [253228/253228]\n",
            "\n",
            "README\n",
            "Data/\n",
            "Data/README\n",
            "Data/lexsub_wcdata.xml\n",
            "Data/lexsubwc.dtd\n",
            "Markup/\n",
            "Markup/WordSenseBest/\n",
            "Markup/WordSenseBest/wsbestmode.csv\n",
            "Markup/WordSenseBest/README_wsbest.txt\n",
            "Markup/WordSenseBest/wsbestratings.csv\n",
            "Markup/SynonymBest/\n",
            "Markup/SynonymBest/README_synbest.txt\n",
            "Markup/SynonymBest/synbestratings.csv\n",
            "Markup/WordSenseSimilarity/\n",
            "Markup/WordSenseSimilarity/README_wssim.txt\n",
            "Markup/WordSenseSimilarity/wssim2ratings.csv\n",
            "Markup/UsageSimilarity/\n",
            "Markup/UsageSimilarity/usim2ratings.csv\n",
            "Markup/UsageSimilarity/README_usim.txt\n",
            "./data/account\n",
            "target:  account\n",
            "target:  account\n",
            "target:  account\n",
            "target:  accounts\n",
            "target:  accounts\n",
            "target:  account\n",
            "target:  accounts\n",
            "target:  accounts\n",
            "target:  accounts\n",
            "target:  account\n",
            "./data/bright\n",
            "target:  bright\n",
            "target:  brighter\n",
            "target:  bright\n",
            "target:  bright\n",
            "target:  brightest\n",
            "target:  brightest\n",
            "target:  bright\n",
            "target:  bright\n",
            "target:  bright\n",
            "target:  bright\n",
            "./data/call\n",
            "target:  calling\n",
            "target:  called\n",
            "target:  called\n",
            "target:  calling\n",
            "target:  called\n",
            "target:  called\n",
            "target:  called\n",
            "target:  call\n",
            "target:  call\n",
            "target:  call\n",
            "./data/coach\n",
            "target:  coach\n",
            "target:  coach\n",
            "target:  coach\n",
            "target:  coach\n",
            "target:  coaches\n",
            "target:  coaches\n",
            "target:  coach\n",
            "target:  coaches\n",
            "target:  coach\n",
            "target:  coach\n",
            "./data/dismiss\n",
            "target:  dismiss\n",
            "target:  dismiss\n",
            "target:  dismissed\n",
            "target:  dismissed\n",
            "target:  dismissed\n",
            "target:  dismissed\n",
            "target:  dismisses\n",
            "target:  dismiss\n",
            "target:  dismiss\n",
            "target:  dismissed\n",
            "./data/fire\n",
            "target:  fired\n",
            "target:  fired\n",
            "target:  fired\n",
            "target:  fired\n",
            "target:  fire\n",
            "target:  fired\n",
            "target:  fired\n",
            "target:  fired\n",
            "target:  fired\n",
            "target:  fired\n",
            "./data/fix\n",
            "target:  fix\n",
            "target:  fix\n",
            "target:  fixing\n",
            "target:  fix\n",
            "target:  fixed\n",
            "target:  fix\n",
            "target:  fixed\n",
            "target:  fixed\n",
            "target:  fix\n",
            "target:  fixed\n",
            "./data/function\n",
            "target:  function\n",
            "target:  function\n",
            "target:  functions\n",
            "target:  Functions\n",
            "target:  function\n",
            "target:  function\n",
            "target:  function\n",
            "target:  function\n",
            "target:  function\n",
            "target:  function\n",
            "./data/hold\n",
            "target:  holding\n",
            "target:  hold\n",
            "target:  held\n",
            "target:  held\n",
            "target:  held\n",
            "target:  holding\n",
            "target:  held\n",
            "target:  holding\n",
            "target:  held\n",
            "target:  holding\n",
            "./data/investigator\n",
            "target:  investigators\n",
            "target:  investigators\n",
            "target:  investigators\n",
            "target:  investigators\n",
            "target:  investigator\n",
            "target:  investigators\n",
            "target:  investigators\n",
            "target:  investigators\n",
            "target:  investigators\n",
            "target:  investigator\n",
            "./data/lead\n",
            "target:  leads\n",
            "target:  lead\n",
            "target:  lead\n",
            "target:  lead\n",
            "target:  leads\n",
            "target:  lead\n",
            "target:  lead\n",
            "target:  leads\n",
            "target:  lead\n",
            "target:  lead\n",
            "./data/neat\n",
            "target:  neat\n",
            "target:  neatest\n",
            "target:  neater\n",
            "target:  neat\n",
            "target:  neat\n",
            "target:  neat\n",
            "target:  neat\n",
            "target:  up\n",
            "target:  neat\n",
            "target:  neat\n",
            "./data/new\n",
            "target:  new\n",
            "target:  new\n",
            "target:  new\n",
            "target:  new\n",
            "target:  new\n",
            "target:  new\n",
            "target:  new\n",
            "target:  new\n",
            "target:  new\n",
            "target:  new\n",
            "./data/order\n",
            "target:  ordered\n",
            "target:  ordered\n",
            "target:  ordered\n",
            "target:  order\n",
            "target:  ordered\n",
            "target:  order\n",
            "target:  ordering\n",
            "target:  ordered\n",
            "target:  order\n",
            "target:  ordered\n",
            "./data/range\n",
            "target:  range\n",
            "target:  range\n",
            "target:  range\n",
            "target:  range\n",
            "target:  range\n",
            "target:  range\n",
            "target:  range\n",
            "target:  range\n",
            "target:  range\n",
            "target:  range\n",
            "./data/rich\n",
            "target:  rich\n",
            "target:  rich\n",
            "target:  rich\n",
            "target:  rich\n",
            "target:  rich\n",
            "target:  rich\n",
            "target:  richer\n",
            "target:  rich\n",
            "target:  Rich\n",
            "target:  rich\n",
            "./data/ring\n",
            "target:  ring\n",
            "target:  ring\n",
            "target:  rings\n",
            "target:  ring\n",
            "target:  ring\n",
            "target:  ring\n",
            "target:  ring\n",
            "target:  ring\n",
            "target:  rings\n",
            "target:  ring\n",
            "./data/rough\n",
            "target:  rough\n",
            "target:  rough\n",
            "target:  rough\n",
            "target:  rough\n",
            "target:  rough\n",
            "target:  Rough\n",
            "target:  rough\n",
            "target:  rough\n",
            "target:  rough\n",
            "target:  rough\n",
            "./data/scrap\n",
            "target:  scrap\n",
            "target:  scrap\n",
            "target:  scrap\n",
            "target:  scraps\n",
            "target:  scraps\n",
            "target:  scrap\n",
            "target:  scrap\n",
            "target:  scrap\n",
            "target:  scraps\n",
            "target:  scrap\n",
            "./data/severely\n",
            "target:  severely\n",
            "target:  severely\n",
            "target:  severely\n",
            "target:  severely\n",
            "target:  severely\n",
            "target:  severely\n",
            "target:  severely\n",
            "target:  severely\n",
            "target:  severely\n",
            "target:  severely\n",
            "./data/shade\n",
            "target:  shade\n",
            "target:  shades\n",
            "target:  shade\n",
            "target:  shades\n",
            "target:  shade\n",
            "target:  shade\n",
            "target:  shades\n",
            "target:  shade\n",
            "target:  shades\n",
            "target:  shades\n",
            "./data/shed\n",
            "target:  shed\n",
            "target:  shed\n",
            "target:  sheds\n",
            "target:  sheds\n",
            "target:  shedding\n",
            "target:  shed\n",
            "target:  shed\n",
            "target:  shed\n",
            "target:  shed\n",
            "target:  shed\n",
            "./data/skip\n",
            "target:  skipped\n",
            "target:  skipping\n",
            "target:  skip\n",
            "target:  skipping\n",
            "target:  skipped\n",
            "target:  skip\n",
            "target:  skip\n",
            "target:  skip\n",
            "target:  skipped\n",
            "target:  skips\n",
            "./data/soft\n",
            "target:  soft\n",
            "target:  soft\n",
            "target:  soft\n",
            "target:  soft\n",
            "target:  soft\n",
            "target:  soft\n",
            "target:  soft\n",
            "target:  soft\n",
            "target:  soft\n",
            "target:  soft\n",
            "./data/stiff\n",
            "target:  stiff\n",
            "target:  stiff\n",
            "target:  stiff\n",
            "target:  stiff\n",
            "target:  stiff\n",
            "target:  stiff\n",
            "target:  stiff\n",
            "target:  Stiffer\n",
            "target:  stiff\n",
            "target:  stiff\n",
            "./data/suffer\n",
            "target:  suffering\n",
            "target:  suffered\n",
            "target:  now\n",
            "target:  suffered\n",
            "target:  suffer\n",
            "target:  suffered\n",
            "target:  suffer\n",
            "target:  suffers\n",
            "target:  suffered\n",
            "target:  suffer\n",
            "./data/account\n",
            "./data/bright\n",
            "./data/call\n",
            "./data/coach\n",
            "./data/dismiss\n",
            "./data/fire\n",
            "./data/fix\n",
            "./data/function\n",
            "./data/hold\n",
            "./data/investigator\n",
            "./data/lead\n",
            "./data/neat\n",
            "./data/new\n",
            "./data/order\n",
            "./data/range\n",
            "./data/rich\n",
            "./data/ring\n",
            "./data/rough\n",
            "./data/scrap\n",
            "./data/severely\n",
            "./data/shade\n",
            "./data/shed\n",
            "./data/skip\n",
            "./data/soft\n",
            "./data/stiff\n",
            "./data/suffer\n"
          ]
        }
      ],
      "source": [
        "!cd /content/WUGs/scripts/misc && bash -e usim2data.sh #transform USim to WUG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnroPHJ1HSQh",
        "outputId": "1d8aee0c-2d35-4fba-a8bf-1516993110a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mevonlp2wug.sh\u001b[m\n",
            "--2023-03-24 11:27:15--  https://codalab.lisn.upsaclay.fr/my/datasets/download/3e22f138-ca00-4b10-a0fd-2e914892200d\n",
            "Resolving codalab.lisn.upsaclay.fr (codalab.lisn.upsaclay.fr)... 129.175.8.8\n",
            "Connecting to codalab.lisn.upsaclay.fr (codalab.lisn.upsaclay.fr)|129.175.8.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://miniodis-rproxy.lisn.upsaclay.fr/py3-private/dataset_data_file/da46462c-0b8c-44c8-98a3-ef085c89e189/TempoWiC_Starting_Kit.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=EASNOMJFX9QFW4QIY4SL%2F20230324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230324T112717Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6364241fbf61dd553fe770237df8adc6b4ebbd80439ad462d37c171339251d9b [following]\n",
            "--2023-03-24 11:27:17--  https://miniodis-rproxy.lisn.upsaclay.fr/py3-private/dataset_data_file/da46462c-0b8c-44c8-98a3-ef085c89e189/TempoWiC_Starting_Kit.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=EASNOMJFX9QFW4QIY4SL%2F20230324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230324T112717Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6364241fbf61dd553fe770237df8adc6b4ebbd80439ad462d37c171339251d9b\n",
            "Resolving miniodis-rproxy.lisn.upsaclay.fr (miniodis-rproxy.lisn.upsaclay.fr)... 129.175.8.8\n",
            "Connecting to miniodis-rproxy.lisn.upsaclay.fr (miniodis-rproxy.lisn.upsaclay.fr)|129.175.8.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3430267 (3.3M) [application/zip]\n",
            "Saving to: ‘./source/3e22f138-ca00-4b10-a0fd-2e914892200d’\n",
            "\n",
            "3e22f138-ca00-4b10- 100%[===================>]   3.27M  2.93MB/s    in 1.1s    \n",
            "\n",
            "2023-03-24 11:27:19 (2.93 MB/s) - ‘./source/3e22f138-ca00-4b10-a0fd-2e914892200d’ saved [3430267/3430267]\n",
            "\n",
            "Archive:  ./source/starting-kit.zip\n",
            "   creating: ./source/TempoWiC_Starting_Kit/\n",
            "   creating: ./source/TempoWiC_Starting_Kit/data/\n",
            "  inflating: ./source/TempoWiC_Starting_Kit/data/test-codalab-10k.data.jl  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/data/trial.gold.tsv  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/data/train.labels.tsv  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/data/validation.data.jl  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/data/validation.labels.tsv  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/data/trial.data.jl  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/data/train.data.jl  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/pprint.py  \n",
            "   creating: ./source/TempoWiC_Starting_Kit/predictions/\n",
            "  inflating: ./source/TempoWiC_Starting_Kit/predictions/answer.tsv.zip  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/predictions/validation.random-preds.tsv  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/predictions/trial.random-preds.tsv  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/predictions/.DS_Store  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/score.py  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/README.md  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/random_baseline.py  \n",
            "  inflating: ./source/TempoWiC_Starting_Kit/.DS_Store  \n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-24 11:27:24.198130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:27:24.198370: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:27:24.198407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-24 11:27:28.273274: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-24 11:28:28.046056: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:28:28.046205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:28:28.046229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-24 11:28:29.836673: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-24 11:28:36.109558: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:28:36.109698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:28:36.109723: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-24 11:28:38.327742: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        }
      ],
      "source": [
        "!cd /content/WUGs/scripts/misc && bash -e evonlp2wug.sh  #transforms tempowic to wug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bliWQos0xHEB",
        "outputId": "8094e77d-add7-4261-ed5d-05dfaf385645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-24 11:28:57.057657: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:28:57.057803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:28:57.057827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-24 11:28:58.849519: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fi-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fi_core_news_sm-3.5.0/fi_core_news_sm-3.5.0-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from fi-core-news-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (67.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (1.10.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->fi-core-news-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fi_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy download fi_core_news_sm #needed for cosimlex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAYzKbZ18jyX",
        "outputId": "d8c8709b-3ff7-47ff-ca11-47eb52c4b6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-24 11:29:09.843060: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:29:09.843243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:29:09.843278: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-24 11:29:11.753400: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hr-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/hr_core_news_sm-3.5.0/hr_core_news_sm-3.5.0-py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from hr-core-news-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (1.10.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (67.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->hr-core-news-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('hr_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy download hr_core_news_sm #needed for cosimlex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14_KO1DSTTfW",
        "outputId": "39d0e6ff-f1af-4810-d614-6d8122455e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mcosimlex2wug.sh\u001b[m\n",
            "--2023-03-24 11:29:25--  https://www.clarin.si/repository/xmlui/handle/11356/1308/allzip\n",
            "Resolving www.clarin.si (www.clarin.si)... 95.87.154.205\n",
            "Connecting to www.clarin.si (www.clarin.si)|95.87.154.205|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘./source/allzip’\n",
            "\n",
            "allzip                  [     <=>            ] 487.64K   321KB/s    in 1.5s    \n",
            "\n",
            "2023-03-24 11:29:28 (321 KB/s) - ‘./source/allzip’ saved [499341]\n",
            "\n",
            "Archive:  ./source/allzip.zip\n",
            "  inflating: ./source/cosimlex_en.csv  \n",
            "  inflating: ./source/cosimlex_fi.csv  \n",
            "  inflating: ./source/cosimlex_hr.csv  \n",
            "  inflating: ./source/cosimlex_sl.csv  \n",
            "  inflating: ./source/README.md      \n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-24 11:29:31.313272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:29:31.313411: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:29:31.313434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-24 11:29:33.587464: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-24 11:30:19.811842: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:30:19.812052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:30:19.812082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-24 11:30:21.873392: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-24 11:30:29.861669: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:30:29.861851: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-24 11:30:29.861875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-24 11:30:32.666637: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        }
      ],
      "source": [
        "!cd /content/WUGs/scripts/misc && bash -e cosimlex2wug.sh #transforms cosimlex to wug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpsldp-xtTHX",
        "outputId": "16f52a04-3108-4dae-c781-a7777185e905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-24 11:30:46--  https://zenodo.org/record/7396225/files/discowug.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5486849 (5.2M) [application/octet-stream]\n",
            "Saving to: ‘discowug.zip.2’\n",
            "\n",
            "discowug.zip.2      100%[===================>]   5.23M   404KB/s    in 14s     \n",
            "\n",
            "2023-03-24 11:31:01 (386 KB/s) - ‘discowug.zip.2’ saved [5486849/5486849]\n",
            "\n",
            "--2023-03-24 11:31:02--  https://zenodo.org/record/5784569/files/surel.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2676637 (2.6M) [application/octet-stream]\n",
            "Saving to: ‘surel.zip.2’\n",
            "\n",
            "surel.zip.2         100%[===================>]   2.55M   381KB/s    in 6.8s    \n",
            "\n",
            "2023-03-24 11:31:10 (385 KB/s) - ‘surel.zip.2’ saved [2676637/2676637]\n",
            "\n",
            "--2023-03-24 11:31:11--  https://zenodo.org/record/5784453/files/durel.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7904030 (7.5M) [application/octet-stream]\n",
            "Saving to: ‘durel.zip.2’\n",
            "\n",
            "durel.zip.2         100%[===================>]   7.54M   388KB/s    in 20s     \n",
            "\n",
            "2023-03-24 11:31:33 (377 KB/s) - ‘durel.zip.2’ saved [7904030/7904030]\n",
            "\n",
            "--2023-03-24 11:31:33--  https://zenodo.org/record/7441645/files/dwug_de.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14620222 (14M) [application/octet-stream]\n",
            "Saving to: ‘dwug_de.zip.2’\n",
            "\n",
            "dwug_de.zip.2       100%[===================>]  13.94M   395KB/s    in 37s     \n",
            "\n",
            "2023-03-24 11:32:12 (381 KB/s) - ‘dwug_de.zip.2’ saved [14620222/14620222]\n",
            "\n",
            "--2023-03-24 11:32:13--  https://zenodo.org/record/5791269/files/refwug.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4514549 (4.3M) [application/octet-stream]\n",
            "Saving to: ‘refwug.zip.2’\n",
            "\n",
            "refwug.zip.2        100%[===================>]   4.30M   396KB/s    in 12s     \n",
            "\n",
            "2023-03-24 11:32:27 (380 KB/s) - ‘refwug.zip.2’ saved [4514549/4514549]\n",
            "\n",
            "--2023-03-24 11:32:27--  https://zenodo.org/record/7387261/files/dwug_en.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11468345 (11M) [application/octet-stream]\n",
            "Saving to: ‘dwug_en.zip.2’\n",
            "\n",
            "dwug_en.zip.2       100%[===================>]  10.94M   376KB/s    in 30s     \n",
            "\n",
            "2023-03-24 11:32:58 (379 KB/s) - ‘dwug_en.zip.2’ saved [11468345/11468345]\n",
            "\n",
            "--2023-03-24 11:32:59--  https://zenodo.org/record/7389506/files/dwug_sv.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12244228 (12M) [application/octet-stream]\n",
            "Saving to: ‘dwug_sv.zip.2’\n",
            "\n",
            "dwug_sv.zip.2       100%[===================>]  11.68M   392KB/s    in 31s     \n",
            "\n",
            "2023-03-24 11:33:32 (381 KB/s) - ‘dwug_sv.zip.2’ saved [12244228/12244228]\n",
            "\n",
            "--2023-03-24 11:33:33--  https://zenodo.org/record/6433667/files/dwug_es.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13771776 (13M) [application/octet-stream]\n",
            "Saving to: ‘dwug_es.zip.2’\n",
            "\n",
            "dwug_es.zip.2       100%[===================>]  13.13M   372KB/s    in 36s     \n",
            "\n",
            "2023-03-24 11:34:10 (377 KB/s) - ‘dwug_es.zip.2’ saved [13771776/13771776]\n",
            "\n",
            "--2023-03-24 11:34:11--  https://zenodo.org/record/5791193/files/diawug.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7301672 (7.0M) [application/octet-stream]\n",
            "Saving to: ‘diawug.zip.2’\n",
            "\n",
            "diawug.zip.2        100%[===================>]   6.96M   387KB/s    in 19s     \n",
            "\n",
            "2023-03-24 11:34:32 (380 KB/s) - ‘diawug.zip.2’ saved [7301672/7301672]\n",
            "\n",
            "--2023-03-24 11:34:33--  https://zenodo.org/record/5500223/files/DUPS-WUG.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4741334 (4.5M) [application/octet-stream]\n",
            "Saving to: ‘DUPS-WUG.zip.2’\n",
            "\n",
            "DUPS-WUG.zip.2      100%[===================>]   4.52M   386KB/s    in 12s     \n",
            "\n",
            "2023-03-24 11:34:46 (377 KB/s) - ‘DUPS-WUG.zip.2’ saved [4741334/4741334]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#RuDSI\n",
        "rudsi = 'https://github.com/kategavrishina/RuDSI/tree/main/data' \n",
        "\n",
        "#NorDiaChange\n",
        "nordia1 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset1/data'\n",
        "nordia2 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset2/data'\n",
        "\n",
        "#RuShiftEval\n",
        "rushifteval1 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval1/data'\n",
        "rushifteval2 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval2/data'\n",
        "rushifteval3 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval3/data'\n",
        "\n",
        "#RuSemShift\n",
        "rusemshift1 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_1/DWUG/data'\n",
        "rusemshift2 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_2/DWUG/data'\n",
        "\n",
        "#Discowug\n",
        "!wget https://zenodo.org/record/7396225/files/discowug.zip\n",
        "with ZipFile('discowug.zip', 'r') as discowug:\n",
        "    discowug.extractall()\n",
        "\n",
        "\n",
        "#surel\n",
        "!wget https://zenodo.org/record/5784569/files/surel.zip\n",
        "with ZipFile('surel.zip', 'r') as surel:\n",
        "    surel.extractall()\n",
        "\n",
        "#durel \n",
        "!wget https://zenodo.org/record/5784453/files/durel.zip\n",
        "with ZipFile('durel.zip', 'r') as durel:\n",
        "    durel.extractall()\n",
        "\n",
        "#DWUG DE\n",
        "!wget https://zenodo.org/record/7441645/files/dwug_de.zip\n",
        "with ZipFile('dwug_de.zip', 'r') as dwug_de:\n",
        "    dwug_de.extractall()\n",
        "\n",
        "#RefWUG \n",
        "!wget https://zenodo.org/record/5791269/files/refwug.zip\n",
        "with ZipFile('refwug.zip', 'r') as refwug:\n",
        "    refwug.extractall()\n",
        "\n",
        "#DWUG EN\n",
        "!wget https://zenodo.org/record/7387261/files/dwug_en.zip\n",
        "with ZipFile('dwug_en.zip', 'r') as dwug_en:\n",
        "    dwug_en.extractall()\n",
        "\n",
        "\n",
        "#DWUG SV\n",
        "!wget https://zenodo.org/record/7389506/files/dwug_sv.zip\n",
        "with ZipFile('dwug_sv.zip', 'r') as dwug_sv:\n",
        "    dwug_sv.extractall()\n",
        "\n",
        "\n",
        "#DWUG ES\n",
        "!wget https://zenodo.org/record/6433667/files/dwug_es.zip\n",
        "with ZipFile('dwug_es.zip', 'r') as dwug_es:\n",
        "    dwug_es.extractall()\n",
        "\n",
        "#DiaWUG\n",
        "!wget https://zenodo.org/record/5791193/files/diawug.zip\n",
        "with ZipFile('diawug.zip', 'r') as diawug:\n",
        "    diawug.extractall()\n",
        "\n",
        "\n",
        "#DUPS_WUG\n",
        "!wget https://zenodo.org/record/5500223/files/DUPS-WUG.zip\n",
        "with ZipFile('DUPS-WUG.zip', 'r') as dups:\n",
        "    dups.extractall()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF7x4EiZQkqm",
        "outputId": "bad6eb3e-369f-4950-e160-f643e9be0586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-24 11:34:48--  https://pilehvar.github.io/wic/package/WiC_dataset.zip\n",
            "Resolving pilehvar.github.io (pilehvar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to pilehvar.github.io (pilehvar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 275984 (270K) [application/zip]\n",
            "Saving to: ‘WiC_dataset.zip.2’\n",
            "\n",
            "\rWiC_dataset.zip.2     0%[                    ]       0  --.-KB/s               \rWiC_dataset.zip.2   100%[===================>] 269.52K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-03-24 11:34:48 (10.8 MB/s) - ‘WiC_dataset.zip.2’ saved [275984/275984]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (3.5.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy) (67.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.10.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "%run /content/WUGs/scripts/misc/wic2wug.ipynb #transforms WIC dataset to wug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "VXfrWc-8Pydq"
      },
      "outputs": [],
      "source": [
        "%run /content/WUGs/scripts/misc/rawc2wug.py #Raw-C to wug "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "827ot725Dqsi"
      },
      "outputs": [],
      "source": [
        "direc = []\n",
        "i = os.listdir('WUGs/scripts/misc/wugdata')\n",
        "direc.append(i)\n",
        "\n",
        "k = os.listdir('WUGs/scripts/misc/wugformat')\n",
        "direc.append(k)                                   #all data directories extracted from tempowic, cosimlex and wic\n",
        "\n",
        "m = os.listdir('/content/WIC')\n",
        "direc.append(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "wvjO51NCDs-G"
      },
      "outputs": [],
      "source": [
        "paths = []          #list of directory paths\n",
        "for i in direc[0]:\n",
        "    paths.append('WUGs/scripts/misc/wugdata/'+i+ '/data/')     #tempowic \n",
        "\n",
        "for i in direc[1]:\n",
        "    paths.append('WUGs/scripts/misc/wugformat/'+ i + '/wug_all/data/all') #cosimlex\n",
        "\n",
        "for i in direc[2]:\n",
        "    paths.append('/content/WIC/'+ i +'/') #wic\n",
        "\n",
        "paths.append(\"WUGs/scripts/misc/data/\")  #usim   \n",
        "paths.append(\"/content/raw-c/\") #rawc\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "Osmw5w2aDyzV"
      },
      "outputs": [],
      "source": [
        "folders = []                       #list of all folders names(lemma wise) in tempowic, cosimlex, wic, usim, rawc\n",
        "for ds in paths:\n",
        "    path = os.listdir(ds)\n",
        "    folders.append(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "-9olDU9GNBiE"
      },
      "outputs": [],
      "source": [
        "#final list judgments paths for tempowic, cosimlex and usim\n",
        "path_j = []  \n",
        "pathco = []                                     \n",
        "for i in folders[0]:\n",
        "     pathj = paths[0] + i + \"/judgments.csv\" #tempowic\n",
        "     path_j.append(pathj)\n",
        "for i in folders[2]:\n",
        "     pathj = paths[2] + i + \"/judgments.csv\" #tempowic\n",
        "     path_j.append(pathj)\n",
        "for i in folders[5]:\n",
        "     pathj = paths[5] + i + \"/judgments.csv\"  #tempowic\n",
        "     path_j.append(pathj)\n",
        "\n",
        "     pathj = paths[6] + \"/judgments.csv\" #cosimlex\n",
        "     pathco.append(pathj)\n",
        "\n",
        "     pathj = paths[7]  + \"/judgments.csv\" #cosimlex\n",
        "     pathco.append(pathj)\n",
        "\n",
        "     pathj = paths[8]  + \"/judgments.csv\" #cosimlex\n",
        "     pathco.append(pathj)\n",
        "for i in folders[12]:            #usim\n",
        "     pathj = paths[12] + i + \"/judgments.csv\"\n",
        "     path_j.append(pathj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "5tsVTgfthxd_"
      },
      "outputs": [],
      "source": [
        "#final list judgments paths and dataframe for wic and rawc\n",
        "path_k = []                                   \n",
        "for i in folders[9]:\n",
        "    pathj = paths[9] + i + \"/judgments.csv\"    #wic\n",
        "    path_k.append(pathj)\n",
        "for i in folders[10]:\n",
        "    pathj = paths[10] + i + \"/judgments.csv\" #wic\n",
        "    path_k.append(pathj)\n",
        "for i in folders[11]:\n",
        "    pathj = paths[11] + i + \"/judgments.csv\"      #wic\n",
        "    path_k.append(pathj)\n",
        "for i in folders[13]:                             #rawc\n",
        "    pathj = paths[13] + i + \"/judgments.csv\"\n",
        "    path_k.append(pathj)\n",
        "#judgements dataframe for rawc and wic datasets\n",
        "raw_df = pd.DataFrame()\n",
        "for i in path_k:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[2]\n",
        "   raw_df = pd.concat([raw_df, Tmp])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "vsaKLfNVie0n"
      },
      "outputs": [],
      "source": [
        "raw_df['language'] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "oNIMVfBORHYz"
      },
      "outputs": [],
      "source": [
        "raw_df = raw_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "Qqogpjk9i_L7"
      },
      "outputs": [],
      "source": [
        "cosim_df = pd.DataFrame()             #cosimlex judgments dataframe\n",
        "for i in pathco:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "   Tmp['dataset'] = i.split('/')[4]\n",
        "   cosim_df = pd.concat([cosim_df, Tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "Jd1OD-Iaj4XL"
      },
      "outputs": [],
      "source": [
        "cosim_df.loc[cosim_df[\"dataset\"] == \"fi\", \"language\"] = 'Finnish' \n",
        "cosim_df.loc[cosim_df[\"dataset\"] == \"hr\", \"language\"] = 'Croatian'\n",
        "cosim_df.loc[cosim_df[\"dataset\"] == \"en\", \"language\"] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "IVAuxcM7kPXU"
      },
      "outputs": [],
      "source": [
        "cosim_df['dataset'] = 'Cosimlex'\n",
        "cosim_df = cosim_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "FBLRXjJ4Rlzr"
      },
      "outputs": [],
      "source": [
        "judgemt_df = pd.DataFrame()                   #judgments dataframe for tempowic and usim \n",
        "for i in path_j:\n",
        "    Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "    Tmp['dataset'] = i.split('/')[3]\n",
        "    judgemt_df = pd.concat([judgemt_df, Tmp])\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "xlwvRygXGHf5"
      },
      "outputs": [],
      "source": [
        "judgemt_df.loc[judgemt_df[\"dataset\"] == \"wugdata\", \"dataset\"] = 'TempoWic'\n",
        "judgemt_df.loc[judgemt_df[\"dataset\"] == \"data\", \"dataset\"] = 'USim'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "H7nT8nomIPCN"
      },
      "outputs": [],
      "source": [
        "judgemt_df.loc[judgemt_df[\"dataset\"] == \"TempoWic\", \"language\"] = 'English'\n",
        "judgemt_df.loc[judgemt_df[\"dataset\"] == \"USim\", \"language\"] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "sKsGR7HDFxSL"
      },
      "outputs": [],
      "source": [
        "judgemt_df = judgemt_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "Gxu63ay6fntu"
      },
      "outputs": [],
      "source": [
        "dwugde = \"dwug_de/data\"                          #WUG data directory paths\n",
        "dwugen = \"dwug_en/data\"\n",
        "dwugsv = \"dwug_sv/data\"\n",
        "discowugg = \"discowug/data\"\n",
        "durel = \"durel/data\"\n",
        "surel = \"surel/data\"\n",
        "refwug = \"refwug/data\"\n",
        "dwuges = 'dwug_es/data'\n",
        "diawug = 'diawug/data'\n",
        "dups = 'DUPS-WUG/data'\n",
        "dupswug = ''\n",
        "dwug = [dwugde, dwugen,dwugsv,discowugg, durel, surel, refwug, dwuges, diawug, dups]\n",
        "dirlist = []\n",
        "for dataset in dwug:\n",
        "  dir = os.listdir(dataset)\n",
        "  dirlist.append(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "wt41rHU53UQU"
      },
      "outputs": [],
      "source": [
        "dwug_j = []                                                #dwug data paths\n",
        "for i in dirlist[0]:\n",
        "  dwugde_j = \"dwug_de/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwugde_j)\n",
        "for i in dirlist[1]:\n",
        "  dwugen_j = \"dwug_en/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwugen_j)\n",
        "for i in dirlist[2]:\n",
        "  dwugsv_j = \"dwug_sv/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwugsv_j)\n",
        "for i in dirlist[3]:\n",
        "  discowugg_j = \"discowug/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(discowugg_j)\n",
        "for i in dirlist[4]:\n",
        "  durel_j = \"durel/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(durel_j)\n",
        "for i in dirlist[5]:\n",
        "  surel_j = \"surel/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(surel_j)  \n",
        "for i in dirlist[6]:\n",
        "  refwug_j = \"refwug/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(refwug_j)\n",
        "for i in dirlist[7]:\n",
        "  dwuges_j = \"dwug_es/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwuges_j)\n",
        "for i in dirlist[8]:\n",
        "  diawug_j = \"diawug/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(diawug_j)\n",
        "for i in dirlist[9]:\n",
        "  dups_j = \"DUPS-WUG/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dups_j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "40oRLVLdYXTR"
      },
      "outputs": [],
      "source": [
        "judgemnt_df = pd.DataFrame()            #dwug data judgments df\n",
        "for i in dwug_j:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[0]\n",
        "   judgemnt_df = pd.concat([judgemnt_df, Tmp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "DuKrc5P7NF6P"
      },
      "outputs": [],
      "source": [
        "path_u = []                      #uses paths for tempowic and usim\n",
        "for i in folders[0]:\n",
        "    pathj = paths[0] + i + \"/uses.csv\"    #tempowic\n",
        "    path_u.append(pathj)\n",
        "for i in folders[2]:\n",
        "    pathj = paths[2] + i + \"/uses.csv\"     #tempowic\n",
        "    path_u.append(pathj)\n",
        "for i in folders[4]:\n",
        "    pathj = paths[4] + i + \"/uses.csv\"     #tempowic\n",
        "    path_u.append(pathj)\n",
        "for i in folders[12]:\n",
        "     pathj = paths[12] + i + \"/uses.csv\"   #usim\n",
        "     path_u.append(pathj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "QfcQ_x25mOWy"
      },
      "outputs": [],
      "source": [
        "path_cou = []                               #for cosimlex uses paths\n",
        "for i in folders[6]:\n",
        "    pathj = paths[6] + \"/uses.csv\"\n",
        "    path_cou.append(pathj)\n",
        "for i in folders[7]:\n",
        "    pathj = paths[7] + \"/uses.csv\"\n",
        "    path_cou.append(pathj)\n",
        "for i in folders[8]:\n",
        "    pathj = paths[8] +  \"/uses.csv\"\n",
        "    path_cou.append(pathj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "2FtNPXSvmaUg"
      },
      "outputs": [],
      "source": [
        "cosim_uses_df = pd.DataFrame()            #cosimlex uses df\n",
        "for i in path_cou:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[4]\n",
        "   cosim_uses_df = pd.concat([cosim_uses_df, Tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "NhJFx09em6yB"
      },
      "outputs": [],
      "source": [
        "cosim_uses_df.loc[cosim_uses_df[\"dataset\"] == \"fi\", \"language\"] = 'Finnish' \n",
        "cosim_uses_df.loc[cosim_uses_df[\"dataset\"] == \"hr\", \"language\"] = 'Croatian'\n",
        "cosim_uses_df.loc[cosim_uses_df[\"dataset\"] == \"en\", \"language\"] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "WfTftRhQnQVR"
      },
      "outputs": [],
      "source": [
        "cosim_uses_df['dataset'] = 'Cosimlex'\n",
        "cosim_uses_df = cosim_uses_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "YkjXw4ganXqu"
      },
      "outputs": [],
      "source": [
        "path_k = []                            #wic and rawc uses df\n",
        "for i in folders[9]:\n",
        "    pathj = paths[9] + i + \"/uses.csv\" #wic\n",
        "    path_k.append(pathj)\n",
        "for i in folders[10]:\n",
        "    pathj = paths[10] + i + \"/uses.csv\" #wic\n",
        "    path_k.append(pathj)\n",
        "for i in folders[11]:\n",
        "    pathj = paths[11] + i + \"/uses.csv\" #wic\n",
        "    path_k.append(pathj)\n",
        "for i in folders[13]:\n",
        "    pathj = paths[13] + i + \"/uses.csv\" #rawc\n",
        "    path_k.append(pathj)\n",
        "raw_uses_df = pd.DataFrame()\n",
        "for i in path_k:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[2]\n",
        "   raw_uses_df = pd.concat([raw_uses_df, Tmp]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "Z1D38jh9nkkE"
      },
      "outputs": [],
      "source": [
        "raw_uses_df['language'] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "Kcs1Wy1In-Cl"
      },
      "outputs": [],
      "source": [
        "use_df = pd.DataFrame()    #uses df temp for tempowic and usim\n",
        "for i in path_u:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "   Tmp['dataset'] = i.split('/')[3]\n",
        "   use_df = pd.concat([use_df, Tmp])\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "PKtzLYAoKE2S"
      },
      "outputs": [],
      "source": [
        "use_df.loc[use_df[\"dataset\"] == \"wugdata\", \"dataset\"] = 'TempoWic'\n",
        "use_df.loc[use_df[\"dataset\"] == \"data\", \"dataset\"] = 'USim'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "ygJMtiIkKmr2"
      },
      "outputs": [],
      "source": [
        "use_df['language'] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "bH1zLd2M6r3i"
      },
      "outputs": [],
      "source": [
        "dwug_u = []                                           #dwug data uses paths\n",
        "for i in dirlist[0]:\n",
        "  dwugde_u = \"dwug_de/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwugde_u)\n",
        "for i in dirlist[1]:\n",
        "  dwugen_u = \"dwug_en/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwugen_u)\n",
        "for i in dirlist[2]:\n",
        "  dwugsv_u = \"dwug_sv/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwugsv_u)\n",
        "for i in dirlist[3]:\n",
        "  discowugg_u = \"discowug/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(discowugg_u)\n",
        "for i in dirlist[4]:\n",
        "  durel_u = \"durel/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(durel_u)\n",
        "for i in dirlist[5]:\n",
        "  surel_u = \"surel/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(surel_u)  \n",
        "for i in dirlist[6]:\n",
        "  refwug_u = \"refwug/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(refwug_u)\n",
        "for i in dirlist[7]:\n",
        "  dwuges_u = \"dwug_es/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwuges_u)\n",
        "for i in dirlist[8]:\n",
        "  diawug_u = \"diawug/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(diawug_u)\n",
        "\n",
        "for i in dirlist[9]:\n",
        "  dups_u = \"DUPS-WUG/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dups_u)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "3i1SnqaGleIR"
      },
      "outputs": [],
      "source": [
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_de\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_en\", \"language\"] = 'English'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"DUPS-WUG\", \"language\"] = 'English'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_es\", \"language\"] = 'Spanish'\n",
        "#judgemnt_df.loc[judgemnt_df[\"name\"] == \"dwug_la\", \"language\"] = 'latin'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_sv\", \"language\"] = 'Swedish'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"durel\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"surel\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"discowug\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"refwug\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"diawug\", \"language\"] = 'Spanish'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "q89I4-6qMxrm"
      },
      "outputs": [],
      "source": [
        "#final judgments df (without russian and norwegian datasets)\n",
        "judgment_df = pd.DataFrame()\n",
        "judgment_df = pd.concat([judgment_df, judgemt_df], axis = 0)\n",
        "judgment_df = pd.concat([judgment_df, judgemnt_df], axis = 0)    \n",
        "judgment_df = pd.concat([judgment_df, raw_df], axis = 0)\n",
        "judgment_df = pd.concat([judgment_df, cosim_df], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "I2OPKvW_LrXW"
      },
      "outputs": [],
      "source": [
        "judgment_df = judgment_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "H5UNk2kXD2oU"
      },
      "outputs": [],
      "source": [
        "usee_df = pd.DataFrame()            #uses dwug df\n",
        "for i in dwug_u:\n",
        "    Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "    Tmp['dataset'] = i.split('/')[0]\n",
        "    usee_df = pd.concat([usee_df, Tmp])\n",
        "    usee_df = pd.concat([usee_df, pd.read_csv(i, delimiter='\\t', quoting = 3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "Swq_wL0BpUYf"
      },
      "outputs": [],
      "source": [
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_de\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_en\", \"language\"] = 'English'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"DUPS-WUG\", \"language\"] = 'English'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_es\", \"language\"] = 'Spanish'\n",
        "#usee_df.loc[usee_df[\"dataset\"] == \"dwug_la\", \"language\"] = 'latin'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_sv\", \"language\"] = 'Swedish'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"durel\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"surel\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"discowug\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"refwug\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"diawug\", \"language\"] = 'Spanish'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "A8ZyibHeoYaS"
      },
      "outputs": [],
      "source": [
        "#combining uses df\n",
        "uses_full_df = pd.concat([usee_df, use_df], axis = 0)\n",
        "uses1_df = pd.concat([uses_full_df, raw_uses_df], axis = 0)\n",
        "uses_df_full = pd.concat([uses1_df, cosim_uses_df], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "-Hs9BgeUHPxZ"
      },
      "outputs": [],
      "source": [
        "#getting the data \n",
        "russian = [rudsi, nordia1, nordia2, rushifteval1, rushifteval2, rushifteval3, rusemshift1, rusemshift2]\n",
        "find_class = []\n",
        "for URL in russian:\n",
        "  page = requests.get(URL)\n",
        "  soup = BeautifulSoup( page.content , 'html.parser')\n",
        "  classy = soup.find_all('a', class_=\"Link--primary\")[3:]\n",
        "  find_class.append(classy)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "uTjddnWNuE1o"
      },
      "outputs": [],
      "source": [
        "judgements = []\n",
        "uses = []\n",
        "for find_by_class in find_class:\n",
        "  for i in find_by_class:\n",
        "    judgements.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/judgments.csv\")\n",
        "    uses.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/uses.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "4DuRGR6jrfD2"
      },
      "outputs": [],
      "source": [
        "#judgments dataframe for rudsi, rusemshift, rushifteval, nordiachange\n",
        "judgements_df = pd.DataFrame()\n",
        "for i in judgements:\n",
        "   Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "   Tmp['dataset'] = i.split('/')[5]\n",
        "   judgements_df = pd.concat([judgements_df, Tmp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "IEcwGGWLKxP1"
      },
      "outputs": [],
      "source": [
        "judgements_df[\"language\"] = \"Russian\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "oyKbDqb-q_hK"
      },
      "outputs": [],
      "source": [
        "judgements_df.loc[judgements_df[\"dataset\"] == \"NorDiaChange\", \"language\"] = 'Norwegian'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "rhhOvgn30FtZ"
      },
      "outputs": [],
      "source": [
        "#uses dataframe for rudsi, rusemshift, rushifteval, nordiachange\n",
        "usees_df = pd.DataFrame()\n",
        "for i in uses:\n",
        "    Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "    Tmp['dataset'] = i.split('/')[5]\n",
        "    usees_df = pd.concat([usees_df, Tmp])\n",
        "   \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "ikn0jHLOtY35"
      },
      "outputs": [],
      "source": [
        "usees_df['language'] = 'Russian'\n",
        "usees_df.loc[usees_df[\"dataset\"] == \"NorDiaChange\", \"language\"] = 'Norwegian'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "oS__0wkBdjfP"
      },
      "outputs": [],
      "source": [
        "#final judgments dataframe full format\n",
        "judgments_full = pd.concat([judgment_df, judgements_df], axis = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "AxBZ18nA7Ky2"
      },
      "outputs": [],
      "source": [
        "#final uses dataframe full format\n",
        "uses_full = pd.concat([uses_df_full, usees_df], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "3DWumP4cKuFn"
      },
      "outputs": [],
      "source": [
        "#resetting the index of uses and judgments dataframes because they have repeated indices\n",
        "judgments_full = judgments_full.reset_index(drop= True)\n",
        "uses_full = uses_full.reset_index(drop= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "zeUvy7OHvdby"
      },
      "outputs": [],
      "source": [
        "#final judgments in wug format\n",
        "judgments_wug = judgments_full[[\"identifier1\", \"identifier2\", \"annotator\", \"judgment\", \"comment\", \"lemma\", \"dataset\", \"language\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "Rl5CzLr9vTDa"
      },
      "outputs": [],
      "source": [
        "#final uses dataframe in wug format\n",
        "uses_wug= uses_full[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'dataset', 'language']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "IL_z2_CgEIrI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
