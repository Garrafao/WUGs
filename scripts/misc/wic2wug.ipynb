{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zASMJ4H54r0-",
        "outputId": "4774efcd-657f-49dd-cdd4-7679f1eccca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-20 16:43:24--  https://pilehvar.github.io/wic/package/WiC_dataset.zip\n",
            "Resolving pilehvar.github.io (pilehvar.github.io)... 185.199.109.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to pilehvar.github.io (pilehvar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 275984 (270K) [application/zip]\n",
            "Saving to: ‘WiC_dataset.zip’\n",
            "\n",
            "\rWiC_dataset.zip       0%[                    ]       0  --.-KB/s               \rWiC_dataset.zip     100%[===================>] 269.52K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-02-20 16:43:24 (8.03 MB/s) - ‘WiC_dataset.zip’ saved [275984/275984]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://pilehvar.github.io/wic/package/WiC_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "aNQkbcRaC6B5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71033617-9f0a-4a1c-a743-3af13cb72b24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = os.makedirs( '/content/WIC', exist_ok=True )"
      ],
      "metadata": {
        "id": "5WhCmopMAQ86"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev = os.makedirs( '/content/WIC/dev', exist_ok=True )\n",
        "train = os.makedirs( '/content/WIC/train', exist_ok=True )\n",
        "test = os.makedirs( '/content/WIC/test', exist_ok=True )\n"
      ],
      "metadata": {
        "id": "PU7JiunOJINI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path = \"/content/dev/dev.data.txt\""
      ],
      "metadata": {
        "id": "vQtjXRG1zOL8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#directory = path.split('/')[2]"
      ],
      "metadata": {
        "id": "xxBg-7aPzSKB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyIzMi43Nl8M",
        "outputId": "641c93ee-606d-4f23-83c2-58da0d9df2a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('WiC_dataset.zip', 'r') as WiC:\n",
        "   WiC.extractall()"
      ],
      "metadata": {
        "id": "U21Til5c5CnA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev = pd.read_csv(\"/content/dev/dev.data.txt\", sep = '\\t', names=[\"lemma\", \"pos\", \"index\", \"sent1\", \"sent2\"], encoding = 'UTF-8')\n",
        "df_train = pd.read_csv(\"/content/train/train.data.txt\", sep = '\\t', names=[\"lemma\", \"pos\", \"index\", \"sent1\", \"sent2\"], encoding = 'UTF-8')\n",
        "df_test = pd.read_csv(\"/content/test/test.data.txt\", sep = '\\t', names=[\"lemma\", \"pos\", \"index\", \"sent1\", \"sent2\"], encoding = 'UTF-8')\n"
      ],
      "metadata": {
        "id": "A9unNJtRB9NA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_label= pd.read_csv(\"/content/dev/dev.gold.txt\", sep = '\\t', names = ['judgment'], encoding = 'UTF-8')\n",
        "train_label= pd.read_csv(\"/content/train/train.gold.txt\", sep = '\\t', names = ['judgment'], encoding = 'UTF-8')\n",
        "test_label= pd.read_csv(\"/content/test/test.gold.txt\", sep = '\\t', names = ['judgment'], encoding = 'UTF-8')"
      ],
      "metadata": {
        "id": "XLnXTxNcsLem"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= df_dev['index'].tolist()\n",
        "y = df_train['index'].tolist()\n",
        "z = df_test['index'].tolist()"
      ],
      "metadata": {
        "id": "7UShtKK95Sdo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dash = df_dev[['lemma', 'sent1', 'sent2']]\n",
        "df_dash1 = df_train[['lemma', 'sent1', 'sent2']]\n",
        "df_dash2 = df_test[['lemma', 'sent1', 'sent2']]"
      ],
      "metadata": {
        "id": "vLI1oPkw1Rii"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df_dash[['lemma', 'sent1']]\n",
        "df1.columns =  ['word', 'sent']\n",
        "df1[\"index\"] = df1.groupby(\"word\").cumcount()*2\n",
        "\n",
        "dfone = df_dash1[['lemma', 'sent1']]\n",
        "dfone.columns =  ['word', 'sent']\n",
        "dfone[\"index\"] = dfone.groupby(\"word\").cumcount()*2\n",
        "\n",
        "dfein = df_dash2[['lemma', 'sent1']]\n",
        "dfein.columns =  ['word', 'sent']\n",
        "dfein[\"index\"] = dfein.groupby(\"word\").cumcount()*2"
      ],
      "metadata": {
        "id": "-ANHu2jj1YZ8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 =  df_dash[['lemma', 'sent2']]\n",
        "df2.columns =  ['word', 'sent']\n",
        "df2[\"index\"] = df2.groupby(\"word\").cumcount()*2+1\n",
        "\n",
        "dftwo =  df_dash1[['lemma', 'sent2']]\n",
        "dftwo.columns =  ['word', 'sent']\n",
        "dftwo[\"index\"] = dftwo.groupby(\"word\").cumcount()*2+1\n",
        "\n",
        "dfdu =  df_dash2[['lemma', 'sent2']]\n",
        "dfdu.columns =  ['word', 'sent']\n",
        "dfdu[\"index\"] = dfdu.groupby(\"word\").cumcount()*2+1"
      ],
      "metadata": {
        "id": "8ENUewpV5lH-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev = pd.concat([df1, df2])\n",
        "df_final_dev = df_final_dev.sort_values(by = ['word', 'index'], ascending = [True, True]) \n",
        "\n",
        "df_final_train = pd.concat([dfone, dftwo])\n",
        "df_final_train = df_final_train.sort_values(by = ['word', 'index'], ascending = [True, True])\n",
        "\n",
        "df_final_test = pd.concat([dfein, dfdu])\n",
        "df_final_test = df_final_test.sort_values(by = ['word', 'index'], ascending = [True, True])"
      ],
      "metadata": {
        "id": "npdDVwrR5w_5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5WKjJ8VR5-7s",
        "outputId": "de92be4d-036f-43c2-9bfd-62aa795a0ea6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            word                                               sent  index\n",
              "59         abort   I wasted a year of my life working on an abort .      0\n",
              "59         abort  He sent a short message requesting an abort du...      1\n",
              "1095  absorption  The absorption of light , heat , electricity ,...      0\n",
              "1095  absorption  The absorption of photons by atoms or molecules .      1\n",
              "618       accept              To accept the report of a committee .      0\n",
              "...          ...                                                ...    ...\n",
              "1224        zero  Write 0.0 to indicate a floating point number ...      5\n",
              "1023      zinger  She tried to think of some killer of an argume...      0\n",
              "1023      zinger           He always greeted me with a new zinger .      1\n",
              "169         zone  The white zone is for loading and unloading on...      0\n",
              "169         zone  There is a no-smoking zone that extends 25 fee...      1\n",
              "\n",
              "[2800 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e24d6b9-44fb-4537-9c39-feaea697ea74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>sent</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>abort</td>\n",
              "      <td>I wasted a year of my life working on an abort .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>abort</td>\n",
              "      <td>He sent a short message requesting an abort du...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>absorption</td>\n",
              "      <td>The absorption of light , heat , electricity ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>absorption</td>\n",
              "      <td>The absorption of photons by atoms or molecules .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>accept</td>\n",
              "      <td>To accept the report of a committee .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1224</th>\n",
              "      <td>zero</td>\n",
              "      <td>Write 0.0 to indicate a floating point number ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>zinger</td>\n",
              "      <td>She tried to think of some killer of an argume...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>zinger</td>\n",
              "      <td>He always greeted me with a new zinger .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>zone</td>\n",
              "      <td>The white zone is for loading and unloading on...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>zone</td>\n",
              "      <td>There is a no-smoking zone that extends 25 fee...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2800 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e24d6b9-44fb-4537-9c39-feaea697ea74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e24d6b9-44fb-4537-9c39-feaea697ea74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e24d6b9-44fb-4537-9c39-feaea697ea74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev[\"identifier\"] = df_final_dev[\"word\"]+\"-\"+df_final_dev[\"index\"].astype(str)\n",
        "df_final_train[\"identifier\"] = df_final_train[\"word\"]+\"-\"+df_final_train[\"index\"].astype(str)\n",
        "df_final_test[\"identifier\"] = df_final_test[\"word\"]+\"-\"+df_final_test[\"index\"].astype(str)"
      ],
      "metadata": {
        "id": "64T1JBGB6BGP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_odd = df_final_dev[1::2]\n",
        "df_odd.columns = [\"word2\", \"sent2\", \"index2\", \"identifier2\"]\n",
        "df_even = df_final_dev[::2]\n",
        "df_even.columns = [\"word1\", \"sent1\", \"index1\", \"identifier1\"]\n",
        "df_final_dev = pd.concat([df_even, df_odd], axis=1)\n",
        "\n",
        "df_odd1 = df_final_train[1::2]\n",
        "df_odd1.columns = [\"word2\", \"sent2\", \"index2\", \"identifier2\"]\n",
        "df_even1 = df_final_train[::2]\n",
        "df_even1.columns = [\"word1\", \"sent1\", \"index1\", \"identifier1\"]\n",
        "df_final_train = pd.concat([df_even1, df_odd1], axis=1)\n",
        "\n",
        "df_odd2 = df_final_test[1::2]\n",
        "df_odd2.columns = [\"word2\", \"sent2\", \"index2\", \"identifier2\"]\n",
        "df_even2 = df_final_test[::2]\n",
        "df_even2.columns = [\"word1\", \"sent1\", \"index1\", \"identifier1\"]\n",
        "df_final_test = pd.concat([df_even2, df_odd2], axis=1)"
      ],
      "metadata": {
        "id": "RlOUbrv86eCw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev = df_final_dev[[\"word2\", \"sent2\", \"identifier2\", \"sent1\", \"identifier1\", 'index1', 'index2']]\n",
        "df_final_dev = df_final_dev.rename(columns={\"word2\":\"lemma\"})\n",
        "\n",
        "df_final_train = df_final_train[[\"word2\", \"sent2\", \"identifier2\", \"sent1\", \"identifier1\", 'index1', 'index2']]\n",
        "df_final_train = df_final_train.rename(columns={\"word2\":\"lemma\"})\n",
        "\n",
        "df_final_test = df_final_test[[\"word2\", \"sent2\", \"identifier2\", \"sent1\", \"identifier1\", 'index1', 'index2']]\n",
        "df_final_test = df_final_test.rename(columns={\"word2\":\"lemma\"})"
      ],
      "metadata": {
        "id": "rr-ckvAc6q6y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev[\"judgment\"] = dev_label[\"judgment\"].values.tolist()\n",
        "df_final_train[\"judgment\"] = train_label[\"judgment\"].values.tolist()\n",
        "df_final_test[\"judgment\"] = test_label[\"judgment\"].values.tolist()"
      ],
      "metadata": {
        "id": "rOw5QTJR63HD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev = df_final_dev[['lemma', 'identifier2', 'identifier1', 'judgment']]\n",
        "df_final_train = df_final_train[['lemma', 'identifier2', 'identifier1', 'judgment']]\n",
        "df_final_test = df_final_test[['lemma', 'identifier2', 'identifier1', 'judgment']]"
      ],
      "metadata": {
        "id": "7ocKdC-Z7OXC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev[\"annotator\"] = \" \"\n",
        "df_final_dev['comment'] = \" \"\n",
        "df_final_train[\"annotator\"] = \" \"\n",
        "df_final_train['comment'] = \" \"\n",
        "df_final_test[\"annotator\"] = \" \"\n",
        "df_final_test['comment'] = \" \""
      ],
      "metadata": {
        "id": "p5-qiLq37jzm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev = df_final_dev[[\"identifier1\", \"identifier2\", \"annotator\", \"judgment\", \"comment\", \"lemma\"]]\n",
        "df_final_train = df_final_train[[\"identifier1\", \"identifier2\", \"annotator\", \"judgment\", \"comment\", \"lemma\"]]\n",
        "df_final_test = df_final_test[[\"identifier1\", \"identifier2\", \"annotator\", \"judgment\", \"comment\", \"lemma\"]]"
      ],
      "metadata": {
        "id": "2BW6UdCn7snM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev = df_final_dev.reset_index(drop =True)\n",
        "df_final_train = df_final_train.reset_index(drop =True)\n",
        "df_final_test = df_final_test.reset_index(drop =True)"
      ],
      "metadata": {
        "id": "Rlq5vTgr76Xe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(df_final_dev[\"lemma\"].value_counts().index):\n",
        "        tmp_df = df_final_dev[df_final_dev[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists('/content/WIC/dev'+ \"/\"+i):\n",
        "            os.mkdir('/content/WIC/dev'+ \"/\"+i)\n",
        "        np.savetxt('/content/WIC/dev' +\"/\"+i+\"/judgments.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ],
      "metadata": {
        "id": "gfb8pIx_zyhW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(df_final_train[\"lemma\"].value_counts().index):\n",
        "        tmp_df = df_final_train[df_final_train[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists('/content/WIC/train'+ \"/\"+i):\n",
        "            os.mkdir('/content/WIC/train'+ \"/\"+i)\n",
        "        np.savetxt('/content/WIC/train' +\"/\"+i+\"/judgments.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ],
      "metadata": {
        "id": "RUgdxcquI_iu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(df_final_test[\"lemma\"].value_counts().index):\n",
        "        tmp_df = df_final_test[df_final_test[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists('/content/WIC/test'+ \"/\"+i):\n",
        "            os.mkdir('/content/WIC/test'+ \"/\"+i)\n",
        "        np.savetxt('/content/WIC/test' +\"/\"+i+\"/judgments.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ],
      "metadata": {
        "id": "L26qNL7XKJyH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind1 = []\n",
        "ind2 = []\n",
        "for i in x:\n",
        "    ind1.append(i.split('-')[0])\n",
        "    ind2.append(i.split('-')[1])\n",
        "\n",
        "ind_1 = []\n",
        "ind_2 = []\n",
        "for i in y:\n",
        "    ind_1.append(i.split('-')[0])\n",
        "    ind_2.append(i.split('-')[1])\n",
        "\n",
        "indone = []\n",
        "indtwo = []\n",
        "for i in z:\n",
        "    indone.append(i.split('-')[0])\n",
        "    indtwo.append(i.split('-')[1])"
      ],
      "metadata": {
        "id": "ViTntw-4GRaD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev.loc[:,'ind1'] = ind1\n",
        "df_dev.loc[:,'ind2'] = ind2\n",
        "\n",
        "df_train.loc[:,'ind_1'] = ind_1\n",
        "df_train.loc[:,'ind_2'] = ind_2\n",
        "\n",
        "df_test.loc[:,'indone'] = indone\n",
        "df_test.loc[:,'indtwo'] = indtwo"
      ],
      "metadata": {
        "id": "HqWbHmIGGzQU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df_dev[['lemma', 'pos', 'sent1', 'ind1']]\n",
        "df1.columns =  ['lemma','pos', 'context_tokenized','ind']\n",
        "df10 = df_train[['lemma', 'pos', 'sent1', 'ind_1']]\n",
        "df10.columns =  ['lemma','pos', 'context_tokenized','ind']\n",
        "df100 = df_test[['lemma', 'pos', 'sent1', 'indone']]\n",
        "df100.columns =  ['lemma','pos', 'context_tokenized','ind']"
      ],
      "metadata": {
        "id": "YUtnwQu9F8ZD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df_dev[['lemma', 'pos', 'sent2', 'ind2']]\n",
        "df2.columns =  ['lemma','pos', 'context_tokenized','ind']\n",
        "df20 = df_train[['lemma', 'pos', 'sent2', 'ind_2']]\n",
        "df20.columns =  ['lemma','pos', 'context_tokenized','ind']\n",
        "df200 = df_test[['lemma', 'pos', 'sent2', 'indtwo']]\n",
        "df200.columns =  ['lemma','pos', 'context_tokenized','ind']"
      ],
      "metadata": {
        "id": "3f_E_QijHH4X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev_uses = pd.concat([df1, df2])\n",
        "df_final_dev_uses = df_final_dev_uses.sort_values(by = ['lemma'], ascending = True)\n",
        "df_final_train_uses = pd.concat([df10, df20])\n",
        "df_final_train_uses= df_final_train_uses.sort_values(by = ['lemma'], ascending = True)\n",
        "df_final_test_uses = pd.concat([df100, df200])\n",
        "df_final_test_uses = df_final_test_uses.sort_values(by = ['lemma'], ascending = True)\n"
      ],
      "metadata": {
        "id": "A4nAuBb7Kbmi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev_uses = df_final_dev_uses.reset_index(drop =True)\n",
        "df_final_train_uses = df_final_train_uses.reset_index(drop =True)\n",
        "df_final_test_uses = df_final_test_uses.reset_index(drop =True)"
      ],
      "metadata": {
        "id": "6s47rUQm873_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_indice(sent, indice):\n",
        "  tag = ''\n",
        "  indice = int(indice)\n",
        "  tok = sent.split(\" \")\n",
        "  #print(tok)\n",
        "  for i in range(len(tok)):\n",
        "    if i == indice:\n",
        "      tag = tok[i]\n",
        "  return str(sent.find(tag))+\":\"+str(sent.find(tag)+len(tag))"
      ],
      "metadata": {
        "id": "unW1QgHvNMle"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev_uses[\"indexes_target_token\"] = df_final_dev_uses.apply(lambda x: get_indice(x.context_tokenized, x.ind), axis=1)\n",
        "df_final_train_uses[\"indexes_target_token\"] = df_final_train_uses.apply(lambda x: get_indice(x.context_tokenized, x.ind), axis=1)\n",
        "df_final_test_uses[\"indexes_target_token\"] = df_final_test_uses.apply(lambda x: get_indice(x.context_tokenized, x.ind), axis=1)"
      ],
      "metadata": {
        "id": "bsgDiCA4VfBM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_indices_of_sent(sentence):\n",
        "    return \"0:\"+str(len(sentence))"
      ],
      "metadata": {
        "id": "KdfdHVEMtid9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev_uses[\"indexes_target_sentence\"] = df_final_dev_uses[\"context_tokenized\"].apply(get_indices_of_sent)\n",
        "df_final_train_uses[\"indexes_target_sentence\"] = df_final_train_uses[\"context_tokenized\"].apply(get_indices_of_sent)\n",
        "df_final_test_uses[\"indexes_target_sentence\"] = df_final_test_uses[\"context_tokenized\"].apply(get_indices_of_sent)"
      ],
      "metadata": {
        "id": "_5jXzydPujr9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_len_tok(sentence):\n",
        "  return \"0:\"+str(len(sentence.split(\" \")))"
      ],
      "metadata": {
        "id": "s6_TKjfTu_Xz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev_uses['indexes_target_sentence_tokenized'] = df_final_dev_uses[\"context_tokenized\"].apply(get_len_tok)\n",
        "df_final_train_uses['indexes_target_sentence_tokenized'] = df_final_train_uses[\"context_tokenized\"].apply(get_len_tok)\n",
        "df_final_test_uses['indexes_target_sentence_tokenized'] = df_final_test_uses[\"context_tokenized\"].apply(get_len_tok)"
      ],
      "metadata": {
        "id": "UR4qpS2vumQ2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lem = ''\n",
        "def lemmatizr(sent):\n",
        "  doc = nlp(sent)\n",
        "  for i in doc:\n",
        "    lem += i.lemma_\n",
        "    return lem"
      ],
      "metadata": {
        "id": "NxwyUqX0vS2t"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev_uses['context_lemmatized'] = df_final_dev_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.lemma_ for w in nlp(row)]))"
      ],
      "metadata": {
        "id": "Ru8yyJVexlq1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_train_uses['context_lemmatized'] = df_final_train_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.lemma_ for w in nlp(row)]))\n",
        "df_final_test_uses['context_lemmatized'] = df_final_test_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.lemma_ for w in nlp(row)]))"
      ],
      "metadata": {
        "id": "_uEfkquuNi06"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev_uses['context_pos'] = df_final_dev_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.pos_ for w in nlp(row)]))\n",
        "df_final_train_uses['context_pos'] = df_final_train_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.pos_ for w in nlp(row)]))\n",
        "df_final_test_uses['context_pos'] = df_final_test_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.pos_ for w in nlp(row)]))"
      ],
      "metadata": {
        "id": "S76RLldcZ1k4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_dev_uses['date'] = \" \"\n",
        "df_final_dev_uses['grouping'] = 1\n",
        "df_final_dev_uses['description'] = \" \"\n",
        "df_final_dev_uses['context'] = df_final_dev_uses['context_tokenized']\n",
        "df_final_dev_uses['identifier'] = \" \"\n",
        "df_final_dev_uses['indexes_target_token_tokenized'] = df_final_dev_uses['ind']\n",
        "\n",
        "df_final_train_uses['date'] = \" \"\n",
        "df_final_train_uses['grouping'] = 1\n",
        "df_final_train_uses['description'] = \" \"\n",
        "df_final_train_uses['context'] = df_final_train_uses['context_tokenized']\n",
        "df_final_train_uses['identifier'] = \" \"\n",
        "df_final_train_uses['indexes_target_token_tokenized'] = df_final_train_uses['ind']\n",
        "\n",
        "df_final_test_uses['date'] = \" \"\n",
        "df_final_test_uses['grouping'] = 1\n",
        "df_final_test_uses['description'] = \" \"\n",
        "df_final_test_uses['context'] = df_final_test_uses['context_tokenized']\n",
        "df_final_test_uses['identifier'] = \" \"\n",
        "df_final_test_uses['indexes_target_token_tokenized'] = df_final_test_uses['ind']"
      ],
      "metadata": {
        "id": "MLQGcdXCRbzU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df_dev = df_final_dev_uses[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'context_tokenized', 'indexes_target_token_tokenized', 'indexes_target_sentence_tokenized', 'context_lemmatized', 'context_pos']]\n",
        "final_df_train = df_final_train_uses[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'context_tokenized', 'indexes_target_token_tokenized', 'indexes_target_sentence_tokenized', 'context_lemmatized', 'context_pos']]\n",
        "final_df_test = df_final_test_uses[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'context_tokenized', 'indexes_target_token_tokenized', 'indexes_target_sentence_tokenized', 'context_lemmatized', 'context_pos']]"
      ],
      "metadata": {
        "id": "2O9FfJ9yagcw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(final_df_dev[\"lemma\"].value_counts().index):\n",
        "        tmp_df = final_df_dev[final_df_dev[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists('/content/WIC/dev'+\"/\"+i):\n",
        "            os.mkdir('/content/WIC/dev'+\"/\"+i)\n",
        "        np.savetxt('/content/WIC/dev'+\"/\"+i+\"/uses.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ],
      "metadata": {
        "id": "vdVI14vP1X2B"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(final_df_train[\"lemma\"].value_counts().index):\n",
        "        tmp_df = final_df_train[final_df_train[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists('/content/WIC/train'+\"/\"+i):\n",
        "            os.mkdir('/content/WIC/train'+\"/\"+i)\n",
        "        np.savetxt('/content/WIC/train'+\"/\"+i+\"/uses.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ],
      "metadata": {
        "id": "C6Mv22TNP-sX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(final_df_test[\"lemma\"].value_counts().index):\n",
        "        tmp_df = final_df_test[final_df_test[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists('/content/WIC/test'+\"/\"+i):\n",
        "            os.mkdir('/content/WIC/test'+\"/\"+i)\n",
        "        np.savetxt('/content/WIC/test'+\"/\"+i+\"/uses.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ],
      "metadata": {
        "id": "Y9NEgdWcP_BK"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GKSTqqtxrNle",
        "outputId": "98fb977f-612f-4516-fcf9-f005c9c6eebe"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         lemma pos date  grouping identifier description  \\\n",
              "0      ability   N              1                          \n",
              "1      ability   N              1                          \n",
              "2      absence   N              1                          \n",
              "3      absence   N              1                          \n",
              "4      absence   N              1                          \n",
              "...        ...  ..  ...       ...        ...         ...   \n",
              "10851      yes   N              1                          \n",
              "10852    youth   N              1                          \n",
              "10853    youth   N              1                          \n",
              "10854    youth   N              1                          \n",
              "10855    youth   N              1                          \n",
              "\n",
              "                                                 context indexes_target_token  \\\n",
              "0      This phone has the ability to have its softwar...                19:26   \n",
              "1      This wood has the ability to fight off insects...                18:25   \n",
              "2                  Absence makes the heart grow fonder .                  0:7   \n",
              "3                  Absence makes the heart grow fonder .                  0:7   \n",
              "4                         He visited during my absence .                21:28   \n",
              "...                                                  ...                  ...   \n",
              "10851                                   Was that a yes ?                11:14   \n",
              "10852  Her youth and beauty is what attracted him to ...                  4:9   \n",
              "10853  Make the most of your youth , it will not last...                22:27   \n",
              "10854  I made many mistakes in my youth , but learned...                27:32   \n",
              "10855  I made many mistakes in my youth , but learned...                27:32   \n",
              "\n",
              "      indexes_target_sentence  \\\n",
              "0                        0:69   \n",
              "1                        0:92   \n",
              "2                        0:37   \n",
              "3                        0:37   \n",
              "4                        0:30   \n",
              "...                       ...   \n",
              "10851                    0:16   \n",
              "10852                    0:51   \n",
              "10853                    0:56   \n",
              "10854                    0:62   \n",
              "10855                    0:62   \n",
              "\n",
              "                                       context_tokenized  \\\n",
              "0      This phone has the ability to have its softwar...   \n",
              "1      This wood has the ability to fight off insects...   \n",
              "2                  Absence makes the heart grow fonder .   \n",
              "3                  Absence makes the heart grow fonder .   \n",
              "4                         He visited during my absence .   \n",
              "...                                                  ...   \n",
              "10851                                   Was that a yes ?   \n",
              "10852  Her youth and beauty is what attracted him to ...   \n",
              "10853  Make the most of your youth , it will not last...   \n",
              "10854  I made many mistakes in my youth , but learned...   \n",
              "10855  I made many mistakes in my youth , but learned...   \n",
              "\n",
              "      indexes_target_token_tokenized indexes_target_sentence_tokenized  \\\n",
              "0                                  4                              0:12   \n",
              "1                                  4                              0:19   \n",
              "2                                  0                               0:7   \n",
              "3                                  0                               0:7   \n",
              "4                                  4                               0:6   \n",
              "...                              ...                               ...   \n",
              "10851                              3                               0:5   \n",
              "10852                              1                              0:11   \n",
              "10853                              5                              0:13   \n",
              "10854                              6                              0:14   \n",
              "10855                              6                              0:14   \n",
              "\n",
              "                                      context_lemmatized  \\\n",
              "0      this phone have the ability to have its softwa...   \n",
              "1      this wood have the ability to fight off insect...   \n",
              "2                   absence make the heart grow fonder .   \n",
              "3                   absence make the heart grow fonder .   \n",
              "4                           he visit during my absence .   \n",
              "...                                                  ...   \n",
              "10851                                    be that a yes ?   \n",
              "10852   her youth and beauty be what attract he to she .   \n",
              "10853  make the most of your youth , it will not last...   \n",
              "10854  I make many mistake in my youth , but learn fr...   \n",
              "10855  I make many mistake in my youth , but learn fr...   \n",
              "\n",
              "                                             context_pos  \n",
              "0      DET NOUN VERB DET NOUN PART AUX PRON NOUN VERB...  \n",
              "1      DET NOUN VERB DET NOUN PART VERB ADP NOUN PUNC...  \n",
              "2                     NOUN VERB DET NOUN VERB NOUN PUNCT  \n",
              "3                     NOUN VERB DET NOUN VERB NOUN PUNCT  \n",
              "4                          PRON VERB ADP PRON NOUN PUNCT  \n",
              "...                                                  ...  \n",
              "10851                            AUX PRON DET INTJ PUNCT  \n",
              "10852  PRON NOUN CCONJ NOUN AUX PRON VERB PRON ADP PR...  \n",
              "10853  VERB DET ADJ ADP PRON NOUN PUNCT PRON AUX PART...  \n",
              "10854  PRON VERB ADJ NOUN ADP PRON NOUN PUNCT CCONJ V...  \n",
              "10855  PRON VERB ADJ NOUN ADP PRON NOUN PUNCT CCONJ V...  \n",
              "\n",
              "[10856 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20dab6ff-4d89-4968-84d7-d693a753189e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>date</th>\n",
              "      <th>grouping</th>\n",
              "      <th>identifier</th>\n",
              "      <th>description</th>\n",
              "      <th>context</th>\n",
              "      <th>indexes_target_token</th>\n",
              "      <th>indexes_target_sentence</th>\n",
              "      <th>context_tokenized</th>\n",
              "      <th>indexes_target_token_tokenized</th>\n",
              "      <th>indexes_target_sentence_tokenized</th>\n",
              "      <th>context_lemmatized</th>\n",
              "      <th>context_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ability</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>This phone has the ability to have its softwar...</td>\n",
              "      <td>19:26</td>\n",
              "      <td>0:69</td>\n",
              "      <td>This phone has the ability to have its softwar...</td>\n",
              "      <td>4</td>\n",
              "      <td>0:12</td>\n",
              "      <td>this phone have the ability to have its softwa...</td>\n",
              "      <td>DET NOUN VERB DET NOUN PART AUX PRON NOUN VERB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ability</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>This wood has the ability to fight off insects...</td>\n",
              "      <td>18:25</td>\n",
              "      <td>0:92</td>\n",
              "      <td>This wood has the ability to fight off insects...</td>\n",
              "      <td>4</td>\n",
              "      <td>0:19</td>\n",
              "      <td>this wood have the ability to fight off insect...</td>\n",
              "      <td>DET NOUN VERB DET NOUN PART VERB ADP NOUN PUNC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>absence</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Absence makes the heart grow fonder .</td>\n",
              "      <td>0:7</td>\n",
              "      <td>0:37</td>\n",
              "      <td>Absence makes the heart grow fonder .</td>\n",
              "      <td>0</td>\n",
              "      <td>0:7</td>\n",
              "      <td>absence make the heart grow fonder .</td>\n",
              "      <td>NOUN VERB DET NOUN VERB NOUN PUNCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>absence</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Absence makes the heart grow fonder .</td>\n",
              "      <td>0:7</td>\n",
              "      <td>0:37</td>\n",
              "      <td>Absence makes the heart grow fonder .</td>\n",
              "      <td>0</td>\n",
              "      <td>0:7</td>\n",
              "      <td>absence make the heart grow fonder .</td>\n",
              "      <td>NOUN VERB DET NOUN VERB NOUN PUNCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>absence</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>He visited during my absence .</td>\n",
              "      <td>21:28</td>\n",
              "      <td>0:30</td>\n",
              "      <td>He visited during my absence .</td>\n",
              "      <td>4</td>\n",
              "      <td>0:6</td>\n",
              "      <td>he visit during my absence .</td>\n",
              "      <td>PRON VERB ADP PRON NOUN PUNCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10851</th>\n",
              "      <td>yes</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Was that a yes ?</td>\n",
              "      <td>11:14</td>\n",
              "      <td>0:16</td>\n",
              "      <td>Was that a yes ?</td>\n",
              "      <td>3</td>\n",
              "      <td>0:5</td>\n",
              "      <td>be that a yes ?</td>\n",
              "      <td>AUX PRON DET INTJ PUNCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10852</th>\n",
              "      <td>youth</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Her youth and beauty is what attracted him to ...</td>\n",
              "      <td>4:9</td>\n",
              "      <td>0:51</td>\n",
              "      <td>Her youth and beauty is what attracted him to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0:11</td>\n",
              "      <td>her youth and beauty be what attract he to she .</td>\n",
              "      <td>PRON NOUN CCONJ NOUN AUX PRON VERB PRON ADP PR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10853</th>\n",
              "      <td>youth</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Make the most of your youth , it will not last...</td>\n",
              "      <td>22:27</td>\n",
              "      <td>0:56</td>\n",
              "      <td>Make the most of your youth , it will not last...</td>\n",
              "      <td>5</td>\n",
              "      <td>0:13</td>\n",
              "      <td>make the most of your youth , it will not last...</td>\n",
              "      <td>VERB DET ADJ ADP PRON NOUN PUNCT PRON AUX PART...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10854</th>\n",
              "      <td>youth</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>I made many mistakes in my youth , but learned...</td>\n",
              "      <td>27:32</td>\n",
              "      <td>0:62</td>\n",
              "      <td>I made many mistakes in my youth , but learned...</td>\n",
              "      <td>6</td>\n",
              "      <td>0:14</td>\n",
              "      <td>I make many mistake in my youth , but learn fr...</td>\n",
              "      <td>PRON VERB ADJ NOUN ADP PRON NOUN PUNCT CCONJ V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10855</th>\n",
              "      <td>youth</td>\n",
              "      <td>N</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>I made many mistakes in my youth , but learned...</td>\n",
              "      <td>27:32</td>\n",
              "      <td>0:62</td>\n",
              "      <td>I made many mistakes in my youth , but learned...</td>\n",
              "      <td>6</td>\n",
              "      <td>0:14</td>\n",
              "      <td>I make many mistake in my youth , but learn fr...</td>\n",
              "      <td>PRON VERB ADJ NOUN ADP PRON NOUN PUNCT CCONJ V...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10856 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20dab6ff-4d89-4968-84d7-d693a753189e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20dab6ff-4d89-4968-84d7-d693a753189e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20dab6ff-4d89-4968-84d7-d693a753189e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#c = final_df.context.tolist()"
      ],
      "metadata": {
        "id": "YpxhwSmzbh9E"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y = []\n",
        "#for m in c:\n",
        " # y.append(m.split(\" \"))"
      ],
      "metadata": {
        "id": "JfSGw06odNMb"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lengthh = []\n",
        "#for i in y:\n",
        " #   lengthh.append(len(i))"
      ],
      "metadata": {
        "id": "oHjCAMVccKuD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final_df.loc[:,'lengthh'] = lengthh"
      ],
      "metadata": {
        "id": "77G-ZeOmcQ5A"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d = final_df.context_pos.tolist()"
      ],
      "metadata": {
        "id": "iFAO6ji3ccX9"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#z = []\n",
        "#for m in d:\n",
        " # z.append(m.split(\" \"))"
      ],
      "metadata": {
        "id": "XOYe_cIAeFS7"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lengthh2 = []\n",
        "#for i in z:\n",
        " #   lengthh2.append(len(i))"
      ],
      "metadata": {
        "id": "MclqrUxycgrg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final_df.loc[:,'lengthh2'] = lengthh2"
      ],
      "metadata": {
        "id": "wacseLJ7ckfj"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CYMtdcQvWuDJ"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}
