{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QUayU6ve0s_"
      },
      "source": [
        "This notebook loads datasets of semantic proximity (Word-in-Context) for various languages the [WUG format](https://www.ims.uni-stuttgart.de/en/research/resources/experiment-data/wugs/). We provide the data in a minimal and an extended format. There are in total 4 dataframes: judgments_full, judgments_wug, uses_full and uses_wug. There are 20 transformed datasets. The notebook should run of-the-shelf in a colab environment with python 3.8. \n",
        "\n",
        "Many of the data sets are transformed when running the notebook. We cannot guarantee that there are no errors. Hence, please make sure that you compare the created data frames to the original data sets before doing serious research with them.\n",
        "\n",
        "Note: Please run this script without gpu on colab.\n",
        "\n",
        "The datasets and their versions are as follows:\n",
        "\n",
        "#RuDSI - Russian\n",
        "rudsi = 'https://github.com/kategavrishina/RuDSI/tree/main/data' \n",
        "\n",
        "#NorDiaChange - Norwegian\n",
        "nordia1 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset1/data'\n",
        "nordia2 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset2/data'\n",
        "\n",
        "#RuShiftEval - Russian\n",
        "rushifteval1 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval1/data'\n",
        "rushifteval2 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval2/data'\n",
        "rushifteval3 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval3/data'\n",
        "\n",
        "#RuSemShift - Russian\n",
        "rusemshift1 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_1/DWUG/data'\n",
        "rusemshift2 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_2/DWUG/data'\n",
        "\n",
        "#DiscoWUG - German (Version: 1.1.1)\n",
        "https://zenodo.org/record/7396225/files/discowug.zip\n",
        "\n",
        "\n",
        "\n",
        "#SURel - German (Version: 3.0.0)\n",
        "https://zenodo.org/record/5784569/files/surel.zip\n",
        "\n",
        "\n",
        "#DURel - German (Version: 3.0.0)\n",
        "https://zenodo.org/record/5784453/files/durel.zip\n",
        "\n",
        "\n",
        "#DWUG DE- German (Version: 2.3.0)\n",
        "https://zenodo.org/record/7441645/files/dwug_de.zip\n",
        "\n",
        "\n",
        "#RefWUG - German (Version: 1.1.0)\n",
        "https://zenodo.org/record/5791269/files/refwug.zip\n",
        "\n",
        "\n",
        "#DWUG EN - English (Version: 2.0.1)\n",
        "https://zenodo.org/record/7387261/files/dwug_en.zip\n",
        "\n",
        "\n",
        "#DWUG SV - Swedish(Version: 2.0.1)\n",
        "https://zenodo.org/record/7389506/files/dwug_sv.zip\n",
        "\n",
        "\n",
        "#DWUG ES - Spanish(Version: 4.0.0)\n",
        "https://zenodo.org/record/6433667/files/dwug_es.zip\n",
        "\n",
        "\n",
        "#DiaWUG - Spanish (Version: 1.1.0)\n",
        "https://zenodo.org/record/5791193/files/diawug.zip\n",
        "\n",
        "\n",
        "#DUPS_WUG - English (version 2.0.0)\n",
        "https://zenodo.org/record/5500223/files/DUPS-WUG.zip\n",
        "\n",
        "#WIC - English (version v1.0)\n",
        "https://pilehvar.github.io/wic/package/WiC_dataset.zip\n",
        "\n",
        "#TempoWIC - English\n",
        "https://codalab.lisn.upsaclay.fr/my/datasets/download/3e22f138-ca00-4b10-a0fd-2e914892200d\n",
        "\n",
        "#Raw-C - English\n",
        "https://raw.githubusercontent.com/seantrott/raw-c/main/data/processed/raw-c.csv\n",
        "\n",
        "#Usim - English\n",
        "http://www.dianamccarthy.co.uk/downloads/WordMeaningAnno2012/\n",
        "\n",
        "#CosimLex - English, Croatian, Finnish\n",
        "https://www.clarin.si/repository/xmlui/handle/11356/1308/allzip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF_EmVh_2LPF"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4IFGsLzzC5c"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Garrafao/WUGs.git #contains transformation scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xuXe6WIxrFm"
      },
      "outputs": [],
      "source": [
        "!pip install fuzzywuzzy #needed for rawc script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKUnfomtawHa"
      },
      "outputs": [],
      "source": [
        "!cd /content/WUGs/scripts/misc && bash -e usim2data.sh #transform USim to WUG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnroPHJ1HSQh"
      },
      "outputs": [],
      "source": [
        "!cd /content/WUGs/scripts/misc && bash -e evonlp2wug.sh  #transforms tempowic to wug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bliWQos0xHEB"
      },
      "outputs": [],
      "source": [
        "!python3 -m spacy download fi_core_news_sm #needed for cosimlex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAYzKbZ18jyX"
      },
      "outputs": [],
      "source": [
        "!python3 -m spacy download hr_core_news_sm #needed for cosimlex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14_KO1DSTTfW"
      },
      "outputs": [],
      "source": [
        "!cd /content/WUGs/scripts/misc && bash -e cosimlex2wug.sh #transforms cosimlex to wug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpsldp-xtTHX"
      },
      "outputs": [],
      "source": [
        "#RuDSI\n",
        "rudsi = 'https://github.com/kategavrishina/RuDSI/tree/main/data' \n",
        "\n",
        "#NorDiaChange\n",
        "nordia1 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset1/data'\n",
        "nordia2 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset2/data'\n",
        "\n",
        "#RuShiftEval\n",
        "rushifteval1 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval1/data'\n",
        "rushifteval2 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval2/data'\n",
        "rushifteval3 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval3/data'\n",
        "\n",
        "#RuSemShift\n",
        "rusemshift1 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_1/DWUG/data'\n",
        "rusemshift2 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_2/DWUG/data'\n",
        "\n",
        "#Discowug\n",
        "!wget https://zenodo.org/record/7396225/files/discowug.zip\n",
        "with ZipFile('discowug.zip', 'r') as discowug:\n",
        "    discowug.extractall()\n",
        "\n",
        "\n",
        "#surel\n",
        "!wget https://zenodo.org/record/5784569/files/surel.zip\n",
        "with ZipFile('surel.zip', 'r') as surel:\n",
        "    surel.extractall()\n",
        "\n",
        "#durel \n",
        "!wget https://zenodo.org/record/5784453/files/durel.zip\n",
        "with ZipFile('durel.zip', 'r') as durel:\n",
        "    durel.extractall()\n",
        "\n",
        "#DWUG DE\n",
        "!wget https://zenodo.org/record/7441645/files/dwug_de.zip\n",
        "with ZipFile('dwug_de.zip', 'r') as dwug_de:\n",
        "    dwug_de.extractall()\n",
        "\n",
        "#RefWUG \n",
        "!wget https://zenodo.org/record/5791269/files/refwug.zip\n",
        "with ZipFile('refwug.zip', 'r') as refwug:\n",
        "    refwug.extractall()\n",
        "\n",
        "#DWUG EN\n",
        "!wget https://zenodo.org/record/7387261/files/dwug_en.zip\n",
        "with ZipFile('dwug_en.zip', 'r') as dwug_en:\n",
        "    dwug_en.extractall()\n",
        "\n",
        "\n",
        "#DWUG SV\n",
        "!wget https://zenodo.org/record/7389506/files/dwug_sv.zip\n",
        "with ZipFile('dwug_sv.zip', 'r') as dwug_sv:\n",
        "    dwug_sv.extractall()\n",
        "\n",
        "\n",
        "#DWUG ES\n",
        "!wget https://zenodo.org/record/6433667/files/dwug_es.zip\n",
        "with ZipFile('dwug_es.zip', 'r') as dwug_es:\n",
        "    dwug_es.extractall()\n",
        "\n",
        "#DiaWUG\n",
        "!wget https://zenodo.org/record/5791193/files/diawug.zip\n",
        "with ZipFile('diawug.zip', 'r') as diawug:\n",
        "    diawug.extractall()\n",
        "\n",
        "\n",
        "#DUPS_WUG\n",
        "!wget https://zenodo.org/record/5500223/files/DUPS-WUG.zip\n",
        "with ZipFile('DUPS-WUG.zip', 'r') as dups:\n",
        "    dups.extractall()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF7x4EiZQkqm"
      },
      "outputs": [],
      "source": [
        "%run /content/WUGs/scripts/misc/wic2wug.ipynb #transforms WIC dataset to wug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXfrWc-8Pydq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9bad94-574e-4561-c7bf-05908905400e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ],
      "source": [
        "%run /content/WUGs/scripts/misc/rawc2wug.py #Raw-C to wug "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "827ot725Dqsi"
      },
      "outputs": [],
      "source": [
        "direc = []\n",
        "i = os.listdir('WUGs/scripts/misc/wugdata')\n",
        "direc.append(i)\n",
        "\n",
        "k = os.listdir('WUGs/scripts/misc/wugformat')\n",
        "direc.append(k)                                   #all data directories extracted from tempowic, cosimlex and wic\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvjO51NCDs-G"
      },
      "outputs": [],
      "source": [
        "paths = []          #list of directory paths\n",
        "for i in direc[0]:\n",
        "    paths.append('WUGs/scripts/misc/wugdata/'+i+ '/data/')     #tempowic \n",
        "\n",
        "for i in direc[1]:\n",
        "    paths.append('WUGs/scripts/misc/wugformat/'+ i + '/wug_all/data/all') #cosimlex\n",
        "\n",
        "\n",
        "paths.append('/content/WiC_data/') #wic\n",
        "\n",
        "paths.append(\"WUGs/scripts/misc/data/\")  #usim   \n",
        "paths.append(\"/content/raw-c/\") #rawc\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Osmw5w2aDyzV"
      },
      "outputs": [],
      "source": [
        "folders = []                       #list of all folders names(lemma wise) in tempowic, cosimlex, wic, usim, rawc\n",
        "for ds in paths:\n",
        "    path = os.listdir(ds)\n",
        "    folders.append(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9olDU9GNBiE"
      },
      "outputs": [],
      "source": [
        "#final list judgments paths for tempowic, cosimlex and usim\n",
        "path_j = []  \n",
        "pathco = [] \n",
        "path_usim = []                                    \n",
        "for i in folders[0]:\n",
        "     pathj = paths[0] + i + \"/judgments.csv\" #tempowic\n",
        "     path_j.append(pathj)\n",
        "for i in folders[3]:\n",
        "     pathj = paths[3] + i + \"/judgments.csv\" #tempowic\n",
        "     path_j.append(pathj)\n",
        "for i in folders[5]:\n",
        "     pathj = paths[5] + i + \"/judgments.csv\"  #tempowic\n",
        "     path_j.append(pathj)\n",
        "\n",
        "     pathj = paths[6] + \"/judgments.csv\" #cosimlex\n",
        "     pathco.append(pathj)\n",
        "\n",
        "     pathj = paths[7]  + \"/judgments.csv\" #cosimlex\n",
        "     pathco.append(pathj)\n",
        "\n",
        "     pathj = paths[8]  + \"/judgments.csv\" #cosimlex\n",
        "     pathco.append(pathj)\n",
        "\n",
        "for i in folders[10]:            #usim\n",
        "     pathj = paths[10] + i + \"/judgments.csv\"\n",
        "     path_usim.append(pathj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tsVTgfthxd_"
      },
      "outputs": [],
      "source": [
        "#final list judgments paths and dataframe for wic and rawc\n",
        "path_k = []    \n",
        "p = []                               \n",
        "for i in folders[9]:\n",
        "     pathj = paths[9] + i + \"/judgments.csv\"      #wic\n",
        "     path_k.append(pathj)\n",
        "for i in folders[11]:                             #rawc\n",
        "    pathj = paths[11] + i + \"/judgments.csv\"\n",
        "    p.append(pathj)\n",
        "#judgements dataframe for rawc and wic datasets\n",
        "wic_df = pd.DataFrame()\n",
        "rawc_df = pd.DataFrame()\n",
        "for i in path_k:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[3]\n",
        "   wic_df = pd.concat([wic_df, Tmp]) \n",
        "\n",
        "for i in p:\n",
        "  tmp_df =  pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "  tmp_df['dataset'] = i.split('/')[2]\n",
        "  rawc_df = pd.concat([rawc_df, tmp_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KFNK-euPRFC"
      },
      "outputs": [],
      "source": [
        "raw_df = pd.DataFrame\n",
        "raw_df = pd.concat([wic_df, rawc_df]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsaKLfNVie0n"
      },
      "outputs": [],
      "source": [
        "raw_df['language'] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNIMVfBORHYz"
      },
      "outputs": [],
      "source": [
        "raw_df = raw_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0hqslAHpwtH"
      },
      "outputs": [],
      "source": [
        "raw_df.loc[raw_df[\"dataset\"] == \"dev\", \"dataset\"] = 'wic_dev'\n",
        "raw_df.loc[raw_df[\"dataset\"] == \"train\", \"dataset\"] = 'wic_train'\n",
        "raw_df.loc[raw_df[\"dataset\"] == \"test\", \"dataset\"] = 'wic_test'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qqogpjk9i_L7"
      },
      "outputs": [],
      "source": [
        "cosim_df = pd.DataFrame()             #cosimlex judgments dataframe\n",
        "for i in pathco:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "   Tmp['dataset'] = i.split('/')[4]\n",
        "   cosim_df = pd.concat([cosim_df, Tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd1OD-Iaj4XL"
      },
      "outputs": [],
      "source": [
        "cosim_df.loc[cosim_df[\"dataset\"] == \"fi\", \"language\"] = 'Finnish' \n",
        "cosim_df.loc[cosim_df[\"dataset\"] == \"hr\", \"language\"] = 'Croatian'\n",
        "cosim_df.loc[cosim_df[\"dataset\"] == \"en\", \"language\"] = 'English'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fby7eMoxqgIW"
      },
      "outputs": [],
      "source": [
        "cosim_df.loc[cosim_df[\"language\"] == \"Finnish\", \"dataset\"] = 'Cosimlex_fi' \n",
        "cosim_df.loc[cosim_df[\"language\"] == \"Croatian\", \"dataset\"] = 'Cosimlex_hr'\n",
        "cosim_df.loc[cosim_df[\"language\"] == \"English\", \"dataset\"] = 'Cosimlex_en'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVAuxcM7kPXU"
      },
      "outputs": [],
      "source": [
        "#cosim_df['dataset'] = 'Cosimlex'\n",
        "cosim_df = cosim_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_usim.remove('WUGs/scripts/misc/data/dwug_en/judgments.csv')"
      ],
      "metadata": {
        "id": "ZRf-WIQMqinb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBLRXjJ4Rlzr"
      },
      "outputs": [],
      "source": [
        "judge_df = pd.DataFrame()  \n",
        "jud_df =  pd.DataFrame()                 #judgments dataframe for tempowic and usim \n",
        "for i in path_j:\n",
        "    Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "    Tmp['dataset'] = i.split('/')[4]\n",
        "    judge_df = pd.concat([judge_df, Tmp])\n",
        "\n",
        "for i in path_usim:\n",
        "    Temp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "    Temp['dataset'] = i.split('/')[3]\n",
        "    jud_df = pd.concat([jud_df, Temp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfGknHOMsFgC"
      },
      "outputs": [],
      "source": [
        "judgemt_df = pd.DataFrame()\n",
        "judgemt_df = pd.concat([judge_df, jud_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlwvRygXGHf5"
      },
      "outputs": [],
      "source": [
        "judgemt_df.loc[judgemt_df[\"dataset\"] == \"data\", \"dataset\"] = 'USim'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7nT8nomIPCN"
      },
      "outputs": [],
      "source": [
        "judgemt_df.loc[judgemt_df[\"dataset\"] == \"TempoWic\", \"language\"] = 'English'\n",
        "judgemt_df.loc[judgemt_df[\"dataset\"] == \"USim\", \"language\"] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKsGR7HDFxSL"
      },
      "outputs": [],
      "source": [
        "judgemt_df = judgemt_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gxu63ay6fntu"
      },
      "outputs": [],
      "source": [
        "dwugde = \"dwug_de/data\"                          #WUG data directory paths\n",
        "dwugen = \"dwug_en/data\"\n",
        "dwugsv = \"dwug_sv/data\"\n",
        "discowugg = \"discowug/data\"\n",
        "durel = \"durel/data\"\n",
        "surel = \"surel/data\"\n",
        "refwug = \"refwug/data\"\n",
        "dwuges = 'dwug_es/data'\n",
        "diawug = 'diawug/data'\n",
        "dups = 'DUPS-WUG/data'\n",
        "dupswug = ''\n",
        "dwug = [dwugde, dwugen,dwugsv,discowugg, durel, surel, refwug, dwuges, diawug, dups]\n",
        "dirlist = []\n",
        "for dataset in dwug:\n",
        "  dir = os.listdir(dataset)\n",
        "  dirlist.append(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt41rHU53UQU"
      },
      "outputs": [],
      "source": [
        "dwug_j = []                                                #dwug data paths\n",
        "for i in dirlist[0]:\n",
        "  dwugde_j = \"dwug_de/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwugde_j)\n",
        "for i in dirlist[1]:\n",
        "  dwugen_j = \"dwug_en/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwugen_j)\n",
        "for i in dirlist[2]:\n",
        "  dwugsv_j = \"dwug_sv/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwugsv_j)\n",
        "for i in dirlist[3]:\n",
        "  discowugg_j = \"discowug/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(discowugg_j)\n",
        "for i in dirlist[4]:\n",
        "  durel_j = \"durel/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(durel_j)\n",
        "for i in dirlist[5]:\n",
        "  surel_j = \"surel/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(surel_j)  \n",
        "for i in dirlist[6]:\n",
        "  refwug_j = \"refwug/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(refwug_j)\n",
        "for i in dirlist[7]:\n",
        "  dwuges_j = \"dwug_es/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwuges_j)\n",
        "for i in dirlist[8]:\n",
        "  diawug_j = \"diawug/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(diawug_j)\n",
        "for i in dirlist[9]:\n",
        "  dups_j = \"DUPS-WUG/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dups_j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40oRLVLdYXTR"
      },
      "outputs": [],
      "source": [
        "judgemnt_df = pd.DataFrame()            #dwug data judgments df\n",
        "for i in dwug_j:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[0]\n",
        "   judgemnt_df = pd.concat([judgemnt_df, Tmp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuKrc5P7NF6P"
      },
      "outputs": [],
      "source": [
        "path_u = []   \n",
        "path_us = []                   #uses paths for tempowic and usim\n",
        "for i in folders[0]:\n",
        "    pathj = paths[0] + i + \"/uses.csv\"    #tempowic\n",
        "    path_u.append(pathj)\n",
        "for i in folders[3]:\n",
        "    pathj = paths[3] + i + \"/uses.csv\"     #tempowic\n",
        "    path_u.append(pathj)\n",
        "for i in folders[4]:\n",
        "    pathj = paths[4] + i + \"/uses.csv\"     #tempowic\n",
        "    path_u.append(pathj)\n",
        "for i in folders[10]:\n",
        "     pathj = paths[10] + i + \"/uses.csv\"   #usim\n",
        "     path_us.append(pathj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfcQ_x25mOWy"
      },
      "outputs": [],
      "source": [
        "path_cou = []                               #for cosimlex uses paths\n",
        "for i in folders[6]:\n",
        "    pathj = paths[6] + \"/uses.csv\"\n",
        "    path_cou.append(pathj)\n",
        "for i in folders[7]:\n",
        "    pathj = paths[7] + \"/uses.csv\"\n",
        "    path_cou.append(pathj)\n",
        "for i in folders[8]:\n",
        "    pathj = paths[8] +  \"/uses.csv\"\n",
        "    path_cou.append(pathj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FtNPXSvmaUg"
      },
      "outputs": [],
      "source": [
        "cosim_uses_df = pd.DataFrame()            #cosimlex uses df\n",
        "for i in path_cou:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[4]\n",
        "   cosim_uses_df = pd.concat([cosim_uses_df, Tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhJFx09em6yB"
      },
      "outputs": [],
      "source": [
        "cosim_uses_df.loc[cosim_uses_df[\"dataset\"] == \"fi\", \"language\"] = 'Finnish' \n",
        "cosim_uses_df.loc[cosim_uses_df[\"dataset\"] == \"hr\", \"language\"] = 'Croatian'\n",
        "cosim_uses_df.loc[cosim_uses_df[\"dataset\"] == \"en\", \"language\"] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fR4F56QSvGJ2"
      },
      "outputs": [],
      "source": [
        "cosim_uses_df.loc[cosim_uses_df[\"language\"] == \"Finnish\", \"dataset\"] = 'Cosimlex_fi' \n",
        "cosim_uses_df.loc[cosim_uses_df[\"language\"] == \"Croatian\", \"dataset\"] = 'Cosimlex_hr'\n",
        "cosim_uses_df.loc[cosim_uses_df[\"language\"] == \"English\", \"dataset\"] = 'Cosimlex_en'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfTftRhQnQVR"
      },
      "outputs": [],
      "source": [
        "#cosim_uses_df['dataset'] = 'Cosimlex'\n",
        "cosim_uses_df = cosim_uses_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkjXw4ganXqu"
      },
      "outputs": [],
      "source": [
        "path_k = []   \n",
        "path_r = []                         #wic and rawc uses df\n",
        "for i in folders[9]:\n",
        "    pathj = paths[9] + i + \"/uses.csv\" #wic\n",
        "    path_k.append(pathj)\n",
        "for i in folders[11]:\n",
        "    pathj = paths[11] + i + \"/uses.csv\" #rawc\n",
        "    path_r.append(pathj)\n",
        "raw_u_df = pd.DataFrame()\n",
        "raw_us_df = pd.DataFrame()\n",
        "for i in path_k:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[3]\n",
        "   raw_u_df = pd.concat([raw_u_df, Tmp]) \n",
        "\n",
        "for i in path_r:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[2]\n",
        "   raw_us_df = pd.concat([raw_us_df, Tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0MiXU51wI1L"
      },
      "outputs": [],
      "source": [
        "raw_uses_df = pd.DataFrame()\n",
        "raw_uses_df = pd.concat([raw_u_df, raw_us_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1D38jh9nkkE"
      },
      "outputs": [],
      "source": [
        "raw_uses_df['language'] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KxwYgGMw5w7"
      },
      "outputs": [],
      "source": [
        "raw_uses_df.loc[raw_uses_df[\"dataset\"] == \"dev\", \"dataset\"] = 'wic_dev'\n",
        "raw_uses_df.loc[raw_uses_df[\"dataset\"] == \"train\", \"dataset\"] = 'wic_train'\n",
        "raw_uses_df.loc[raw_uses_df[\"dataset\"] == \"test\", \"dataset\"] = 'wic_test'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_us.remove(\"WUGs/scripts/misc/data/dwug_en/uses.csv\")"
      ],
      "metadata": {
        "id": "-1lIJGtjrM8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcs1Wy1In-Cl"
      },
      "outputs": [],
      "source": [
        "u_df = pd.DataFrame()  \n",
        "ud_df =  pd.DataFrame()                 #uses dataframe for tempowic and usim \n",
        "for i in path_u:\n",
        "    Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "    Tmp['dataset'] = i.split('/')[4]\n",
        "    u_df = pd.concat([u_df, Tmp])\n",
        "\n",
        "for i in path_us:\n",
        "    Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "    Tmp['dataset'] = i.split('/')[3]\n",
        "    ud_df = pd.concat([ud_df, Tmp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMbpHFNpyL37"
      },
      "outputs": [],
      "source": [
        "use_df = pd.DataFrame()\n",
        "use_df = pd.concat([u_df, ud_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKtzLYAoKE2S"
      },
      "outputs": [],
      "source": [
        "#use_df.loc[use_df[\"dataset\"] == \"wugdata\", \"dataset\"] = 'TempoWic'\n",
        "use_df.loc[use_df[\"dataset\"] == \"data\", \"dataset\"] = 'USim'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygJMtiIkKmr2"
      },
      "outputs": [],
      "source": [
        "use_df['language'] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH1zLd2M6r3i"
      },
      "outputs": [],
      "source": [
        "dwug_u = []                                           #dwug data uses paths\n",
        "for i in dirlist[0]:\n",
        "  dwugde_u = \"dwug_de/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwugde_u)\n",
        "for i in dirlist[1]:\n",
        "  dwugen_u = \"dwug_en/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwugen_u)\n",
        "for i in dirlist[2]:\n",
        "  dwugsv_u = \"dwug_sv/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwugsv_u)\n",
        "for i in dirlist[3]:\n",
        "  discowugg_u = \"discowug/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(discowugg_u)\n",
        "for i in dirlist[4]:\n",
        "  durel_u = \"durel/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(durel_u)\n",
        "for i in dirlist[5]:\n",
        "  surel_u = \"surel/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(surel_u)  \n",
        "for i in dirlist[6]:\n",
        "  refwug_u = \"refwug/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(refwug_u)\n",
        "for i in dirlist[7]:\n",
        "  dwuges_u = \"dwug_es/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwuges_u)\n",
        "for i in dirlist[8]:\n",
        "  diawug_u = \"diawug/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(diawug_u)\n",
        "\n",
        "for i in dirlist[9]:\n",
        "  dups_u = \"DUPS-WUG/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dups_u)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i1SnqaGleIR"
      },
      "outputs": [],
      "source": [
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_de\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_en\", \"language\"] = 'English'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"DUPS-WUG\", \"language\"] = 'English'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_es\", \"language\"] = 'Spanish'\n",
        "#judgemnt_df.loc[judgemnt_df[\"name\"] == \"dwug_la\", \"language\"] = 'latin'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_sv\", \"language\"] = 'Swedish'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"durel\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"surel\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"discowug\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"refwug\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"diawug\", \"language\"] = 'Spanish'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q89I4-6qMxrm"
      },
      "outputs": [],
      "source": [
        "#final judgments df (without russian and norwegian datasets)\n",
        "judgment_df = pd.DataFrame()\n",
        "judgment_df = pd.concat([judgment_df, judgemt_df], axis = 0)\n",
        "judgment_df = pd.concat([judgment_df, judgemnt_df], axis = 0)    \n",
        "judgment_df = pd.concat([judgment_df, raw_df], axis = 0)\n",
        "judgment_df = pd.concat([judgment_df, cosim_df], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2OPKvW_LrXW"
      },
      "outputs": [],
      "source": [
        "judgment_df = judgment_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5UNk2kXD2oU"
      },
      "outputs": [],
      "source": [
        "usee_df = pd.DataFrame()            #uses dwug df\n",
        "for i in dwug_u:\n",
        "    Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "    Tmp['dataset'] = i.split('/')[0]\n",
        "    usee_df = pd.concat([usee_df, Tmp])\n",
        "    usee_df = pd.concat([usee_df, pd.read_csv(i, delimiter='\\t', quoting = 3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Swq_wL0BpUYf"
      },
      "outputs": [],
      "source": [
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_de\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_en\", \"language\"] = 'English'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"DUPS-WUG\", \"language\"] = 'English'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_es\", \"language\"] = 'Spanish'\n",
        "#usee_df.loc[usee_df[\"dataset\"] == \"dwug_la\", \"language\"] = 'latin'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_sv\", \"language\"] = 'Swedish'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"durel\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"surel\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"discowug\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"refwug\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"diawug\", \"language\"] = 'Spanish'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8ZyibHeoYaS"
      },
      "outputs": [],
      "source": [
        "#combining uses df\n",
        "uses_full_df = pd.concat([usee_df, use_df], axis = 0)\n",
        "uses1_df = pd.concat([uses_full_df, raw_uses_df], axis = 0)\n",
        "uses_df_full = pd.concat([uses1_df, cosim_uses_df], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Hs9BgeUHPxZ"
      },
      "outputs": [],
      "source": [
        "#getting the data \n",
        "russian = [rudsi, nordia1, nordia2, rushifteval1, rushifteval2, rushifteval3, rusemshift1, rusemshift2]\n",
        "find_class = []\n",
        "for URL in russian:\n",
        "  page = requests.get(URL)\n",
        "  soup = BeautifulSoup( page.content , 'html.parser')\n",
        "  classy = soup.find_all('a', class_=\"Link--primary\")[3:]\n",
        "  find_class.append(classy)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTjddnWNuE1o"
      },
      "outputs": [],
      "source": [
        "judgements = []\n",
        "uses = []\n",
        "for find_by_class in find_class:\n",
        "  for i in find_by_class:\n",
        "    judgements.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/judgments.csv\")\n",
        "    uses.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/uses.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DuRGR6jrfD2"
      },
      "outputs": [],
      "source": [
        "#judgments dataframe for rudsi, rusemshift, rushifteval, nordiachange\n",
        "judgements_df = pd.DataFrame()\n",
        "for i in judgements:\n",
        "   Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "   Tmp['dataset'] = i.split('/')[5]\n",
        "   judgements_df = pd.concat([judgements_df, Tmp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEcwGGWLKxP1"
      },
      "outputs": [],
      "source": [
        "judgements_df[\"language\"] = \"Russian\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyKbDqb-q_hK"
      },
      "outputs": [],
      "source": [
        "judgements_df.loc[judgements_df[\"dataset\"] == \"NorDiaChange\", \"language\"] = 'Norwegian'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhhOvgn30FtZ"
      },
      "outputs": [],
      "source": [
        "#uses dataframe for rudsi, rusemshift, rushifteval, nordiachange\n",
        "usees_df = pd.DataFrame()\n",
        "for i in uses:\n",
        "    Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "    Tmp['dataset'] = i.split('/')[5]\n",
        "    usees_df = pd.concat([usees_df, Tmp])\n",
        "   \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikn0jHLOtY35"
      },
      "outputs": [],
      "source": [
        "usees_df['language'] = 'Russian'\n",
        "usees_df.loc[usees_df[\"dataset\"] == \"NorDiaChange\", \"language\"] = 'Norwegian'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS__0wkBdjfP"
      },
      "outputs": [],
      "source": [
        "#final judgments dataframe full format\n",
        "judgments_full = pd.concat([judgment_df, judgements_df], axis = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxBZ18nA7Ky2"
      },
      "outputs": [],
      "source": [
        "#final uses dataframe full format\n",
        "uses_full = pd.concat([uses_df_full, usees_df], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DWumP4cKuFn"
      },
      "outputs": [],
      "source": [
        "#resetting the index of uses and judgments dataframes because they have repeated indices\n",
        "judgments_full = judgments_full.reset_index(drop= True)\n",
        "uses_full = uses_full.reset_index(drop= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeUvy7OHvdby"
      },
      "outputs": [],
      "source": [
        "#final uses and judgments in wug format\n",
        "judgments_wug = judgments_full[[\"identifier1\", \"identifier2\", \"annotator\", \"judgment\", \"comment\", \"lemma\", \"dataset\", \"language\"]]\n",
        "uses_wug= uses_full[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'dataset', 'language']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haNL38ua-_S4"
      },
      "outputs": [],
      "source": [
        "for i in list(judgments_wug[\"dataset\"].value_counts().index):\n",
        "    df_temp = judgments_wug[judgments_wug[\"dataset\"]==i]\n",
        "    if not os.path.exists(i):\n",
        "        os.mkdir(i)\n",
        "    df_temp.to_csv(i +'/judgments.csv',index = False, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, quotechar = '')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(uses_wug[\"dataset\"].value_counts().index):\n",
        "    df_temp = uses_wug[uses_wug[\"dataset\"]==i]\n",
        "    if not os.path.exists(i):\n",
        "        os.mkdir(i)\n",
        "    df_temp.to_csv(i +'/uses.csv',index = False, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, quotechar = '')"
      ],
      "metadata": {
        "id": "GJmYL2apO58c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(judgments_full[\"dataset\"].value_counts().index):\n",
        "    df_temp = judgments_full[judgments_full[\"dataset\"]==i]\n",
        "    if not os.path.exists(i):\n",
        "        os.mkdir(i)\n",
        "    df_temp.to_csv(i +'/judgments.csv',index = False, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, quotechar = '')"
      ],
      "metadata": {
        "id": "PnwBHYwfPD6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(uses_full[\"dataset\"].value_counts().index):\n",
        "    df_temp = uses_full[uses_full[\"dataset\"]==i]\n",
        "    if not os.path.exists(i):\n",
        "        os.mkdir(i)\n",
        "    df_temp.to_csv(i +'/uses.csv',index = False, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, quotechar = '')"
      ],
      "metadata": {
        "id": "7XD6tea3PKlM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}