{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Garrafao/WUGs/blob/main/scripts/misc/one_for_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QUayU6ve0s_"
      },
      "source": [
        "This notebook loads datasets of semantic proximity (Word-in-Context) for various languages the [WUG format](https://www.ims.uni-stuttgart.de/en/research/resources/experiment-data/wugs/). We provide the data in a minimal and an extended format. There are in total 4 dataframes: judgments_full, judgments_wug, uses_full and uses_wug. There are 20 transformed datasets. The notebook should run of-the-shelf in a colab environment with python 3.8.\n",
        "\n",
        "Many of the data sets are transformed when running the notebook. We cannot guarantee that there are no errors. Hence, please make sure that you compare the created data frames to the original data sets before doing serious research with them.\n",
        "\n",
        "Note: Please run this script without gpu on colab.\n",
        "\n",
        "The datasets and their versions are as follows:\n",
        "\n",
        "#RuDSI - Russian\n",
        "rudsi = 'https://github.com/kategavrishina/RuDSI/tree/main/data'\n",
        "\n",
        "#NorDiaChange - Norwegian\n",
        "nordia1 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset1/data'\n",
        "nordia2 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset2/data'\n",
        "\n",
        "#RuShiftEval - Russian\n",
        "rushifteval1 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval1/data'\n",
        "rushifteval2 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval2/data'\n",
        "rushifteval3 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval3/data'\n",
        "\n",
        "#RuSemShift - Russian\n",
        "rusemshift1 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_1/DWUG/data'\n",
        "rusemshift2 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_2/DWUG/data'\n",
        "\n",
        "#DiscoWUG - German (Version: 1.1.1)\n",
        "https://zenodo.org/record/7396225/files/discowug.zip\n",
        "\n",
        "\n",
        "\n",
        "#SURel - German (Version: 3.0.0)\n",
        "https://zenodo.org/record/5784569/files/surel.zip\n",
        "\n",
        "\n",
        "#DURel - German (Version: 3.0.0)\n",
        "https://zenodo.org/record/5784453/files/durel.zip\n",
        "\n",
        "\n",
        "#DWUG DE- German (Version: 2.3.0)\n",
        "https://zenodo.org/record/7441645/files/dwug_de.zip\n",
        "\n",
        "\n",
        "#RefWUG - German (Version: 1.1.0)\n",
        "https://zenodo.org/record/5791269/files/refwug.zip\n",
        "\n",
        "\n",
        "#DWUG EN - English (Version: 2.0.1)\n",
        "https://zenodo.org/record/7387261/files/dwug_en.zip\n",
        "\n",
        "\n",
        "#DWUG SV - Swedish(Version: 2.0.1)\n",
        "https://zenodo.org/record/7389506/files/dwug_sv.zip\n",
        "\n",
        "\n",
        "#DWUG ES - Spanish(Version: 4.0.0)\n",
        "https://zenodo.org/record/6433667/files/dwug_es.zip\n",
        "\n",
        "\n",
        "#DiaWUG - Spanish (Version: 1.1.0)\n",
        "https://zenodo.org/record/5791193/files/diawug.zip\n",
        "\n",
        "\n",
        "#DUPS_WUG - English (version 2.0.0)\n",
        "https://zenodo.org/record/5500223/files/DUPS-WUG.zip\n",
        "\n",
        "#WIC - English (version v1.0)\n",
        "https://pilehvar.github.io/wic/package/WiC_dataset.zip\n",
        "\n",
        "#TempoWIC - English\n",
        "https://codalab.lisn.upsaclay.fr/my/datasets/download/3e22f138-ca00-4b10-a0fd-2e914892200d\n",
        "\n",
        "#Raw-C - English\n",
        "https://raw.githubusercontent.com/seantrott/raw-c/main/data/processed/raw-c.csv\n",
        "\n",
        "#Usim - English\n",
        "http://www.dianamccarthy.co.uk/downloads/WordMeaningAnno2012/\n",
        "\n",
        "#CosimLex - English, Croatian, Finnish\n",
        "https://www.clarin.si/repository/xmlui/handle/11356/1308/allzip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "DF_EmVh_2LPF"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "W4IFGsLzzC5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c3b9a05-44b8-4420-ac48-431092fd24cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'WUGs' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Garrafao/WUGs.git #contains transformation scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "2xuXe6WIxrFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fdb2411-1855-4422-fa41-73cabcff36d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (0.18.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy #needed for rawc script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKUnfomtawHa"
      },
      "outputs": [],
      "source": [
        "!cd /content/WUGs/scripts/misc && bash -e usim2data.sh #transform USim to WUG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnroPHJ1HSQh"
      },
      "outputs": [],
      "source": [
        "!cd /content/WUGs/scripts/misc && bash -e evonlp2wug.sh  #transforms tempowic to wug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bliWQos0xHEB"
      },
      "outputs": [],
      "source": [
        "!python3 -m spacy download fi_core_news_sm #needed for cosimlex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAYzKbZ18jyX"
      },
      "outputs": [],
      "source": [
        "!python3 -m spacy download hr_core_news_sm #needed for cosimlex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14_KO1DSTTfW"
      },
      "outputs": [],
      "source": [
        "!cd /content/WUGs/scripts/misc && bash -e cosimlex2wug.sh #transforms cosimlex to wug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpsldp-xtTHX"
      },
      "outputs": [],
      "source": [
        "#RuDSI\n",
        "rudsi = 'https://github.com/kategavrishina/RuDSI/tree/main/data'\n",
        "\n",
        "#NorDiaChange\n",
        "nordia1 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset1/data'\n",
        "nordia2 = 'https://github.com/ltgoslo/nor_dia_change/tree/main/subset2/data'\n",
        "\n",
        "#RuShiftEval\n",
        "rushifteval1 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval1/data'\n",
        "rushifteval2 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval2/data'\n",
        "rushifteval3 = 'https://github.com/akutuzov/rushifteval_public/tree/main/durel/rushifteval3/data'\n",
        "\n",
        "#RuSemShift\n",
        "rusemshift1 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_1/DWUG/data'\n",
        "rusemshift2 = 'https://github.com/juliarodina/RuSemShift/tree/master/rusemshift_2/DWUG/data'\n",
        "\n",
        "#Discowug\n",
        "!wget https://zenodo.org/record/7396225/files/discowug.zip\n",
        "with ZipFile('discowug.zip', 'r') as discowug:\n",
        "    discowug.extractall()\n",
        "\n",
        "\n",
        "#surel\n",
        "!wget https://zenodo.org/record/5784569/files/surel.zip\n",
        "with ZipFile('surel.zip', 'r') as surel:\n",
        "    surel.extractall()\n",
        "\n",
        "#durel\n",
        "!wget https://zenodo.org/record/5784453/files/durel.zip\n",
        "with ZipFile('durel.zip', 'r') as durel:\n",
        "    durel.extractall()\n",
        "\n",
        "#DWUG DE\n",
        "!wget https://zenodo.org/record/7441645/files/dwug_de.zip\n",
        "with ZipFile('dwug_de.zip', 'r') as dwug_de:\n",
        "    dwug_de.extractall()\n",
        "\n",
        "#RefWUG\n",
        "!wget https://zenodo.org/record/5791269/files/refwug.zip\n",
        "with ZipFile('refwug.zip', 'r') as refwug:\n",
        "    refwug.extractall()\n",
        "\n",
        "#DWUG EN\n",
        "!wget https://zenodo.org/record/7387261/files/dwug_en.zip\n",
        "with ZipFile('dwug_en.zip', 'r') as dwug_en:\n",
        "    dwug_en.extractall()\n",
        "\n",
        "\n",
        "#DWUG SV\n",
        "!wget https://zenodo.org/record/7389506/files/dwug_sv.zip\n",
        "with ZipFile('dwug_sv.zip', 'r') as dwug_sv:\n",
        "    dwug_sv.extractall()\n",
        "\n",
        "\n",
        "#DWUG ES\n",
        "!wget https://zenodo.org/record/6433667/files/dwug_es.zip\n",
        "with ZipFile('dwug_es.zip', 'r') as dwug_es:\n",
        "    dwug_es.extractall()\n",
        "\n",
        "#DiaWUG\n",
        "!wget https://zenodo.org/record/5791193/files/diawug.zip\n",
        "with ZipFile('diawug.zip', 'r') as diawug:\n",
        "    diawug.extractall()\n",
        "\n",
        "\n",
        "#DUPS_WUG\n",
        "!wget https://zenodo.org/record/5500223/files/DUPS-WUG.zip\n",
        "with ZipFile('DUPS-WUG.zip', 'r') as dups:\n",
        "    dups.extractall()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF7x4EiZQkqm"
      },
      "outputs": [],
      "source": [
        "%run /content/WUGs/scripts/misc/wic2wug.ipynb #transforms WIC dataset to wug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "VXfrWc-8Pydq"
      },
      "outputs": [],
      "source": [
        "%run /content/WUGs/scripts/misc/rawc2wug.py #Raw-C to wug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "827ot725Dqsi"
      },
      "outputs": [],
      "source": [
        "direc = []\n",
        "i = os.listdir('WUGs/scripts/misc/wugdata')\n",
        "direc.append(i)\n",
        "\n",
        "k = os.listdir('WUGs/scripts/misc/wugformat')\n",
        "direc.append(k)                                   #all data directories extracted from tempowic, cosimlex and wic\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "wvjO51NCDs-G"
      },
      "outputs": [],
      "source": [
        "paths = []          #list of directory paths\n",
        "for i in direc[0]:\n",
        "    paths.append('WUGs/scripts/misc/wugdata/'+i+ '/data/')     #tempowic\n",
        "\n",
        "for i in direc[1]:\n",
        "    paths.append('WUGs/scripts/misc/wugformat/'+ i + '/wug_all/data/all') #cosimlex\n",
        "\n",
        "\n",
        "paths.append('/content/WiC_data/') #wic\n",
        "\n",
        "paths.append(\"WUGs/scripts/misc/data/\")  #usim\n",
        "paths.append(\"/content/raw-c/\") #rawc\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "Osmw5w2aDyzV"
      },
      "outputs": [],
      "source": [
        "folders = []                       #list of all folders names(lemma wise) in tempowic, cosimlex, wic, usim, rawc\n",
        "for ds in paths:\n",
        "    path = os.listdir(ds)\n",
        "    folders.append(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "-9olDU9GNBiE"
      },
      "outputs": [],
      "source": [
        "#final list judgments paths for tempowic, cosimlex and usim\n",
        "path_j = []\n",
        "\n",
        "path_usim = []\n",
        "for i in folders[0]:\n",
        "     pathj = paths[0] + i + \"/judgments.csv\" #tempowic\n",
        "     path_j.append(pathj)\n",
        "for i in folders[3]:\n",
        "     pathj = paths[3] + i + \"/judgments.csv\" #tempowic\n",
        "     path_j.append(pathj)\n",
        "for i in folders[5]:\n",
        "     pathj = paths[5] + i + \"/judgments.csv\"  #tempowic\n",
        "     path_j.append(pathj)\n",
        "\n",
        "for i in folders[10]:            #usim\n",
        "     pathj = paths[10] + i + \"/judgments.csv\"\n",
        "     path_usim.append(pathj)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pathco = []\n",
        "pat = paths[6] + \"/judgments.csv\" #cosimlex\n",
        "pathco.append(pat)\n",
        "\n",
        "pat = paths[7]  + \"/judgments.csv\" #cosimlex\n",
        "pathco.append(pat)\n",
        "\n",
        "pathj = paths[8]  + \"/judgments.csv\" #cosimlex\n",
        "pathco.append(pat)\n"
      ],
      "metadata": {
        "id": "6xUP3Dnzcdmx"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "5tsVTgfthxd_"
      },
      "outputs": [],
      "source": [
        "#final list judgments paths and dataframe for wic and rawc\n",
        "path_k = []\n",
        "p = []\n",
        "for i in folders[9]:\n",
        "     pathj = paths[9] + i + \"/judgments.csv\"      #wic\n",
        "     path_k.append(pathj)\n",
        "for i in folders[11]:                             #rawc\n",
        "    pathj = paths[11] + i + \"/judgments.csv\"\n",
        "    p.append(pathj)\n",
        "#judgements dataframe for rawc and wic datasets\n",
        "wic_df = pd.DataFrame()\n",
        "rawc_df = pd.DataFrame()\n",
        "for i in path_k:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[3]\n",
        "   wic_df = pd.concat([wic_df, Tmp])\n",
        "\n",
        "for i in p:\n",
        "  tmp_df =  pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "  tmp_df['dataset'] = i.split('/')[2]\n",
        "  rawc_df = pd.concat([rawc_df, tmp_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "7KFNK-euPRFC"
      },
      "outputs": [],
      "source": [
        "raw_df = pd.DataFrame\n",
        "raw_df = pd.concat([wic_df, rawc_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "vsaKLfNVie0n"
      },
      "outputs": [],
      "source": [
        "raw_df['language'] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "oNIMVfBORHYz"
      },
      "outputs": [],
      "source": [
        "raw_df = raw_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "_0hqslAHpwtH"
      },
      "outputs": [],
      "source": [
        "raw_df.loc[raw_df[\"dataset\"] == \"dev\", \"dataset\"] = 'wic_dev'\n",
        "raw_df.loc[raw_df[\"dataset\"] == \"train\", \"dataset\"] = 'wic_train'\n",
        "raw_df.loc[raw_df[\"dataset\"] == \"test\", \"dataset\"] = 'wic_test'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "Qqogpjk9i_L7"
      },
      "outputs": [],
      "source": [
        "cosim_df = pd.DataFrame()             #cosimlex judgments dataframe\n",
        "for i in pathco:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "   Tmp['dataset'] = i.split('/')[4]\n",
        "   cosim_df = pd.concat([cosim_df, Tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "Jd1OD-Iaj4XL"
      },
      "outputs": [],
      "source": [
        "cosim_df.loc[cosim_df[\"dataset\"] == \"fi\", \"language\"] = 'Finnish'\n",
        "cosim_df.loc[cosim_df[\"dataset\"] == \"hr\", \"language\"] = 'Croatian'\n",
        "cosim_df.loc[cosim_df[\"dataset\"] == \"en\", \"language\"] = 'English'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "fby7eMoxqgIW"
      },
      "outputs": [],
      "source": [
        "cosim_df.loc[cosim_df[\"language\"] == \"Finnish\", \"dataset\"] = 'Cosimlex_fi'\n",
        "cosim_df.loc[cosim_df[\"language\"] == \"Croatian\", \"dataset\"] = 'Cosimlex_hr'\n",
        "cosim_df.loc[cosim_df[\"language\"] == \"English\", \"dataset\"] = 'Cosimlex_en'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "IVAuxcM7kPXU"
      },
      "outputs": [],
      "source": [
        "#cosim_df['dataset'] = 'Cosimlex'\n",
        "cosim_df = cosim_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_usim.remove('WUGs/scripts/misc/data/dwug_en/judgments.csv')"
      ],
      "metadata": {
        "id": "ZRf-WIQMqinb"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "FBLRXjJ4Rlzr"
      },
      "outputs": [],
      "source": [
        "judge_df = pd.DataFrame()\n",
        "jud_df =  pd.DataFrame()                 #judgments dataframe for tempowic and usim\n",
        "for i in path_j:\n",
        "    Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "    Tmp['dataset'] = i.split('/')[4]\n",
        "    judge_df = pd.concat([judge_df, Tmp])\n",
        "\n",
        "for i in path_usim:\n",
        "    Temp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "    Temp['dataset'] = i.split('/')[3]\n",
        "    jud_df = pd.concat([jud_df, Temp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "PfGknHOMsFgC"
      },
      "outputs": [],
      "source": [
        "judgemt_df = pd.DataFrame()\n",
        "judgemt_df = pd.concat([judge_df, jud_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "xlwvRygXGHf5"
      },
      "outputs": [],
      "source": [
        "judgemt_df.loc[judgemt_df[\"dataset\"] == \"data\", \"dataset\"] = 'USim'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "H7nT8nomIPCN"
      },
      "outputs": [],
      "source": [
        "judgemt_df.loc[judgemt_df[\"dataset\"] == \"TempoWic\", \"language\"] = 'English'\n",
        "judgemt_df.loc[judgemt_df[\"dataset\"] == \"USim\", \"language\"] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "sKsGR7HDFxSL"
      },
      "outputs": [],
      "source": [
        "judgemt_df = judgemt_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "Gxu63ay6fntu"
      },
      "outputs": [],
      "source": [
        "dwugde = \"dwug_de/data\"                          #WUG data directory paths\n",
        "dwugen = \"dwug_en/data\"\n",
        "dwugsv = \"dwug_sv/data\"\n",
        "discowugg = \"discowug/data\"\n",
        "durel = \"durel/data\"\n",
        "surel = \"surel/data\"\n",
        "refwug = \"refwug/data\"\n",
        "dwuges = 'dwug_es/data'\n",
        "diawug = 'diawug/data'\n",
        "dups = 'DUPS-WUG/data'\n",
        "dupswug = ''\n",
        "dwug = [dwugde, dwugen,dwugsv,discowugg, durel, surel, refwug, dwuges, diawug, dups]\n",
        "dirlist = []\n",
        "for dataset in dwug:\n",
        "  dir = os.listdir(dataset)\n",
        "  dirlist.append(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "wt41rHU53UQU"
      },
      "outputs": [],
      "source": [
        "dwug_j = []                                                #dwug data paths\n",
        "for i in dirlist[0]:\n",
        "  dwugde_j = \"dwug_de/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwugde_j)\n",
        "for i in dirlist[1]:\n",
        "  dwugen_j = \"dwug_en/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwugen_j)\n",
        "for i in dirlist[2]:\n",
        "  dwugsv_j = \"dwug_sv/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwugsv_j)\n",
        "for i in dirlist[3]:\n",
        "  discowugg_j = \"discowug/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(discowugg_j)\n",
        "for i in dirlist[4]:\n",
        "  durel_j = \"durel/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(durel_j)\n",
        "for i in dirlist[5]:\n",
        "  surel_j = \"surel/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(surel_j)\n",
        "for i in dirlist[6]:\n",
        "  refwug_j = \"refwug/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(refwug_j)\n",
        "for i in dirlist[7]:\n",
        "  dwuges_j = \"dwug_es/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dwuges_j)\n",
        "for i in dirlist[8]:\n",
        "  diawug_j = \"diawug/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(diawug_j)\n",
        "for i in dirlist[9]:\n",
        "  dups_j = \"DUPS-WUG/data/\" + i + \"/judgments.csv\"\n",
        "  dwug_j.append(dups_j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "40oRLVLdYXTR"
      },
      "outputs": [],
      "source": [
        "judgemnt_df = pd.DataFrame()            #dwug data judgments df\n",
        "for i in dwug_j:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[0]\n",
        "   judgemnt_df = pd.concat([judgemnt_df, Tmp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "DuKrc5P7NF6P"
      },
      "outputs": [],
      "source": [
        "path_u = []\n",
        "path_us = []                   #uses paths for tempowic and usim\n",
        "for i in folders[0]:\n",
        "    pathj = paths[0] + i + \"/uses.csv\"    #tempowic\n",
        "    path_u.append(pathj)\n",
        "for i in folders[3]:\n",
        "    pathj = paths[3] + i + \"/uses.csv\"     #tempowic\n",
        "    path_u.append(pathj)\n",
        "for i in folders[4]:\n",
        "    pathj = paths[4] + i + \"/uses.csv\"     #tempowic\n",
        "    path_u.append(pathj)\n",
        "for i in folders[10]:\n",
        "     pathj = paths[10] + i + \"/uses.csv\"   #usim\n",
        "     path_us.append(pathj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "QfcQ_x25mOWy"
      },
      "outputs": [],
      "source": [
        "path_cou = []                               #for cosimlex uses paths\n",
        "pat = paths[6] + \"/uses.csv\"\n",
        "path_cou.append(pat)\n",
        "\n",
        "pat = paths[7] + \"/uses.csv\"\n",
        "path_cou.append(pat)\n",
        "\n",
        "pat = paths[8] +  \"/uses.csv\"\n",
        "path_cou.append(pat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "2FtNPXSvmaUg"
      },
      "outputs": [],
      "source": [
        "cosim_uses_df = pd.DataFrame()            #cosimlex uses df\n",
        "for i in path_cou:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[4]\n",
        "   cosim_uses_df = pd.concat([cosim_uses_df, Tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "NhJFx09em6yB"
      },
      "outputs": [],
      "source": [
        "cosim_uses_df.loc[cosim_uses_df[\"dataset\"] == \"fi\", \"language\"] = 'Finnish'\n",
        "cosim_uses_df.loc[cosim_uses_df[\"dataset\"] == \"hr\", \"language\"] = 'Croatian'\n",
        "cosim_uses_df.loc[cosim_uses_df[\"dataset\"] == \"en\", \"language\"] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "fR4F56QSvGJ2"
      },
      "outputs": [],
      "source": [
        "cosim_uses_df.loc[cosim_uses_df[\"language\"] == \"Finnish\", \"dataset\"] = 'Cosimlex_fi'\n",
        "cosim_uses_df.loc[cosim_uses_df[\"language\"] == \"Croatian\", \"dataset\"] = 'Cosimlex_hr'\n",
        "cosim_uses_df.loc[cosim_uses_df[\"language\"] == \"English\", \"dataset\"] = 'Cosimlex_en'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "WfTftRhQnQVR"
      },
      "outputs": [],
      "source": [
        "#cosim_uses_df['dataset'] = 'Cosimlex'\n",
        "cosim_uses_df = cosim_uses_df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "YkjXw4ganXqu"
      },
      "outputs": [],
      "source": [
        "path_k = []\n",
        "path_r = []                         #wic and rawc uses df\n",
        "for i in folders[9]:\n",
        "    pathj = paths[9] + i + \"/uses.csv\" #wic\n",
        "    path_k.append(pathj)\n",
        "for i in folders[11]:\n",
        "    pathj = paths[11] + i + \"/uses.csv\" #rawc\n",
        "    path_r.append(pathj)\n",
        "raw_u_df = pd.DataFrame()\n",
        "raw_us_df = pd.DataFrame()\n",
        "for i in path_k:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[3]\n",
        "   raw_u_df = pd.concat([raw_u_df, Tmp])\n",
        "\n",
        "for i in path_r:\n",
        "   Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "   Tmp['dataset'] = i.split('/')[2]\n",
        "   raw_us_df = pd.concat([raw_us_df, Tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "p0MiXU51wI1L"
      },
      "outputs": [],
      "source": [
        "raw_uses_df = pd.DataFrame()\n",
        "raw_uses_df = pd.concat([raw_u_df, raw_us_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "Z1D38jh9nkkE"
      },
      "outputs": [],
      "source": [
        "raw_uses_df['language'] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "6KxwYgGMw5w7"
      },
      "outputs": [],
      "source": [
        "raw_uses_df.loc[raw_uses_df[\"dataset\"] == \"dev\", \"dataset\"] = 'wic_dev'\n",
        "raw_uses_df.loc[raw_uses_df[\"dataset\"] == \"train\", \"dataset\"] = 'wic_train'\n",
        "raw_uses_df.loc[raw_uses_df[\"dataset\"] == \"test\", \"dataset\"] = 'wic_test'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_us.remove(\"WUGs/scripts/misc/data/dwug_en/uses.csv\")"
      ],
      "metadata": {
        "id": "-1lIJGtjrM8j"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "Kcs1Wy1In-Cl"
      },
      "outputs": [],
      "source": [
        "u_df = pd.DataFrame()\n",
        "ud_df =  pd.DataFrame()                 #uses dataframe for tempowic and usim\n",
        "for i in path_u:\n",
        "    Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "    Tmp['dataset'] = i.split('/')[4]\n",
        "    u_df = pd.concat([u_df, Tmp])\n",
        "\n",
        "for i in path_us:\n",
        "    Tmp = pd.read_csv(i, delimiter='\\t', quoting =3)\n",
        "    Tmp['dataset'] = i.split('/')[3]\n",
        "    ud_df = pd.concat([ud_df, Tmp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "iMbpHFNpyL37"
      },
      "outputs": [],
      "source": [
        "use_df = pd.DataFrame()\n",
        "use_df = pd.concat([u_df, ud_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "PKtzLYAoKE2S"
      },
      "outputs": [],
      "source": [
        "#use_df.loc[use_df[\"dataset\"] == \"wugdata\", \"dataset\"] = 'TempoWic'\n",
        "use_df.loc[use_df[\"dataset\"] == \"data\", \"dataset\"] = 'USim'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "ygJMtiIkKmr2"
      },
      "outputs": [],
      "source": [
        "use_df['language'] = 'English'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "bH1zLd2M6r3i"
      },
      "outputs": [],
      "source": [
        "dwug_u = []                                           #dwug data uses paths\n",
        "for i in dirlist[0]:\n",
        "  dwugde_u = \"dwug_de/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwugde_u)\n",
        "for i in dirlist[1]:\n",
        "  dwugen_u = \"dwug_en/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwugen_u)\n",
        "for i in dirlist[2]:\n",
        "  dwugsv_u = \"dwug_sv/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwugsv_u)\n",
        "for i in dirlist[3]:\n",
        "  discowugg_u = \"discowug/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(discowugg_u)\n",
        "for i in dirlist[4]:\n",
        "  durel_u = \"durel/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(durel_u)\n",
        "for i in dirlist[5]:\n",
        "  surel_u = \"surel/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(surel_u)\n",
        "for i in dirlist[6]:\n",
        "  refwug_u = \"refwug/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(refwug_u)\n",
        "for i in dirlist[7]:\n",
        "  dwuges_u = \"dwug_es/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dwuges_u)\n",
        "for i in dirlist[8]:\n",
        "  diawug_u = \"diawug/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(diawug_u)\n",
        "for i in dirlist[9]:\n",
        "  dups_u = \"DUPS-WUG/data/\" + i + \"/uses.csv\"\n",
        "  dwug_u.append(dups_u)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "3i1SnqaGleIR"
      },
      "outputs": [],
      "source": [
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_de\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_en\", \"language\"] = 'English'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"DUPS-WUG\", \"language\"] = 'English'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_es\", \"language\"] = 'Spanish'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"dwug_sv\", \"language\"] = 'Swedish'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"durel\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"surel\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"discowug\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"refwug\", \"language\"] = 'German'\n",
        "judgemnt_df.loc[judgemnt_df[\"dataset\"] == \"diawug\", \"language\"] = 'Spanish'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "q89I4-6qMxrm"
      },
      "outputs": [],
      "source": [
        "#final judgments df (without russian and norwegian datasets)\n",
        "judgment_df = pd.DataFrame()\n",
        "judgment_df = pd.concat([judgment_df, judgemt_df], axis = 0)\n",
        "judgment_df = pd.concat([judgment_df, judgemnt_df], axis = 0)\n",
        "judgment_df = pd.concat([judgment_df, raw_df], axis = 0)\n",
        "judgment_df = pd.concat([judgment_df, cosim_df], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "I2OPKvW_LrXW"
      },
      "outputs": [],
      "source": [
        "judgment_df = judgment_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "H5UNk2kXD2oU"
      },
      "outputs": [],
      "source": [
        "usee_df = pd.DataFrame()            #uses dwug df\n",
        "for i in dwug_u:\n",
        "    Tmp = pd.read_csv(i, delimiter='\\t', quoting = 3)\n",
        "    Tmp['dataset'] = i.split('/')[0]\n",
        "    usee_df = pd.concat([usee_df, Tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "Swq_wL0BpUYf"
      },
      "outputs": [],
      "source": [
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_de\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_en\", \"language\"] = 'English'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"DUPS-WUG\", \"language\"] = 'English'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_es\", \"language\"] = 'Spanish'\n",
        "#usee_df.loc[usee_df[\"dataset\"] == \"dwug_la\", \"language\"] = 'latin'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"dwug_sv\", \"language\"] = 'Swedish'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"durel\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"surel\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"discowug\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"refwug\", \"language\"] = 'German'\n",
        "usee_df.loc[usee_df[\"dataset\"] == \"diawug\", \"language\"] = 'Spanish'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "A8ZyibHeoYaS"
      },
      "outputs": [],
      "source": [
        "#combining uses df\n",
        "uses_full_df = pd.concat([usee_df, use_df], axis = 0)\n",
        "uses1_df = pd.concat([uses_full_df, raw_uses_df], axis = 0)\n",
        "uses_df_full = pd.concat([uses1_df, cosim_uses_df], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "-Hs9BgeUHPxZ"
      },
      "outputs": [],
      "source": [
        "#getting the data\n",
        "rudsi = [rudsi]\n",
        "nordia = [nordia1, nordia2]\n",
        "rushift = [rushifteval1, rushifteval2, rushifteval3]\n",
        "rusem = [rusemshift1, rusemshift2]\n",
        "find_class_nordia = []\n",
        "find_class_rudsi = []\n",
        "find_class_rusem = []\n",
        "find_class_rushift = []\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class(URL):\n",
        "      page = requests.get(URL)\n",
        "      soup = BeautifulSoup( page.content , 'html.parser')\n",
        "      classy = soup.find_all('a', class_=\"Link--primary\")[3:]\n",
        "      return classy"
      ],
      "metadata": {
        "id": "3hbWSdGi-FS9"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for URL in rusem:\n",
        "  classed = get_class(URL)\n",
        "  find_class_rusem.append(classed)\n",
        "for URL in rushift:\n",
        "  classed = get_class(URL)\n",
        "  find_class_rushift.append(classed)\n",
        "for URL in nordia:\n",
        "  classed = get_class(URL)\n",
        "  find_class_nordia.append(classed)\n",
        "for URL in rudsi:\n",
        "  classed = get_class(URL)\n",
        "  find_class_rudsi.append(classed)"
      ],
      "metadata": {
        "id": "NHnssvMbMhzD"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "uTjddnWNuE1o"
      },
      "outputs": [],
      "source": [
        "judgements_rusem = []\n",
        "judgements_nordia = []\n",
        "judgements_rudsi = []\n",
        "judgements_rushift = []\n",
        "uses_rusem = []\n",
        "uses_nordia = []\n",
        "uses_rudsi = []\n",
        "uses_rushift = []\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j in find_class_rudsi :\n",
        "    for i in j:\n",
        "      judgements_rudsi.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/judgments.csv\")\n",
        "      uses_rudsi.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/uses.csv\")\n",
        "for j in find_class_rusem :\n",
        "    for i in j:\n",
        "      judgements_rusem.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/judgments.csv\")\n",
        "      uses_rusem.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/uses.csv\")\n",
        "for j in find_class_rushift :\n",
        "    for i in j:\n",
        "      judgements_rushift.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/judgments.csv\")\n",
        "      uses_rushift.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/uses.csv\")\n",
        "for j in find_class_nordia :\n",
        "    for i in j:\n",
        "      judgements_nordia.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/judgments.csv\")\n",
        "      uses_nordia.append(\"https://raw.githubusercontent.com/\"+i['href']+\"/uses.csv\")"
      ],
      "metadata": {
        "id": "wg8mnhgA_M9s"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "4DuRGR6jrfD2"
      },
      "outputs": [],
      "source": [
        "#judgments dataframe for rudsi, rusemshift, rushifteval, nordiachange\n",
        "jud_rudsi = pd.DataFrame()\n",
        "for i in judgements_rudsi:\n",
        "   Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "   Tmp['dataset'] = i.split('/')[5]\n",
        "   jud_rudsi = pd.concat([jud_rudsi, Tmp])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jud_rusems = pd.DataFrame()\n",
        "for i in judgements_rusem:\n",
        "   Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "   Tmp['dataset'] = i.split('/')[8]\n",
        "   jud_rusems = pd.concat([jud_rusems, Tmp])\n"
      ],
      "metadata": {
        "id": "BhWQ9x3NSf9q"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jud_rushift = pd.DataFrame()\n",
        "for i in judgements_rushift:\n",
        "   Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "   Tmp['dataset'] = i.split('/')[9]\n",
        "   jud_rushift = pd.concat([jud_rushift, Tmp])"
      ],
      "metadata": {
        "id": "5Fs6Aty1TlPm"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jud_nordia = pd.DataFrame()\n",
        "for i in judgements_nordia:\n",
        "   Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "   Tmp['dataset'] = i.split('/')[8]\n",
        "   jud_nordia = pd.concat([jud_nordia, Tmp])"
      ],
      "metadata": {
        "id": "UyIaj_uXUaPm"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jud_nordia.loc[jud_nordia['dataset'] == 'subset1', 'dataset'] = 'NorDiaChange1'\n",
        "jud_nordia.loc[jud_nordia['dataset'] == 'subset2', 'dataset'] = 'NorDiaChange2'"
      ],
      "metadata": {
        "id": "iMldrMUuVYun"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "judgements_df = pd.DataFrame()\n",
        "judgements_df = pd.concat([judgements_df, jud_rudsi])\n",
        "judgements_df = pd.concat([judgements_df, jud_rusems])\n",
        "judgements_df = pd.concat([judgements_df, jud_rushift])\n",
        "judgements_df = pd.concat([judgements_df, jud_nordia])"
      ],
      "metadata": {
        "id": "sc4yhIN2V590"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "IEcwGGWLKxP1"
      },
      "outputs": [],
      "source": [
        "judgements_df[\"language\"] = \"Russian\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "id": "oyKbDqb-q_hK"
      },
      "outputs": [],
      "source": [
        "judgements_df.loc[judgements_df[\"dataset\"] == \"NorDiaChange1\", \"language\"] = 'Norwegian'\n",
        "judgements_df.loc[judgements_df[\"dataset\"] == \"NorDiaChange2\", \"language\"] = 'Norwegian'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_rudsi = pd.DataFrame()\n",
        "for i in uses_rudsi:\n",
        "   Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "   Tmp['dataset'] = i.split('/')[5]\n",
        "   use_rudsi = pd.concat([use_rudsi, Tmp])"
      ],
      "metadata": {
        "id": "y-Cg5SqnW2br"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_rusems = pd.DataFrame()\n",
        "for i in uses_rusem:\n",
        "   Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "   Tmp['dataset'] = i.split('/')[8]\n",
        "   use_rusems = pd.concat([use_rusems, Tmp])"
      ],
      "metadata": {
        "id": "VSnf0MX2W-pU"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_rushift = pd.DataFrame()\n",
        "for i in uses_rushift:\n",
        "   Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "   Tmp['dataset'] = i.split('/')[9]\n",
        "   use_rushift = pd.concat([use_rushift, Tmp])"
      ],
      "metadata": {
        "id": "k7Ey9vEIXCoL"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_nordia = pd.DataFrame()\n",
        "for i in uses_nordia:\n",
        "   Tmp = pd.read_csv(io.StringIO(requests.get(i.replace(\"/tree\",\"\")).content.decode('utf-8')), delimiter='\\t')\n",
        "   Tmp['dataset'] = i.split('/')[8]\n",
        "   use_nordia = pd.concat([use_nordia, Tmp])"
      ],
      "metadata": {
        "id": "eD0MlB2CXFf0"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usees_df = pd.DataFrame()\n",
        "usees_df = pd.concat([usees_df, use_rudsi])\n",
        "usees_df = pd.concat([usees_df, use_rusems])\n",
        "usees_df = pd.concat([usees_df, use_rushift])\n",
        "usees_df = pd.concat([usees_df, use_nordia])"
      ],
      "metadata": {
        "id": "NbDiBv5VXp7J"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "ikn0jHLOtY35"
      },
      "outputs": [],
      "source": [
        "usees_df['language'] = 'Russian'\n",
        "usees_df.loc[usees_df[\"dataset\"] == \"NorDiaChange1\", \"language\"] = 'Norwegian'\n",
        "usees_df.loc[usees_df[\"dataset\"] == \"NorDiaChange2\", \"language\"] = 'Norwegian'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "oS__0wkBdjfP"
      },
      "outputs": [],
      "source": [
        "#final judgments dataframe full format\n",
        "judgments_full = pd.concat([judgment_df, judgements_df], axis = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "AxBZ18nA7Ky2"
      },
      "outputs": [],
      "source": [
        "#final uses dataframe full format\n",
        "uses_full = pd.concat([uses_df_full, usees_df], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "3DWumP4cKuFn"
      },
      "outputs": [],
      "source": [
        "#resetting the index of uses and judgments dataframes because they have repeated indices\n",
        "judgments_full = judgments_full.reset_index(drop= True)\n",
        "uses_full = uses_full.reset_index(drop= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "zeUvy7OHvdby"
      },
      "outputs": [],
      "source": [
        "#final uses and judgments in wug format\n",
        "judgments_wug = judgments_full[[\"identifier1\", \"identifier2\", \"annotator\", \"judgment\", \"comment\", \"lemma\", \"dataset\", \"language\"]]\n",
        "uses_wug= uses_full[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'dataset', 'language']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dup = uses_full[uses_full.duplicated()] #to gwt duplicates"
      ],
      "metadata": {
        "id": "cXRNcF1-lreW"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "haNL38ua-_S4"
      },
      "outputs": [],
      "source": [
        "for i in list(judgments_wug[\"dataset\"].value_counts().index):\n",
        "    df_temp = judgments_wug[judgments_wug[\"dataset\"]==i]\n",
        "    if not os.path.exists(i):\n",
        "        os.mkdir(i)\n",
        "    df_temp.to_csv(i +'/judgments.csv',index = False, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, quotechar = '')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(uses_wug[\"dataset\"].value_counts().index):\n",
        "    df_temp = uses_wug[uses_wug[\"dataset\"]==i]\n",
        "    if not os.path.exists(i):\n",
        "        os.mkdir(i)\n",
        "    df_temp.to_csv(i +'/uses.csv',index = False, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, quotechar = '')"
      ],
      "metadata": {
        "id": "GJmYL2apO58c"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(judgments_full[\"dataset\"].value_counts().index):\n",
        "    df_temp = judgments_full[judgments_full[\"dataset\"]==i]\n",
        "    if not os.path.exists(i):\n",
        "        os.mkdir(i)\n",
        "    df_temp.to_csv(i +'/judgments.csv',index = False, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, quotechar = '')"
      ],
      "metadata": {
        "id": "PnwBHYwfPD6Q"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(uses_full[\"dataset\"].value_counts().index):\n",
        "    df_temp = uses_full[uses_full[\"dataset\"]==i]\n",
        "    if not os.path.exists(i):\n",
        "        os.mkdir(i)\n",
        "    df_temp.to_csv(i +'/uses.csv',index = False, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, quotechar = '')"
      ],
      "metadata": {
        "id": "7XD6tea3PKlM"
      },
      "execution_count": 230,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}