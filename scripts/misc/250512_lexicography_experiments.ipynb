{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5d5da4-4b0e-4aa1-95cf-9fdff226bb2f",
   "metadata": {},
   "source": [
    "#### Statistical analysis of lexicographer's analysis of different cluster groups (round 2)\n",
    "- based on numbers from \"281_lemmas_overview. 23 december 2024.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a37dd-8c82-4b7a-b425-e9ca6a5299ec",
   "metadata": {},
   "source": [
    "| Item            | 1 cluster | >1 cluster     | Row total |\n",
    "|-----------------|-----------|----------------|-----------|\n",
    "| interesting     | 1         | 17+7+4+1+1=30  | 31        |\n",
    "| not interesting | 27        | 32+2+2+0+0=36  | 63        |\n",
    "| Column total    | 28        | 66             | 94        |\n",
    "\n",
    "to do:\n",
    "- verify numbers (Emma? Second pair of eyes.)\n",
    "- includes some non-randomly chosen words for one cluster (done)\n",
    "- some words have no decision (done)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46a43e-6483-4ecf-9690-235854ff1d7b",
   "metadata": {},
   "source": [
    "- Fisher's exact test: https://en.wikipedia.org/wiki/Fisher%27s_exact_test\n",
    "- https://docs.scipy.org/doc/scipy/tutorial/stats/hypothesis_fisher_exact.html#hypothesis-fisher-exact\n",
    "- Null hypothesis: \"The odds of finding a semantically interesting word are the same within the 1-cluster group as they are within the >1-cluster group.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c220d434-cbde-4940-b6af-337e9518edd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00002412\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "from decimal import Decimal\n",
    "\n",
    "table = [[27, 1], [36, 30]]\n",
    "res = fisher_exact(table, alternative='greater')\n",
    "print('%.8f' % Decimal(res.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa95210-04d4-4b04-8339-1fb6283f6b28",
   "metadata": {},
   "source": [
    "- Using a significance level of 1%, we would reject the null hypothesis in favor of the alternative hypothesis: \"The odds of finding a semantically interesting word are greater within the >1-cluster group as they are within the 1-cluster group.\"\n",
    "- Additionally, the 1-cluster group is much more frequent than the >1-cluster group (215 versus 66).\n",
    "- Hence, by inspecting only the >1-cluster group we increase the chance to find semantically interesting words as compared to a random selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b98bc00",
   "metadata": {},
   "source": [
    "#### Statistical analysis of lexicographer's analysis of different cluster groups (round 3)\n",
    "- based on numbers from \"1. Lemmas_with_cluster_round3_lex.judgements_4 juni.ods\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa754fd7",
   "metadata": {},
   "source": [
    "| Item            | 1 cluster | >1 cluster     | Row total |\n",
    "|-----------------|-----------|----------------|-----------|\n",
    "| interesting     | 0         | 58+16+11+1+1=87| 87        |\n",
    "| not interesting | 21        | 43+17+4+2+0=66 | 87        |\n",
    "| Column total    | 21        | 153            | 174       |\n",
    "\n",
    "to do:\n",
    "- verify numbers (Emma? Second pair of eyes.). Done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9283ed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00000012\n"
     ]
    }
   ],
   "source": [
    "table = [[21, 0], [66, 87]]\n",
    "res = fisher_exact(table, alternative='greater')\n",
    "print('%.8f' % Decimal(res.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d98578",
   "metadata": {},
   "source": [
    "- same results as above\n",
    "- effect size seems stronger (smaller significance value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a1ff0",
   "metadata": {},
   "source": [
    "#### Additional experiments parallel to experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3137564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>cluster</th>\n",
       "      <th>model</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svt-2019-9a093e72-21</td>\n",
       "      <td>0</td>\n",
       "      <td>correlation_0.45</td>\n",
       "      <td>tysta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svt-2012-e28bee60-15</td>\n",
       "      <td>0</td>\n",
       "      <td>correlation_0.45</td>\n",
       "      <td>tysta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svt-2011-91a33298-8</td>\n",
       "      <td>0</td>\n",
       "      <td>correlation_0.45</td>\n",
       "      <td>tysta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svt-2014-152158f0-12</td>\n",
       "      <td>0</td>\n",
       "      <td>correlation_0.45</td>\n",
       "      <td>tysta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svt-2011-e2825434-8</td>\n",
       "      <td>0</td>\n",
       "      <td>correlation_0.45</td>\n",
       "      <td>tysta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>svt-2016-f54f3f49-1</td>\n",
       "      <td>0</td>\n",
       "      <td>correlation_0.675</td>\n",
       "      <td>fotavtryck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>svt-2016-d697bc6e-7</td>\n",
       "      <td>1</td>\n",
       "      <td>correlation_0.675</td>\n",
       "      <td>fotavtryck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>svt-2019-9a09d01d-16</td>\n",
       "      <td>1</td>\n",
       "      <td>correlation_0.675</td>\n",
       "      <td>fotavtryck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>svt-2017-1188d57d-34</td>\n",
       "      <td>0</td>\n",
       "      <td>correlation_0.675</td>\n",
       "      <td>fotavtryck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>svt-2012-118cb71-12</td>\n",
       "      <td>0</td>\n",
       "      <td>correlation_0.675</td>\n",
       "      <td>fotavtryck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20634 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              identifier  cluster              model       lemma\n",
       "0   svt-2019-9a093e72-21        0   correlation_0.45       tysta\n",
       "1   svt-2012-e28bee60-15        0   correlation_0.45       tysta\n",
       "2    svt-2011-91a33298-8        0   correlation_0.45       tysta\n",
       "3   svt-2014-152158f0-12        0   correlation_0.45       tysta\n",
       "4    svt-2011-e2825434-8        0   correlation_0.45       tysta\n",
       "..                   ...      ...                ...         ...\n",
       "45   svt-2016-f54f3f49-1        0  correlation_0.675  fotavtryck\n",
       "46   svt-2016-d697bc6e-7        1  correlation_0.675  fotavtryck\n",
       "47  svt-2019-9a09d01d-16        1  correlation_0.675  fotavtryck\n",
       "48  svt-2017-1188d57d-34        0  correlation_0.675  fotavtryck\n",
       "49   svt-2012-118cb71-12        0  correlation_0.675  fotavtryck\n",
       "\n",
       "[20634 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, rand_score, adjusted_mutual_info_score\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "\n",
    "experiment_folder='../../data/lexicographer_project/Euralex_sv_experiment_1_v2.02/xllexeme'\n",
    "#experiment_folder='../../data/lexicographer_project/Euralex_sv_experiment_1_v2.02/xldurel'\n",
    "\n",
    "is_load_data = False\n",
    "\n",
    "if is_load_data:\n",
    "    df_experiments = pd.read_pickle(experiment_folder + \"/clusterings.pkl\")\n",
    "else:\n",
    "    df_experiments = pd.DataFrame()\n",
    "    paths = Path(experiment_folder+'/').glob('*/clusters/*.csv')\n",
    "    for i, p in enumerate(paths):\n",
    "\n",
    "        #if not 'wsbm' in str(p):\n",
    "        #    continue\n",
    "        #if 'old' in str(p):\n",
    "        #    continue\n",
    "        #print(p)\n",
    "        #if i==1000:\n",
    "        #    break\n",
    "\n",
    "        model = str(p).replace('\\\\', '/').split('/')[-3]\n",
    "        lemma = str(p).replace('\\\\', '/').split('/')[-1].replace('.csv','')\n",
    "        lemma = unicodedata.normalize('NFC', lemma)\n",
    "        df = pd.read_csv(p, delimiter='\\t', quoting=3, na_filter=False)\n",
    "        df['model'] = model\n",
    "        df['lemma'] = lemma\n",
    "        df_experiments = pd.concat([df_experiments, df])\n",
    "    df_experiments.to_pickle(experiment_folder + \"/clusterings.pkl\")\n",
    "display(df_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548dffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ground truth\n",
    "truth_folder='../../data/lexicographer_project/lexicographer_judgments'\n",
    "\n",
    "df_truth = pd.DataFrame()\n",
    "paths = Path(truth_folder+'/').glob('*.csv')\n",
    "for i, p in enumerate(paths):\n",
    "    #display(p)\n",
    "    lemma = str(p).replace('\\\\', '/').split('/')[-1].replace('.csv','').split('_')[1]\n",
    "    lemma = unicodedata.normalize('NFC', lemma)\n",
    "    df = pd.read_csv(p, delimiter=';')\n",
    "    df['lemma'] = lemma\n",
    "    df = df.rename(columns={'lex.judgement': 'lex_judgement', 'lex. judgement': 'lex_judgement', 'lex. Jugement': 'lex_judgement'})\n",
    "    df_truth = pd.concat([df_truth, df])\n",
    "#display(df_truth)\n",
    "#print(df_truth.columns.tolist())\n",
    "\n",
    "# Filter\n",
    "df_truth = df_truth[(~df_truth['lex_judgement'].eq('unclear'))]\n",
    "df_truth = df_truth[~df_truth['lex_judgement'].isnull()]\n",
    "df_experiments = df_experiments[(df_experiments['lemma'].isin(df_truth['lemma'].unique()))]\n",
    "#display(df_truth['lex_judgement'].unique())\n",
    "gb_truth_lemma = df_truth.groupby('lemma')    \n",
    "#gb_truth = gb_truth_lemma.groups\n",
    "#display(sorted(df_experiments['lemma'].unique()))\n",
    "#display(sorted(df_truth['lemma'].unique()))\n",
    "assert set(df_truth['lemma'].unique()) == set(df_experiments['lemma'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eae252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " correlation_0.3 mean 0.19671879294415545 0.6855276965643725\n",
      "\n",
      " correlation_0.325 mean 0.24544926169415549 0.6866722543875017\n",
      "\n",
      " correlation_0.35 mean 0.25551646343936996 0.6972407422912258\n",
      "\n",
      " correlation_0.375 mean 0.313371108410046 0.7205662444451154\n",
      "\n",
      " correlation_0.4 mean 0.3191706017699908 0.7197159043090611\n",
      "\n",
      " correlation_0.425 mean 0.31630965110183323 0.7167877104620664\n",
      "\n",
      " correlation_0.45 mean 0.411899076121062 0.7438446755994794\n",
      "\n",
      " correlation_0.475 mean 0.4213088920993869 0.7667968646358376\n",
      "\n",
      " correlation_0.5 mean 0.3898254254624668 0.7356454930788893\n",
      "\n",
      " correlation_0.525 mean 0.4213205971685345 0.7456192284789165\n",
      "\n",
      " correlation_0.55 mean 0.415823071276606 0.7404938784314045\n",
      "\n",
      " correlation_0.575 mean 0.4487771469993344 0.7508595246899078\n",
      "\n",
      " correlation_0.6 mean 0.4887712468774944 0.7690422463424741\n",
      "\n",
      " correlation_0.625 mean 0.48226494073660914 0.7632520451556164\n",
      "\n",
      " correlation_0.65 mean 0.4853282424592054 0.7644052825837977\n",
      "\n",
      " correlation_0.675 mean 0.46915612118502664 0.7489216437773322\n",
      "\n",
      " correlation_0.7 mean 0.475167882124844 0.7478267287733577\n",
      "\n",
      " wsbm_real-exponential mean 0.31851541334224487 0.743830209977878\n",
      "\n",
      " wsbm_real-normal mean 0.14510385790305805 0.4927181299661142\n"
     ]
    }
   ],
   "source": [
    "gb_model = df_experiments.groupby('model')    \n",
    "groups_model = gb_model.groups\n",
    "results = []\n",
    "for model in groups_model.keys():\n",
    "    df_model = gb_model.get_group(model)\n",
    "    gb_model_lemma = df_model.groupby('lemma')    \n",
    "    groups_model_lemma = gb_model_lemma.groups\n",
    "    aris = []\n",
    "    ris = []\n",
    "    for lemma in groups_model_lemma.keys():\n",
    "        df_truth_lemma = gb_truth_lemma.get_group(lemma)\n",
    "        df_truth_lemma_dict = pd.Series(df_truth_lemma.lex_judgement.values,index=df_truth_lemma.identifier).to_dict()\n",
    "        #print(df_truth_lemma_dict)\n",
    "        df_model_lemma = gb_model_lemma.get_group(lemma)\n",
    "        df_model_lemma_dict = pd.Series(df_model_lemma.cluster.values,index=df_model_lemma.identifier).to_dict()\n",
    "        #print(df_model_lemma_dict)\n",
    "        data1 = [label for identifier, label in df_truth_lemma_dict.items()]\n",
    "        data2 = [df_model_lemma_dict[identifier] for identifier, _ in df_truth_lemma_dict.items()]\n",
    "        #print(data2)\n",
    "        ari = adjusted_rand_score(data1, data2)\n",
    "        ri = rand_score(data1, data2)\n",
    "        #print(' ', lemma, ari)\n",
    "        results.append({'model':model, 'lemma':lemma, 'ARI':ari, 'RI':ri})\n",
    "        aris.append(ari)\n",
    "        ris.append(ri)\n",
    "\n",
    "    mean_ari = np.mean(aris) \n",
    "    mean_ri = np.mean(ris) \n",
    "    print('\\n', model, 'mean', mean_ari, mean_ri)\n",
    "\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cf9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
