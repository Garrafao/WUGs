{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "A sample from the DWUG DE data set was additionally annotated with sense descriptions extracted from two historical dictionaries. Annotators were instructed to choose only one of the provided descriptions and could choose one generic description 'others' for senses which were not provided in the descriptions. In the first round only annotatorA annotated the data and also provided some additional sense descriptions. These were then added to the previous descriptions and presented to two further annotators. We analyze the agreement of all three annotators and the correspondence of the annotated data with different cleaning methods (majority label conditions) to the inferred SemEval clusterings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from os.path import exists\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import cohen_kappa_score, hamming_loss, accuracy_score\n",
    "import krippendorff_ as krippendorff\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "nice_colors = [x for x in mcolors.get_named_colors_mapping().values() if isinstance(x, str)] # Nice colors\n",
    "colors_global = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#984ea3', '#999999', '#e41a1c', '#dede00'] # color-blind colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load inferred clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../../data/dwug_de_1.1.0/dwug_de/clusters/semeval'\n",
    "data = []\n",
    "for root, subdirectories, files in os.walk(input_path):\n",
    "    for f in files:\n",
    "        path = os.path.join(root, f)\n",
    "        #print(f)       \n",
    "        with open(path, encoding='utf-8') as csvfile: \n",
    "            reader = csv.DictReader(csvfile, delimiter='\\t',quoting=csv.QUOTE_NONE,strict=True)\n",
    "            table = [row | {'lemma':f.split('.')[0]} for row in reader]\n",
    "            data = data + table\n",
    " \n",
    "variable_names = list(data[0].keys())\n",
    "variable_names.remove('identifier')\n",
    "index = [row['identifier'] for row in data]\n",
    "variables = [[row[name] for row in data] for name in variable_names]\n",
    "df = DataFrame(np.transpose(variables), index=index, columns=variable_names)\n",
    "df[\"cluster\"] = df[\"cluster\"].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dwug_de sense description annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../../data/dwug_de_1.1.0/data'\n",
    "judgments_senses = []\n",
    "data_senses = []\n",
    "for root, subdirectories, files in os.walk(input_path):\n",
    "    for f in files:\n",
    "        path = os.path.join(root, f)\n",
    "        if f=='judgments_senses.csv':\n",
    "            #print(f)    \n",
    "            with open(path, encoding='utf-8') as csvfile: \n",
    "                reader = csv.DictReader(csvfile, delimiter='\\t',quoting=csv.QUOTE_NONE,strict=True)\n",
    "                table = [row for row in reader]\n",
    "                judgments_senses = judgments_senses + table\n",
    "        if f=='senses.csv':\n",
    "            with open(path, encoding='utf-8') as csvfile: \n",
    "                reader = csv.DictReader(csvfile, delimiter='\\t',quoting=csv.QUOTE_NONE,strict=True)\n",
    "                table = [row | {'lemma':path.split('/')[-2]} for row in reader]\n",
    "                data_senses = data_senses + table\n",
    " \n",
    "# Transform data format            \n",
    "annotators = sorted(list(set([row['annotator'] for row in judgments_senses])))\n",
    "identifier2annotator2judgment = defaultdict(lambda: {})\n",
    "for row in judgments_senses:\n",
    "    identifier2annotator2judgment[(row['identifier'],row['lemma'])] |= {row['annotator']:row['identifier_sense']}    \n",
    "#print(identifier2annotator2judgment)\n",
    "judgments_senses_transformed = [{'identifier':identifier} | {annotator:annotator2judgment[annotator] \n",
    "                    for annotator in annotators} | {'lemma':lemma} for ((identifier,lemma), annotator2judgment) in \n",
    "                    identifier2annotator2judgment.items()]\n",
    "variable_names = list(judgments_senses_transformed[0].keys())\n",
    "variable_names.remove('identifier')\n",
    "index = [row['identifier'] for row in judgments_senses_transformed]\n",
    "variables = [[row[name] for row in judgments_senses_transformed] for name in variable_names]\n",
    "df_description = DataFrame(np.transpose(variables), index=index, columns=variable_names)\n",
    "\n",
    "# Get sense labels\n",
    "lemma2description2label = defaultdict(lambda: {})\n",
    "for row in data_senses:\n",
    "    lemma2description2label[row['lemma']] |= {row['description_sense']:row['identifier_sense']}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sense2index(label):\n",
    "    label_1 = label[-1]\n",
    "    label_2 = label[-2:-1]\n",
    "    if label_2.isdigit():\n",
    "        id_ = int(label_2)\n",
    "    else:\n",
    "        id_ = int(label_1)\n",
    "    return id_\n",
    "\n",
    "# Get lemmas\n",
    "lemmas = sorted(list(set(df_description['lemma'])))\n",
    "#print(lemmas)\n",
    "lemma2index = {l:i*100 for (i,l) in enumerate(lemmas)}\n",
    "#print(lemma2index)\n",
    "# Transform data, convert to numbers, set nans\n",
    "df_description = df_description.apply(lambda x: pd.Series([lemma2index[x['lemma']]+sense2index(y) if y!='None' \n",
    "                else np.NaN for y in x[annotators[0]:annotators[-1]]]+[x['lemma']], index=df_description.columns),\n",
    "                axis=1)\n",
    "index2description = {lemma2index[lemma]+sense2index(label):description \n",
    "               for lemma, description2label in lemma2description2label.items() for description, label in \n",
    "               description2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          cluster           lemma  annotatorA  \\\n",
      "treitschke_geschichte02_1882-7387-3           0.0  Ausnahmegesetz         NaN   \n",
      "2532889X_1978-04-01_01_229.tcf.xml-40-11      0.0  Ausnahmegesetz         NaN   \n",
      "treitschke_geschichte02_1882-8135-23          0.0  Ausnahmegesetz         NaN   \n",
      "treitschke_geschichte03_1885-129-10           0.0  Ausnahmegesetz         NaN   \n",
      "26120215_1963_06_01_01_068.tcf.xml-26-4       0.0  Ausnahmegesetz         NaN   \n",
      "...                                           ...             ...         ...   \n",
      "beyer_poetik01_1882-7723-51                   NaN        Mißklang       801.0   \n",
      "robert_griechische_1881-1366-6                NaN           Titel         NaN   \n",
      "savigny_system01_1840-2586-21                 NaN           Titel      1506.0   \n",
      "26120215_1966_07_27_01_394.tcf.xml-9-7        NaN           Titel         NaN   \n",
      "2532889X_1966-05-09_01_147.tcf.xml-3-5        NaN           Titel      1504.0   \n",
      "\n",
      "                                          annotatorB  annotatorC  \n",
      "treitschke_geschichte02_1882-7387-3              NaN         NaN  \n",
      "2532889X_1978-04-01_01_229.tcf.xml-40-11         NaN         NaN  \n",
      "treitschke_geschichte02_1882-8135-23             NaN         NaN  \n",
      "treitschke_geschichte03_1885-129-10              NaN         NaN  \n",
      "26120215_1963_06_01_01_068.tcf.xml-26-4          NaN         NaN  \n",
      "...                                              ...         ...  \n",
      "beyer_poetik01_1882-7723-51                      NaN         NaN  \n",
      "robert_griechische_1881-1366-6                1503.0         NaN  \n",
      "savigny_system01_1840-2586-21                 1503.0      1503.0  \n",
      "26120215_1966_07_27_01_394.tcf.xml-9-7        1505.0         NaN  \n",
      "2532889X_1966-05-09_01_147.tcf.xml-3-5        1504.0      1504.0  \n",
      "\n",
      "[8488 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "for column in df_description.columns:\n",
    "    if column=='lemma':\n",
    "        continue\n",
    "    df[column] = np.NaN \n",
    "for identifier, row in df_description.iterrows():\n",
    "    for column in df_description.columns:\n",
    "        df.loc[identifier,column] = row[column]\n",
    "\n",
    "lemmas = sorted(list(set(df['lemma'])))\n",
    "    \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8488\n",
      "8375\n"
     ]
    }
   ],
   "source": [
    "# Add andere column\n",
    "def extract_label_count(row, labels, columns, index, name):\n",
    "    label2count = Counter(row[columns])\n",
    "    label_count = np.sum([label2count[label] for label in label2count if label in labels])\n",
    "    out_data = pd.Series(row.to_list()+[label_count], index=index+[name])\n",
    "    return out_data\n",
    "\n",
    "indexes_andere = [index for index, description in index2description.items() if description == 'andere']\n",
    "df = df.apply(lambda x: extract_label_count(x, indexes_andere, annotators, \n",
    "                 list(df.columns), 'label_count_andere'), axis=1)\n",
    "#print(df)\n",
    "\n",
    "print(len(df.index))\n",
    "df = df.drop(df[(df['label_count_andere'] > 0)].index) # uncomment to test without instances annotated as andere\n",
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full annotatorA annotatorB 0.8519102638032974\n",
      "full annotatorA annotatorC 0.8882536723351926\n",
      "full annotatorB annotatorC 0.8862587056179285\n",
      "mean 0.8754742139188062\n",
      "Abgesang annotatorA annotatorB 0.837962962962963\n",
      "Abgesang annotatorA annotatorC 1.0\n",
      "Abgesang annotatorB annotatorC 0.837962962962963\n",
      "mean 0.8919753086419754\n",
      "Ackergerät annotatorA annotatorB nan\n",
      "Ackergerät annotatorA annotatorC nan\n",
      "Ackergerät annotatorB annotatorC nan\n",
      "mean nan\n",
      "Armenhaus annotatorA annotatorB 1.0\n",
      "Armenhaus annotatorA annotatorC 1.0\n",
      "Armenhaus annotatorB annotatorC 1.0\n",
      "mean 1.0\n",
      "Ausnahmegesetz annotatorA annotatorB nan\n",
      "Ausnahmegesetz annotatorA annotatorC nan\n",
      "Ausnahmegesetz annotatorB annotatorC nan\n",
      "mean nan\n",
      "Dynamik annotatorA annotatorB 0.5685618729096991\n",
      "Dynamik annotatorA annotatorC 0.6606538895152199\n",
      "Dynamik annotatorB annotatorC 0.6226415094339622\n",
      "mean 0.6172857572862936\n",
      "Einreichung annotatorA annotatorB nan\n",
      "Einreichung annotatorA annotatorC nan\n",
      "Einreichung annotatorB annotatorC nan\n",
      "mean nan\n",
      "Eintagsfliege annotatorA annotatorB 0.8973684210526316\n",
      "Eintagsfliege annotatorA annotatorC 0.8973684210526316\n",
      "Eintagsfliege annotatorB annotatorC 0.9089026915113871\n",
      "mean 0.9012131778722168\n",
      "Engpaß annotatorA annotatorB 0.9578947368421052\n",
      "Engpaß annotatorA annotatorC 0.9139194139194139\n",
      "Engpaß annotatorB annotatorC 0.916083916083916\n",
      "mean 0.9292993556151451\n",
      "Entscheidung annotatorA annotatorB nan\n",
      "Entscheidung annotatorA annotatorC nan\n",
      "Entscheidung annotatorB annotatorC nan\n",
      "mean nan\n",
      "Festspiel annotatorA annotatorB nan\n",
      "Festspiel annotatorA annotatorC nan\n",
      "Festspiel annotatorB annotatorC nan\n",
      "mean nan\n",
      "Frechheit annotatorA annotatorB nan\n",
      "Frechheit annotatorA annotatorC nan\n",
      "Frechheit annotatorB annotatorC nan\n",
      "mean nan\n",
      "Fuß annotatorA annotatorB 0.9665889665889666\n",
      "Fuß annotatorA annotatorC 0.9661290322580646\n",
      "Fuß annotatorB annotatorC 0.9049964813511612\n",
      "mean 0.9459048267327308\n",
      "Gesichtsausdruck annotatorA annotatorB nan\n",
      "Gesichtsausdruck annotatorA annotatorC nan\n",
      "Gesichtsausdruck annotatorB annotatorC nan\n",
      "mean nan\n",
      "Knotenpunkt annotatorA annotatorB 0.28315946348733245\n",
      "Knotenpunkt annotatorA annotatorC 0.8370044052863437\n",
      "Knotenpunkt annotatorB annotatorC 0.16457142857142848\n",
      "mean 0.42824509911503483\n",
      "Kubikmeter annotatorA annotatorB nan\n",
      "Kubikmeter annotatorA annotatorC nan\n",
      "Kubikmeter annotatorB annotatorC nan\n",
      "mean nan\n",
      "Lyzeum annotatorA annotatorB nan\n",
      "Lyzeum annotatorA annotatorC nan\n",
      "Lyzeum annotatorB annotatorC nan\n",
      "mean nan\n",
      "Manschette annotatorA annotatorB 0.7419354838709677\n",
      "Manschette annotatorA annotatorC 0.85625\n",
      "Manschette annotatorB annotatorC 0.824390243902439\n",
      "mean 0.8075252425911356\n",
      "Mißklang annotatorA annotatorB 0.5905044510385756\n",
      "Mißklang annotatorA annotatorC 0.6003552397868561\n",
      "Mißklang annotatorB annotatorC 0.53\n",
      "mean 0.5736198969418106\n",
      "Mulatte annotatorA annotatorB nan\n",
      "Mulatte annotatorA annotatorC nan\n",
      "Mulatte annotatorB annotatorC nan\n",
      "mean nan\n",
      "Naturschönheit annotatorA annotatorB nan\n",
      "Naturschönheit annotatorA annotatorC nan\n",
      "Naturschönheit annotatorB annotatorC nan\n",
      "mean nan\n",
      "Ohrwurm annotatorA annotatorB 1.0\n",
      "Ohrwurm annotatorA annotatorC 1.0\n",
      "Ohrwurm annotatorB annotatorC 1.0\n",
      "mean 1.0\n",
      "Pachtzins annotatorA annotatorB nan\n",
      "Pachtzins annotatorA annotatorC nan\n",
      "Pachtzins annotatorB annotatorC nan\n",
      "mean nan\n",
      "Rezeption annotatorA annotatorB 0.8338983050847457\n",
      "Rezeption annotatorA annotatorC 0.8977035490605428\n",
      "Rezeption annotatorB annotatorC 0.6721311475409836\n",
      "mean 0.8012443338954242\n",
      "Schmiere annotatorA annotatorB 0.8377693282636248\n",
      "Schmiere annotatorA annotatorC 0.7602905569007263\n",
      "Schmiere annotatorB annotatorC 0.7981651376146789\n",
      "mean 0.7987416742596767\n",
      "Seminar annotatorA annotatorB 0.6512509476876421\n",
      "Seminar annotatorA annotatorC 0.5747422680412371\n",
      "Seminar annotatorB annotatorC 0.625\n",
      "mean 0.616997738576293\n",
      "Sensation annotatorA annotatorB 0.49339207048458156\n",
      "Sensation annotatorA annotatorC 0.3783783783783784\n",
      "Sensation annotatorB annotatorC 0.5588235294117647\n",
      "mean 0.47686465942490824\n",
      "Spielball annotatorA annotatorB 0.48421052631578954\n",
      "Spielball annotatorA annotatorC 0.6571428571428571\n",
      "Spielball annotatorB annotatorC 0.7894736842105263\n",
      "mean 0.643609022556391\n",
      "Tier annotatorA annotatorB nan\n",
      "Tier annotatorA annotatorC nan\n",
      "Tier annotatorB annotatorC nan\n",
      "mean nan\n",
      "Titel annotatorA annotatorB 0.7923664122137405\n",
      "Titel annotatorA annotatorC 0.6944444444444444\n",
      "Titel annotatorB annotatorC 0.7982195845697329\n",
      "mean 0.7616768137426394\n",
      "Tragfähigkeit annotatorA annotatorB nan\n",
      "Tragfähigkeit annotatorA annotatorC nan\n",
      "Tragfähigkeit annotatorB annotatorC nan\n",
      "mean nan\n",
      "Truppenteil annotatorA annotatorB nan\n",
      "Truppenteil annotatorA annotatorC nan\n",
      "Truppenteil annotatorB annotatorC nan\n",
      "mean nan\n",
      "Unentschlossenheit annotatorA annotatorB nan\n",
      "Unentschlossenheit annotatorA annotatorC nan\n",
      "Unentschlossenheit annotatorB annotatorC nan\n",
      "mean nan\n",
      "abbauen annotatorA annotatorB 0.7893129770992366\n",
      "abbauen annotatorA annotatorC 0.9650817236255572\n",
      "abbauen annotatorB annotatorC 0.7971223021582734\n",
      "mean 0.8505056676276891\n",
      "abdecken annotatorA annotatorB 0.2887383573243014\n",
      "abdecken annotatorA annotatorC 0.7925531914893618\n",
      "abdecken annotatorB annotatorC 0.4734473447344735\n",
      "mean 0.5182462978493789\n",
      "abgebrüht annotatorA annotatorB 0.9592006661115737\n",
      "abgebrüht annotatorA annotatorC 1.0\n",
      "abgebrüht annotatorB annotatorC 0.9592006661115737\n",
      "mean 0.9728004440743825\n",
      "artikulieren annotatorA annotatorB 0.0\n",
      "artikulieren annotatorA annotatorC 0.0\n",
      "artikulieren annotatorB annotatorC nan\n",
      "mean 0.0\n",
      "aufrechterhalten annotatorA annotatorB nan\n",
      "aufrechterhalten annotatorA annotatorC nan\n",
      "aufrechterhalten annotatorB annotatorC nan\n",
      "mean nan\n",
      "ausspannen annotatorA annotatorB 0.826192400970089\n",
      "ausspannen annotatorA annotatorC 0.8950366151342555\n",
      "ausspannen annotatorB annotatorC 0.8"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean 0.8404096720347815\n",
      "beimischen annotatorA annotatorB nan\n",
      "beimischen annotatorA annotatorC nan\n",
      "beimischen annotatorB annotatorC nan\n",
      "mean nan\n",
      "packen annotatorA annotatorB 1.0\n",
      "packen annotatorA annotatorC 0.9042253521126761\n",
      "packen annotatorB annotatorC 0.9090909090909091\n",
      "mean 0.9377720870678617\n",
      "verbauen annotatorA annotatorB nan\n",
      "verbauen annotatorA annotatorC nan\n",
      "verbauen annotatorB annotatorC nan\n",
      "mean nan\n",
      "vergönnen annotatorA annotatorB nan\n",
      "vergönnen annotatorA annotatorC nan\n",
      "vergönnen annotatorB annotatorC nan\n",
      "mean nan\n",
      "voranstellen annotatorA annotatorB nan\n",
      "voranstellen annotatorA annotatorC nan\n",
      "voranstellen annotatorB annotatorC nan\n",
      "mean nan\n",
      "vorliegen annotatorA annotatorB nan\n",
      "vorliegen annotatorA annotatorC nan\n",
      "vorliegen annotatorB annotatorC nan\n",
      "mean nan\n",
      "vorweisen annotatorA annotatorB nan\n",
      "vorweisen annotatorA annotatorC nan\n",
      "vorweisen annotatorB annotatorC nan\n",
      "mean nan\n",
      "weitgreifend annotatorA annotatorB nan\n",
      "weitgreifend annotatorA annotatorC nan\n",
      "weitgreifend annotatorB annotatorC nan\n",
      "mean nan\n",
      "zersetzen annotatorA annotatorB 0.023474178403755874\n",
      "zersetzen annotatorA annotatorC 0.018181818181818188\n",
      "zersetzen annotatorB annotatorC 0.9586776859504132\n",
      "mean 0.3334445608453291\n",
      "überspannen annotatorA annotatorB 0.4\n",
      "überspannen annotatorA annotatorC 0.6\n",
      "überspannen annotatorB annotatorC 0.6162790697674418\n",
      "mean 0.5387596899224806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/metrics/_classification.py:658: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "<ipython-input-7-efbce51abafb>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(cohs)\n"
     ]
    }
   ],
   "source": [
    "cohs = []\n",
    "for a, b in combinations(annotators, 2):\n",
    "    data = df[~df[a].isnull() & ~df[b].isnull()]\n",
    "    coh = cohen_kappa_score(data[a], data[b])\n",
    "    print('full', a, b, coh)\n",
    "    cohs.append(coh)\n",
    "    \n",
    "mean = np.mean(cohs)    \n",
    "print('mean', mean)\n",
    "\n",
    "# By lemma\n",
    "groups = df.groupby(by=\"lemma\")\n",
    "data_groups = [groups.get_group(x) for x in groups.groups]    \n",
    "for i, lemma in enumerate(lemmas):\n",
    "    cohs = []\n",
    "    for a, b in combinations(annotators, 2):\n",
    "        data = data_groups[i]\n",
    "        data = data[~data[a].isnull() & ~data[b].isnull()]\n",
    "        coh = cohen_kappa_score(data[a], data[b])\n",
    "        print(lemma, a, b, coh)\n",
    "        cohs.append(coh)\n",
    "\n",
    "    mean = np.nanmean(cohs)    \n",
    "    print('mean', mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise Percentage Agreement\n",
    "- see https://dl.acm.org/doi/10.1162/coli.07-034-R2\n",
    "- as far as I understand (please verify) the same as inter-tagger agreement (ITA) used in early words sense annotation studies (e.g. SenseEval).\n",
    "- \"With WordNet, the sense inventory currently most widely used in word sense annotation, ITA ranges from 67% to 78%\" (Erk et al. 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full annotatorA annotatorB 0.8551724137931034\n",
      "full annotatorA annotatorC 0.8907646474677259\n",
      "full annotatorB annotatorC 0.8887841658812441\n",
      "mean 0.8782404090473578\n",
      "Abgesang annotatorA annotatorB 0.9428571428571428\n",
      "Abgesang annotatorA annotatorC 1.0\n",
      "Abgesang annotatorB annotatorC 0.9428571428571428\n",
      "mean 0.9619047619047619\n",
      "Ackergerät annotatorA annotatorB nan\n",
      "Ackergerät annotatorA annotatorC nan\n",
      "Ackergerät annotatorB annotatorC nan\n",
      "mean nan\n",
      "Armenhaus annotatorA annotatorB 1.0\n",
      "Armenhaus annotatorA annotatorC 1.0\n",
      "Armenhaus annotatorB annotatorC 1.0\n",
      "mean 1.0\n",
      "Ausnahmegesetz annotatorA annotatorB nan\n",
      "Ausnahmegesetz annotatorA annotatorC nan\n",
      "Ausnahmegesetz annotatorB annotatorC nan\n",
      "mean nan\n",
      "Dynamik annotatorA annotatorB 0.7906976744186046\n",
      "Dynamik annotatorA annotatorC 0.8372093023255813\n",
      "Dynamik annotatorB annotatorC 0.8222222222222222\n",
      "mean 0.8167097329888028\n",
      "Einreichung annotatorA annotatorB nan\n",
      "Einreichung annotatorA annotatorC nan\n",
      "Einreichung annotatorB annotatorC nan\n",
      "mean nan\n",
      "Eintagsfliege annotatorA annotatorB 0.9487179487179487\n",
      "Eintagsfliege annotatorA annotatorC 0.9487179487179487\n",
      "Eintagsfliege annotatorB annotatorC 0.9545454545454546\n",
      "mean 0.9506604506604507\n",
      "Engpaß annotatorA annotatorB 0.9791666666666666\n",
      "Engpaß annotatorA annotatorC 0.9574468085106383\n",
      "Engpaß annotatorB annotatorC 0.9583333333333334\n",
      "mean 0.9649822695035462\n",
      "Entscheidung annotatorA annotatorB nan\n",
      "Entscheidung annotatorA annotatorC nan\n",
      "Entscheidung annotatorB annotatorC nan\n",
      "mean nan\n",
      "Festspiel annotatorA annotatorB nan\n",
      "Festspiel annotatorA annotatorC nan\n",
      "Festspiel annotatorB annotatorC nan\n",
      "mean nan\n",
      "Frechheit annotatorA annotatorB nan\n",
      "Frechheit annotatorA annotatorC nan\n",
      "Frechheit annotatorB annotatorC nan\n",
      "mean nan\n",
      "Fuß annotatorA annotatorB 0.9767441860465116\n",
      "Fuß annotatorA annotatorC 0.9761904761904762\n",
      "Fuß annotatorB annotatorC 0.9333333333333333\n",
      "mean 0.9620893318567738\n",
      "Gesichtsausdruck annotatorA annotatorB nan\n",
      "Gesichtsausdruck annotatorA annotatorC nan\n",
      "Gesichtsausdruck annotatorB annotatorC nan\n",
      "mean nan\n",
      "Knotenpunkt annotatorA annotatorB 0.6486486486486487\n",
      "Knotenpunkt annotatorA annotatorC 0.9189189189189189\n",
      "Knotenpunkt annotatorB annotatorC 0.6046511627906976\n",
      "mean 0.7240729101194218\n",
      "Kubikmeter annotatorA annotatorB nan\n",
      "Kubikmeter annotatorA annotatorC nan\n",
      "Kubikmeter annotatorB annotatorC nan\n",
      "mean nan\n",
      "Lyzeum annotatorA annotatorB nan\n",
      "Lyzeum annotatorA annotatorC nan\n",
      "Lyzeum annotatorB annotatorC nan\n",
      "mean nan\n",
      "Manschette annotatorA annotatorB 0.9130434782608696\n",
      "Manschette annotatorA annotatorC 0.9565217391304348\n",
      "Manschette annotatorB annotatorC 0.9375\n",
      "mean 0.9356884057971016\n",
      "Mißklang annotatorA annotatorB 0.8695652173913043\n",
      "Mißklang annotatorA annotatorC 0.8888888888888888\n",
      "Mißklang annotatorB annotatorC 0.8297872340425532\n",
      "mean 0.8627471134409154\n",
      "Mulatte annotatorA annotatorB nan\n",
      "Mulatte annotatorA annotatorC nan\n",
      "Mulatte annotatorB annotatorC nan\n",
      "mean nan\n",
      "Naturschönheit annotatorA annotatorB nan\n",
      "Naturschönheit annotatorA annotatorC nan\n",
      "Naturschönheit annotatorB annotatorC nan\n",
      "mean nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohrwurm annotatorA annotatorB 1.0\n",
      "Ohrwurm annotatorA annotatorC 1.0\n",
      "Ohrwurm annotatorB annotatorC 1.0\n",
      "mean 1.0\n",
      "Pachtzins annotatorA annotatorB nan\n",
      "Pachtzins annotatorA annotatorC nan\n",
      "Pachtzins annotatorB annotatorC nan\n",
      "mean nan\n",
      "Rezeption annotatorA annotatorB 0.9591836734693877\n",
      "Rezeption annotatorA annotatorC 0.9795918367346939\n",
      "Rezeption annotatorB annotatorC 0.92\n",
      "mean 0.9529251700680272\n",
      "Schmiere annotatorA annotatorB 0.875\n",
      "Schmiere annotatorA annotatorC 0.8181818181818181\n",
      "Schmiere annotatorB annotatorC 0.8636363636363636\n",
      "mean 0.8522727272727272\n",
      "Seminar annotatorA annotatorB 0.782608695652174\n",
      "Seminar annotatorA annotatorC 0.7555555555555555\n",
      "Seminar annotatorB annotatorC 0.7777777777777778\n",
      "mean 0.7719806763285023\n",
      "Sensation annotatorA annotatorB 0.782608695652174\n",
      "Sensation annotatorA annotatorC 0.7391304347826086\n",
      "Sensation annotatorB annotatorC 0.88\n",
      "mean 0.8005797101449276\n",
      "Spielball annotatorA annotatorB 0.9591836734693877\n",
      "Spielball annotatorA annotatorC 0.9791666666666666\n",
      "Spielball annotatorB annotatorC 0.9791666666666666\n",
      "mean 0.9725056689342403\n",
      "Tier annotatorA annotatorB nan\n",
      "Tier annotatorA annotatorC nan\n",
      "Tier annotatorB annotatorC nan\n",
      "mean nan\n",
      "Titel annotatorA annotatorB 0.8823529411764706\n",
      "Titel annotatorA annotatorC 0.8181818181818181\n",
      "Titel annotatorB annotatorC 0.8823529411764706\n",
      "mean 0.8609625668449198\n",
      "Tragfähigkeit annotatorA annotatorB nan\n",
      "Tragfähigkeit annotatorA annotatorC nan\n",
      "Tragfähigkeit annotatorB annotatorC nan\n",
      "mean nan\n",
      "Truppenteil annotatorA annotatorB nan\n",
      "Truppenteil annotatorA annotatorC nan\n",
      "Truppenteil annotatorB annotatorC nan\n",
      "mean nan\n",
      "Unentschlossenheit annotatorA annotatorB nan\n",
      "Unentschlossenheit annotatorA annotatorC nan\n",
      "Unentschlossenheit annotatorB annotatorC nan\n",
      "mean nan\n",
      "abbauen annotatorA annotatorB 0.8695652173913043\n",
      "abbauen annotatorA annotatorC 0.9787234042553191\n",
      "abbauen annotatorB annotatorC 0.8723404255319149\n",
      "mean 0.9068763490595128\n",
      "abdecken annotatorA annotatorB 0.475\n",
      "abdecken annotatorA annotatorC 0.8717948717948718\n",
      "abdecken annotatorB annotatorC 0.6153846153846154\n",
      "mean 0.6540598290598291\n",
      "abgebrüht annotatorA annotatorB 0.9795918367346939\n",
      "abgebrüht annotatorA annotatorC 1.0\n",
      "abgebrüht annotatorB annotatorC 0.9795918367346939\n",
      "mean 0.9863945578231292\n",
      "artikulieren annotatorA annotatorB 0.96875\n",
      "artikulieren annotatorA annotatorC 0.96875\n",
      "artikulieren annotatorB annotatorC 1.0\n",
      "mean 0.9791666666666666\n",
      "aufrechterhalten annotatorA annotatorB nan\n",
      "aufrechterhalten annotatorA annotatorC nan\n",
      "aufrechterhalten annotatorB annotatorC nan\n",
      "mean nan\n",
      "ausspannen annotatorA annotatorB 0.8837209302325582\n",
      "ausspannen annotatorA annotatorC 0.9302325581395349\n",
      "ausspannen annotatorB annotatorC 0.8636363636363636\n",
      "mean 0.8925299506694856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beimischen annotatorA annotatorB nan\n",
      "beimischen annotatorA annotatorC nan\n",
      "beimischen annotatorB annotatorC nan\n",
      "mean nan\n",
      "packen annotatorA annotatorB 1.0\n",
      "packen annotatorA annotatorC 0.9411764705882353\n",
      "packen annotatorB annotatorC 0.9444444444444444\n",
      "mean 0.9618736383442266\n",
      "verbauen annotatorA annotatorB nan\n",
      "verbauen annotatorA annotatorC nan\n",
      "verbauen annotatorB annotatorC nan\n",
      "mean nan\n",
      "vergönnen annotatorA annotatorB nan\n",
      "vergönnen annotatorA annotatorC nan\n",
      "vergönnen annotatorB annotatorC nan\n",
      "mean nan\n",
      "voranstellen annotatorA annotatorB nan\n",
      "voranstellen annotatorA annotatorC nan\n",
      "voranstellen annotatorB annotatorC nan\n",
      "mean nan\n",
      "vorliegen annotatorA annotatorB nan\n",
      "vorliegen annotatorA annotatorC nan\n",
      "vorliegen annotatorB annotatorC nan\n",
      "mean nan\n",
      "vorweisen annotatorA annotatorB nan\n",
      "vorweisen annotatorA annotatorC nan\n",
      "vorweisen annotatorB annotatorC nan\n",
      "mean nan\n",
      "weitgreifend annotatorA annotatorB nan\n",
      "weitgreifend annotatorA annotatorC nan\n",
      "weitgreifend annotatorB annotatorC nan\n",
      "mean nan\n",
      "zersetzen annotatorA annotatorB 0.45833333333333337\n",
      "zersetzen annotatorA annotatorC 0.4375\n",
      "zersetzen annotatorB annotatorC 0.98\n",
      "mean 0.6252777777777778\n",
      "überspannen annotatorA annotatorB 0.6222222222222222\n",
      "überspannen annotatorA annotatorC 0.7333333333333334\n",
      "überspannen annotatorB annotatorC 0.7555555555555555\n",
      "mean 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/lib64/python3.10/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-8-0b27e1762e14>:23: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(pers)\n"
     ]
    }
   ],
   "source": [
    "pers = []\n",
    "for a, b in combinations(annotators, 2):\n",
    "    data = df[~df[a].isnull() & ~df[b].isnull()]\n",
    "    per = 1-hamming_loss(data[a], data[b])\n",
    "    print('full', a, b, per)\n",
    "    pers.append(per)\n",
    "    \n",
    "mean = np.mean(pers)    \n",
    "print('mean', mean)\n",
    "\n",
    "# By lemma\n",
    "groups = df.groupby(by=\"lemma\")\n",
    "data_groups = [groups.get_group(x) for x in groups.groups]    \n",
    "for i, lemma in enumerate(lemmas):\n",
    "    pers = []\n",
    "    for a, b in combinations(annotators, 2):\n",
    "        data = data_groups[i]\n",
    "        data = data[~data[a].isnull() & ~data[b].isnull()]\n",
    "        per = 1-hamming_loss(data[a], data[b])\n",
    "        print(lemma, a, b, per)\n",
    "        pers.append(per)\n",
    "\n",
    "    mean = np.nanmean(pers)    \n",
    "    print('mean', mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Krippendorf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full 0.8734491989957522\n",
      "full annotatorA annotatorB 0.8519030313743345\n",
      "full annotatorA annotatorC 0.8882605729326465\n",
      "full annotatorB annotatorC 0.8862822946006377\n",
      "Abgesang 0.8930041152263375\n",
      "Ackergerät nan\n",
      "Armenhaus 1.0\n",
      "Ausnahmegesetz nan\n",
      "Dynamik 0.6264150943396227\n",
      "Einreichung nan\n",
      "Eintagsfliege 0.9061102831594635\n",
      "Engpaß 0.9171461449942463\n",
      "Entscheidung nan\n",
      "Festspiel nan\n",
      "Frechheit nan\n",
      "Fuß 0.9359653346172364\n",
      "Gesichtsausdruck nan\n",
      "Knotenpunkt 0.3261627906976744\n",
      "Kubikmeter nan\n",
      "Lyzeum nan\n",
      "Manschette 0.7934368590682683\n",
      "Mißklang 0.5689655172413792\n",
      "Mulatte nan\n",
      "Naturschönheit nan\n",
      "Ohrwurm 1.0\n",
      "Pachtzins nan\n",
      "Rezeption 0.7705426356589147\n",
      "Schmiere 0.8061628345269506\n",
      "Seminar 0.6218834080717488\n",
      "Sensation 0.4288340336134454\n",
      "Spielball 0.6547619047619048\n",
      "Tier nan\n",
      "Titel 0.7679558011049723\n",
      "Tragfähigkeit nan\n",
      "Truppenteil nan\n",
      "Unentschlossenheit nan\n",
      "abbauen 0.8418015707645456\n",
      "abdecken 0.4898085237801112\n",
      "abgebrüht 0.972972972972973\n",
      "artikulieren 0.0\n",
      "aufrechterhalten nan\n",
      "ausspannen 0.8423423423423424\n",
      "beimischen nan\n",
      "packen 0.9395992097092859\n",
      "verbauen nan\n",
      "vergönnen nan\n",
      "voranstellen nan\n",
      "vorliegen nan\n",
      "vorweisen nan\n",
      "weitgreifend nan\n",
      "zersetzen 0.2556264066016505\n",
      "überspannen 0.5359307359307359\n"
     ]
    }
   ],
   "source": [
    "# Full data\n",
    "data = np.transpose(df.loc[:, annotators[0]:annotators[-1]].values)\n",
    "kri = krippendorff.alpha(reliability_data=data, level_of_measurement='nominal')\n",
    "print('full', kri)\n",
    "\n",
    "# Pairwise\n",
    "for a, b in combinations(annotators, 2):\n",
    "    data = [df[a].values, df[b].values]\n",
    "    kri = krippendorff.alpha(reliability_data=data, level_of_measurement='nominal')\n",
    "    print('full', a, b, kri)\n",
    "\n",
    "\n",
    "# By lemma\n",
    "groups = df.groupby(by=\"lemma\")\n",
    "data_groups = [groups.get_group(x) for x in groups.groups]\n",
    "for i, lemma in enumerate(lemmas):\n",
    "    data = np.transpose(data_groups[i].loc[:, annotators[0]:annotators[-1]].values)\n",
    "    #print(data)\n",
    "    try:\n",
    "        kri = krippendorff.alpha(reliability_data=data, level_of_measurement='nominal')\n",
    "    except AssertionError:\n",
    "        kri = np.nan\n",
    "    print(lemma, kri)\n",
    "    #print(data_groups[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract majority labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          cluster           lemma  annotatorA  \\\n",
      "treitschke_geschichte02_1882-7387-3           0.0  Ausnahmegesetz         NaN   \n",
      "2532889X_1978-04-01_01_229.tcf.xml-40-11      0.0  Ausnahmegesetz         NaN   \n",
      "treitschke_geschichte02_1882-8135-23          0.0  Ausnahmegesetz         NaN   \n",
      "treitschke_geschichte03_1885-129-10           0.0  Ausnahmegesetz         NaN   \n",
      "26120215_1963_06_01_01_068.tcf.xml-26-4       0.0  Ausnahmegesetz         NaN   \n",
      "...                                           ...             ...         ...   \n",
      "beyer_poetik01_1882-7723-51                   NaN        Mißklang       801.0   \n",
      "robert_griechische_1881-1366-6                NaN           Titel         NaN   \n",
      "savigny_system01_1840-2586-21                 NaN           Titel      1506.0   \n",
      "26120215_1966_07_27_01_394.tcf.xml-9-7        NaN           Titel         NaN   \n",
      "2532889X_1966-05-09_01_147.tcf.xml-3-5        NaN           Titel      1504.0   \n",
      "\n",
      "                                          annotatorB  annotatorC  \\\n",
      "treitschke_geschichte02_1882-7387-3              NaN         NaN   \n",
      "2532889X_1978-04-01_01_229.tcf.xml-40-11         NaN         NaN   \n",
      "treitschke_geschichte02_1882-8135-23             NaN         NaN   \n",
      "treitschke_geschichte03_1885-129-10              NaN         NaN   \n",
      "26120215_1963_06_01_01_068.tcf.xml-26-4          NaN         NaN   \n",
      "...                                              ...         ...   \n",
      "beyer_poetik01_1882-7723-51                      NaN         NaN   \n",
      "robert_griechische_1881-1366-6                1503.0         NaN   \n",
      "savigny_system01_1840-2586-21                 1503.0      1503.0   \n",
      "26120215_1966_07_27_01_394.tcf.xml-9-7        1505.0         NaN   \n",
      "2532889X_1966-05-09_01_147.tcf.xml-3-5        1504.0      1504.0   \n",
      "\n",
      "                                          label_count_andere   maj_1   maj_2  \\\n",
      "treitschke_geschichte02_1882-7387-3                      0.0     NaN     NaN   \n",
      "2532889X_1978-04-01_01_229.tcf.xml-40-11                 0.0     NaN     NaN   \n",
      "treitschke_geschichte02_1882-8135-23                     0.0     NaN     NaN   \n",
      "treitschke_geschichte03_1885-129-10                      0.0     NaN     NaN   \n",
      "26120215_1963_06_01_01_068.tcf.xml-26-4                  0.0     NaN     NaN   \n",
      "...                                                      ...     ...     ...   \n",
      "beyer_poetik01_1882-7723-51                              0.0     NaN     NaN   \n",
      "robert_griechische_1881-1366-6                           0.0  1503.0     NaN   \n",
      "savigny_system01_1840-2586-21                            0.0  1503.0  1503.0   \n",
      "26120215_1966_07_27_01_394.tcf.xml-9-7                   0.0     NaN     NaN   \n",
      "2532889X_1966-05-09_01_147.tcf.xml-3-5                   0.0  1504.0  1504.0   \n",
      "\n",
      "                                           maj_3  \n",
      "treitschke_geschichte02_1882-7387-3          NaN  \n",
      "2532889X_1978-04-01_01_229.tcf.xml-40-11     NaN  \n",
      "treitschke_geschichte02_1882-8135-23         NaN  \n",
      "treitschke_geschichte03_1885-129-10          NaN  \n",
      "26120215_1963_06_01_01_068.tcf.xml-26-4      NaN  \n",
      "...                                          ...  \n",
      "beyer_poetik01_1882-7723-51                  NaN  \n",
      "robert_griechische_1881-1366-6               NaN  \n",
      "savigny_system01_1840-2586-21                NaN  \n",
      "26120215_1966_07_27_01_394.tcf.xml-9-7       NaN  \n",
      "2532889X_1966-05-09_01_147.tcf.xml-3-5    1504.0  \n",
      "\n",
      "[8375 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_majority_label(row, columns, threshold, index):\n",
    "    label2count = Counter(row[columns])\n",
    "    majority_labels = [l for l, c in label2count.items() if c >= threshold]\n",
    "    if len(majority_labels) > 0:\n",
    "        label = np.random.choice(majority_labels)\n",
    "    else:\n",
    "        label = np.NaN  \n",
    "    #print(label, row, columns, index, index+['maj_'+str(threshold)])\n",
    "    out_data = pd.Series(row.to_list()+[label], index=index+['maj_'+str(threshold)])\n",
    "    return out_data\n",
    "        \n",
    "df = df.apply(lambda x: extract_majority_label(x, annotators, 1, index=list(df.columns)), axis=1)\n",
    "df = df.apply(lambda x: extract_majority_label(x, annotators, 2, index=list(df.columns)), axis=1)\n",
    "df = df.apply(lambda x: extract_majority_label(x, annotators, 3, index=list(df.columns)), axis=1)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to inferred clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- condition annotatorA -----\n",
      "mean 0.5025746601524207\n",
      "----- condition maj_2 -----\n",
      "mean 0.5829602562214008\n",
      "----- condition maj_3 -----\n",
      "mean 0.6521181994175511\n"
     ]
    }
   ],
   "source": [
    "# By lemma\n",
    "majs = ['annotatorA', 'maj_2','maj_3']\n",
    "namess = []\n",
    "file2variables = {'semeval-correlation-2.5':[]}\n",
    "for maj in majs:\n",
    "    print('-----','condition', maj, '-----') \n",
    "    names = []\n",
    "    aris = []\n",
    "    groups = df.groupby(by=\"lemma\")\n",
    "    data_groups = [groups.get_group(x) for x in groups.groups]\n",
    "    for i, lemma in enumerate(lemmas):\n",
    "        data = data_groups[i].reindex(columns = ['cluster', maj])\n",
    "        #data = np.transpose(data.values)\n",
    "        data = np.transpose(data[(~data['cluster'].isnull()) & (~data[maj].isnull())].values)\n",
    "        #print(data)\n",
    "        if len(data[0]) == 0 :\n",
    "            continue\n",
    "        names.append(lemma)\n",
    "        ari = adjusted_rand_score(data[0], data[1])\n",
    "        #print(lemma, ari, len(data[0]))\n",
    "        aris.append(ari)\n",
    "        #print(data_groups[i])\n",
    "\n",
    "    namess.append(names)    \n",
    "    file2variables['semeval-correlation-2.5'].append(aris) \n",
    "    mean = np.mean(aris)    \n",
    "    print('mean', mean)\n",
    "\n",
    "for (names1, names2) in combinations(namess,2):\n",
    "    if (names1 != names2):\n",
    "        print(names1, '\\n', names2)\n",
    "        sys.exit('Breaking: names in columns don\\'t match.')\n",
    "        \n",
    "names = namess[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "variable_names = majs\n",
    "for (i, name) in enumerate(variable_names):\n",
    "    \n",
    "    if not name == 'maj_3':\n",
    "        continue\n",
    "        \n",
    "    name = 'ARI'\n",
    "    \n",
    "    variable_over_files = np.transpose(np.array([file2variables[filename][i] for filename in file2variables.keys()]))\n",
    "    df = DataFrame(variable_over_files, index=names, columns=list(file2variables.keys()))\n",
    "    df.sort_values([list(file2variables.keys())[0]], ascending=[True], inplace=True)\n",
    "    #df.to_numpy()\n",
    "    #df=(df-df.min())/(df.max()-df.min()) # normalize columns\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.ylabel(name, fontsize='large')\n",
    "    #plt.ylim(0.85, 4.15)\n",
    "    #print(df)\n",
    "    plt.xticks(np.arange(0,len(df.index)*3,3), df.index, fontsize='medium', rotation=45)\n",
    "    for filename in file2variables.keys():\n",
    "        #print(filename)\n",
    "        variable = df[filename]\n",
    "        plt.plot(np.arange(0,len(variable)*3,3), variable, label=filename[:20], marker='o', color='k', linestyle='None')\n",
    "    #plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #plt.savefig('ari-scores.png', dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nan_count(row, columns, index):\n",
    "    nan_count = row[columns].isna().sum()\n",
    "    #print(nan_count)\n",
    "    out_data = pd.Series(row.to_list()+[nan_count], index=index+['nans_'+'_'.join(columns)])\n",
    "    return out_data\n",
    "        \n",
    "df_description = df_description.apply(lambda x: extract_nan_count(x, annotators, index=list(df_description.columns)), axis=1)\n",
    "#print(df_description)\n",
    "\n",
    "indexes_none = df_description[ np.isnan(df_description[annotators[0]]) | \n",
    "                np.isnan(df_description[annotators[1]]) | np.isnan(df_description[annotators[2]])].index  \n",
    "print('total number of sense description annotations:', len(df_description.index))\n",
    "for i in [1,2,3]:\n",
    "    print('number of instances with exactly {0} missing annotations:'.format(i), \n",
    "      len(df_description[ df_description['nans_'+'_'.join(annotators)] == i].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_disagreement_0 = df[(~df['maj_3'].isnull())].index\n",
    "indexes_disagreement_1 = df[(~df['maj_2'].isnull()) & (df['maj_3'].isnull())].index\n",
    "indexes_disagreement_3 = df[(~df['maj_1'].isnull()) & (df['maj_2'].isnull())].index\n",
    "print('number of instances with exactly 3 agreeing annotators:', len(indexes_disagreement_0))\n",
    "print('number of instances with exactly 2 agreeing annotators:', len(indexes_disagreement_1))\n",
    "print('number of instances with exactly 0 agreeing annotators:', len(indexes_disagreement_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3]:\n",
    "    print('number of instances with exactly {0} \\'andere\\' annotations:'.format(i), \n",
    "      len(df[ df['label_count_andere'] == i].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- agreement on sense description annotation is high with 0.82 Krippendorf's alpha, percentage agreement (ITA) and pairwise Cohen's Kappa.\n",
    "- Nikolai: how is agreement on binary WiC annotation, e.g. recent competition you participated in?\n",
    "- low agreement between annotators A versus B and C on *zersetzen* comes from this: the word has mainly two senses 'to destroy' and 'to dissolve'. Annotator A chose to annotate instances of a chemical or physical dissolving with the sense 'to destroy', while the others chose to annotate it with the sense 'to dissolve'.\n",
    "- correspondence between sense description annotation and inferred clusterings was 0.5 (ARI) for annotatorA and is now considerably higher with 0.59/0.65 for a threshold of 2/3 agreeing annotations of the three annotators.\n",
    "- using opt clusterings instead of semeval yields the same results (less than 0.01 improvement).\n",
    "- removing instances annotated with at least one 'andere' label increases agreement scores to 0.88, but has no effect on correspondence with inferred clusterings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do\n",
    "- in future: annotate semantic proximity of sense descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To come\n",
    "- which effect on correspondence have different clustering methods\n",
    "- which effect has additional data on the graph clusterings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pairwise proximity annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../../data/dwug_de_1.1.0/data'\n",
    "judgments_pairwise = []\n",
    "for root, subdirectories, files in os.walk(input_path):\n",
    "    for f in files:\n",
    "        path = os.path.join(root, f)\n",
    "        if f=='judgments.csv':\n",
    "            with open(path, encoding='utf-8') as csvfile: \n",
    "                reader = csv.DictReader(csvfile, delimiter='\\t',quoting=csv.QUOTE_NONE,strict=True)\n",
    "                table = [row for row in reader]\n",
    "                judgments_pairwise = judgments_pairwise + table\n",
    "\n",
    "# Transform data format            \n",
    "annotators_pairwise = sorted(list(set([row['annotator'] for row in judgments_pairwise])))\n",
    "identifier2annotator2judgment = defaultdict(lambda: {})\n",
    "for row in judgments_pairwise:\n",
    "    identifier2annotator2judgment[(frozenset((row['identifier1'],row['identifier2'])),row['lemma'])] |= {row['annotator']:float(row['judgment'])}    \n",
    "#print(identifier2annotator2judgment)\n",
    "judgment_pairwise_transformed = [{'identifier':identifier1+'__'+identifier2} | \n",
    "                                 {annotator:annotator2judgment[annotator] if annotator in annotator2judgment else np.NaN for annotator in annotators_pairwise} | \n",
    "                                 {'lemma':lemma} for (((identifier1,identifier2),lemma), annotator2judgment) \n",
    "                                 in identifier2annotator2judgment.items()]\n",
    "variable_names = list(judgment_pairwise_transformed[0].keys())\n",
    "variable_names.remove('identifier')\n",
    "index = [row['identifier'] for row in judgment_pairwise_transformed]\n",
    "variables = [[row[name] for row in judgment_pairwise_transformed] for name in variable_names]\n",
    "df_pairwise = DataFrame(np.transpose(variables), index=index, columns=variable_names)\n",
    "for annotator in annotators_pairwise:\n",
    "    df_pairwise[annotator] = df_pairwise[annotator].astype(float)\n",
    "    #print(len(df_pairwise[df_pairwise[annotator]==0.0].index))\n",
    "    df_pairwise[annotator] = df_pairwise[annotator].replace(0.0, np.NaN)\n",
    "df_pairwise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_median(row, columns, index):\n",
    "    #print(row[columns].to_list())\n",
    "    median = np.nanmedian(row[columns].to_list())\n",
    "    out_data = pd.Series(row.to_list()+[median], index=index+['median'])\n",
    "    return out_data\n",
    "def extract_std(row, columns, index):\n",
    "    #print(row[columns].to_list())\n",
    "    std = np.nanstd(row[columns].to_list())\n",
    "    out_data = pd.Series(row.to_list()+[std], index=index+['std'])\n",
    "    return out_data\n",
    "         \n",
    "# Add annotator number column\n",
    "df_pairwise['annotator_no'] = df_pairwise[annotators_pairwise].count(axis=1) \n",
    "    \n",
    "# Add median and std column\n",
    "df_pairwise = df_pairwise.apply(lambda x: extract_median(x, annotators_pairwise, list(df_pairwise.columns)), axis=1)\n",
    "df_pairwise = df_pairwise.apply(lambda x: extract_std(x, annotators_pairwise, list(df_pairwise.columns)), axis=1)\n",
    "\n",
    "# Add binarize column\n",
    "df_pairwise['binarized'] = np.NaN\n",
    "indices_1 = df_pairwise[(df_pairwise['median']==4.0) & (df_pairwise['std']==0.0)\n",
    "                        & (df_pairwise['annotator_no']>1)].index\n",
    "indices_0 = df_pairwise[( (df_pairwise['median']==1.0) | (df_pairwise['median']==2.0)) \n",
    "                        & (df_pairwise['std']==0.0) & (df_pairwise['annotator_no']>1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairwise.loc[indices_1,'binarized'] = 1.0\n",
    "df_pairwise.loc[indices_0,'binarized'] = 0.0\n",
    "\n",
    "# Add column with pairwise annotation derived from sense annotation\n",
    "for column in df.columns:\n",
    "    if column=='lemma':\n",
    "        continue\n",
    "    df_pairwise[column] = np.NaN\n",
    "    \n",
    "for ((identifier1,identifier2),lemma) in identifier2annotator2judgment:\n",
    "    if (not identifier1 in df.index) or (not identifier2 in df.index):\n",
    "        continue\n",
    "    for column in df.columns:\n",
    "        if column=='lemma':\n",
    "            continue\n",
    "        judgment1, judgment2 = df.loc[identifier1,column], df.loc[identifier2,column]\n",
    "        if np.isnan(judgment1) or np.isnan(judgment2):\n",
    "            judgment_derived = np.NaN\n",
    "        elif judgment1==judgment2:\n",
    "            judgment_derived = 1.0\n",
    "        else:\n",
    "            judgment_derived = 0.0\n",
    "        if identifier1 + '__' + identifier2 in df_pairwise.index:\n",
    "            df_pairwise.loc[identifier1 + '__' + identifier2,column] = judgment_derived\n",
    "            #if lemma=='Armenhaus' and column=='maj_2':\n",
    "            #    print(judgment1, judgment2, judgment_derived)\n",
    "        elif identifier2 + '__' + identifier1 in df_pairwise.index:\n",
    "            df_pairwise.loc[identifier2 + '__' + identifier1,column] = judgment_derived\n",
    "        else:\n",
    "            df_pairwise.loc[identifier1 + '__' + identifier2,column] = judgment_derived\n",
    "\n",
    "#print(df_pairwise[(df_pairwise['lemma']=='Armenhaus')])\n",
    "#print(len(df_pairwise[(~df_pairwise['maj_2'].isnull()) & (df_pairwise['lemma']=='Armenhaus')].index))\n",
    "\n",
    "indexes_binarized = df_pairwise[(~df_pairwise['binarized'].isnull())].index\n",
    "indexes_annotatorA = df_pairwise[(~df_pairwise['annotatorA'].isnull())].index\n",
    "indexes_maj_2 = df_pairwise[(~df_pairwise['maj_2'].isnull())].index\n",
    "indexes_maj_3 = df_pairwise[(~df_pairwise['maj_3'].isnull())].index\n",
    "print('number of binarized instances from pairwise proximity annotation:', len(indexes_binarized))\n",
    "print('number of inferred pairwise instances from annotatorA condition on sense annotation:', len(indexes_annotatorA))\n",
    "print('number of inferred pairwise instances from maj_2 condition on sense annotation:', len(indexes_maj_2))\n",
    "print('number of inferred pairwise instances from maj_3 condition on sense annotation:', len(indexes_maj_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate accuracy between (reliable) pairwise annotation and inferred pairwise annotation from senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in ['binarized']:\n",
    "    for b in ['annotatorA', 'maj_2', 'maj_3']:\n",
    "        data = df_pairwise[~df_pairwise[a].isnull() & ~df_pairwise[b].isnull()]\n",
    "        score = accuracy_score(data[a], data[b])\n",
    "        print(a, b, score)\n",
    "        print('majority class baseline:', max([accuracy_score(data[a], [0.0]*len(data.index)), \n",
    "                                            accuracy_score(data[a], [1.0]*len(data.index))]))\n",
    "        print('number of evaluation instances:', len(data.index))\n",
    "        #print('number of instances where {0} is not nan:'.format(a), len(df_pairwise[~df_pairwise[a].isnull()].index))\n",
    "        #print('number of instances where {0} is not nan:'.format(b), len(df_pairwise[~df_pairwise[b].isnull()].index))\n",
    "print('-----')\n",
    "\n",
    "# By lemma\n",
    "lemmas = sorted(list(set(df_pairwise['lemma'])))\n",
    "#print('number of lemmas:', len(lemmas))\n",
    "groups = df_pairwise.groupby(by=\"lemma\")\n",
    "data_groups = [groups.get_group(x) for x in groups.groups]    \n",
    "for i, lemma in enumerate(lemmas):\n",
    "    data_full = data_groups[i]\n",
    "    for a in ['binarized']:\n",
    "        for b in ['annotatorA', 'maj_2', 'maj_3']:\n",
    "            data = data_full[(~data_full[a].isnull()) & (~data_full[b].isnull())]\n",
    "            score = accuracy_score(data[a], data[b])\n",
    "            if not np.isnan(score):\n",
    "                print(lemma, a, b, score)\n",
    "                print('majority class baseline:', max([accuracy_score(data[a], [0.0]*len(data.index)), \n",
    "                                            accuracy_score(data[a], [1.0]*len(data.index))]))\n",
    "                print('number of evaluation instances:', len(data.index))\n",
    "                #print('number of instances where {0} is not nan:'.format(a), len(data_full[(~data_full[a].isnull())].index))\n",
    "                #print('number of instances where {0} is not nan:'.format(b), len(data_full[(~data_full[b].isnull())].index))\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- accuracy of cleaned and binarized pairwise annotation with inferred pairwise annotation from sense description annotation is 0.87/0.94/0.99 for conditions annotatorA/maj_2/maj_3. This means that if annotators show high agreement on either type of annotation they lead to the same (0.99) results in terms of binary sense distinctions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
