{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Garrafao/WUGs/blob/main/scripts/misc/wic2wug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zASMJ4H54r0-",
        "outputId": "cb41aaa2-9792-4253-e7c1-baeb53fb6571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-26 12:23:34--  https://pilehvar.github.io/wic/package/WiC_dataset.zip\n",
            "Resolving pilehvar.github.io (pilehvar.github.io)... 185.199.108.153, 185.199.110.153, 185.199.109.153, ...\n",
            "Connecting to pilehvar.github.io (pilehvar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 275984 (270K) [application/zip]\n",
            "Saving to: ‘WiC_dataset.zip.2’\n",
            "\n",
            "WiC_dataset.zip.2   100%[===================>] 269.52K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-05-26 12:23:35 (6.80 MB/s) - ‘WiC_dataset.zip.2’ saved [275984/275984]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://pilehvar.github.io/wic/package/WiC_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "aNQkbcRaC6B5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "5WhCmopMAQ86"
      },
      "outputs": [],
      "source": [
        "os.makedirs('WiC_data', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "anEsLLliMf-P"
      },
      "outputs": [],
      "source": [
        "path = 'WiC_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "PU7JiunOJINI"
      },
      "outputs": [],
      "source": [
        "dev = os.makedirs(path + '/dev', exist_ok=True )\n",
        "train = os.makedirs(path + '/train', exist_ok=True )\n",
        "test = os.makedirs(path+ '/test', exist_ok=True )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "SyIzMi43Nl8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c213935-510b-46d2-9729-d24e35d49c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "aKZGpmjJNoAB"
      },
      "outputs": [],
      "source": [
        "fold = 'WiC_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "U21Til5c5CnA"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('WiC_dataset.zip', 'r') as WiC:\n",
        "   WiC.extractall(fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "eFcviWmS3saH"
      },
      "outputs": [],
      "source": [
        "ds = os.listdir(fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "nCdIytsf7F87"
      },
      "outputs": [],
      "source": [
        "ds.remove('README.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "A9unNJtRB9NA"
      },
      "outputs": [],
      "source": [
        "pathss = []\n",
        "for i in ds:\n",
        "  pathss.append(fold +'/' + i + '/' + i+'.data.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "s_hVKk_87Oyd"
      },
      "outputs": [],
      "source": [
        "path_jud = []\n",
        "for i in ds:\n",
        "  path_jud.append(fold + '/' + i + '/' + i+'.gold.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "5MHbaruW5enp"
      },
      "outputs": [],
      "source": [
        "df_all = pd.DataFrame()\n",
        "for i in pathss:\n",
        "  df_3 = pd.read_csv(i, sep = '\\t', names=[\"lemma\", \"pos\", \"indice\", \"sent1\", \"sent2\"], encoding = 'UTF-8')\n",
        "  df_3['dataset'] = i.split('/')[1]\n",
        "  df_all = pd.concat([df_all, df_3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "SFeVzJy_7Znz"
      },
      "outputs": [],
      "source": [
        "df_all_labels = pd.DataFrame()\n",
        "for i in path_jud:\n",
        "  tmp = pd.read_csv(i, sep = '\\t', names = ['judgment'], encoding = 'UTF-8')\n",
        "  tmp['dataset'] = i.split('/')[1]\n",
        "  df_all_labels = pd.concat([df_all_labels, tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "7UShtKK95Sdo"
      },
      "outputs": [],
      "source": [
        "x= df_all['indice'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "SMgjk6VXPX77"
      },
      "outputs": [],
      "source": [
        "def create_ident(sent1, ind, lemma):\n",
        "  x1 = str(ind).split('-')[0]\n",
        "  id1 = lemma+'_' + x1 +'_' + sent1\n",
        "  return id1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "erAZAk_PQOuv"
      },
      "outputs": [],
      "source": [
        "def create_ident2(sent2, ind, lemma):\n",
        "  x2 = str(ind).split('-')[1]\n",
        "  id2 = lemma+'_' + x2 +'_' + sent2 \n",
        "  return id2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "XzEj0ecvQkAZ"
      },
      "outputs": [],
      "source": [
        "df_ = df_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "bQpzp8M-Qu1I"
      },
      "outputs": [],
      "source": [
        "df_['id1'] = df_.apply(lambda x: create_ident(x.sent1, x.indice, x.lemma), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "0jaJ1JiH0InE"
      },
      "outputs": [],
      "source": [
        "df_['id2'] = df_.apply(lambda x: create_ident2(x.sent2, x.indice, x.lemma), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "ns6w4rzApOcg"
      },
      "outputs": [],
      "source": [
        "df_judgments = df_[['id1', 'id2', 'lemma', 'dataset']]\n",
        "df_judgments = df_judgments.rename(columns = {'id1':'identifier1', 'id2': 'identifier2'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "RVr7AM80qxlv"
      },
      "outputs": [],
      "source": [
        "df_judgments['annotator'] = 'gold'\n",
        "df_judgments['comment'] = ' '\n",
        "df_judgments['judgment'] = df_all_labels[\"judgment\"].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "3MB6hzaOq8dy"
      },
      "outputs": [],
      "source": [
        "df_judgments = df_judgments[[\"identifier1\", \"identifier2\", \"annotator\", \"judgment\", \"comment\", \"lemma\", 'dataset']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "yDdbcXfQ7gSh"
      },
      "outputs": [],
      "source": [
        "df_dash = df_[['lemma', 'sent1', 'sent2', 'dataset', 'id1', 'id2']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "-ANHu2jj1YZ8"
      },
      "outputs": [],
      "source": [
        "df1 = df_dash[['lemma', 'sent1', 'dataset', 'id1']]\n",
        "df1.columns =  ['word', 'sent', 'dataset', 'id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "8ENUewpV5lH-"
      },
      "outputs": [],
      "source": [
        "df2 =  df_dash[['lemma', 'sent2', 'dataset', 'id2']]\n",
        "df2.columns =  ['word', 'sent', 'dataset', 'id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "npdDVwrR5w_5"
      },
      "outputs": [],
      "source": [
        "df_final = pd.concat([df1, df2])\n",
        "df_final= df_final.sort_values(by = ['word'], ascending = True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "-U-Iagi49lvw"
      },
      "outputs": [],
      "source": [
        "dftodict = pd.unique(df_final[['sent', 'id']].values.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "cAOi9nuV-7Tk"
      },
      "outputs": [],
      "source": [
        "result_df = df_final.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "Mb2KEm3Q_Dxx"
      },
      "outputs": [],
      "source": [
        "sent_to_id = pd.Series(result_df.id.values,index=result_df.sent).to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "ViTntw-4GRaD"
      },
      "outputs": [],
      "source": [
        "ind1 = []\n",
        "ind2 = []\n",
        "for i in x:\n",
        "    ind1.append(i.split('-')[0])\n",
        "    ind2.append(i.split('-')[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "HqWbHmIGGzQU"
      },
      "outputs": [],
      "source": [
        "df_all.loc[:,'ind1'] = ind1\n",
        "df_all.loc[:,'ind2'] = ind2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "YUtnwQu9F8ZD"
      },
      "outputs": [],
      "source": [
        "df1 = df_all[['lemma', 'pos', 'sent1', 'ind1', 'dataset']]\n",
        "df1.columns =  ['lemma','pos', 'context_tokenized','ind', 'dataset']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "3f_E_QijHH4X"
      },
      "outputs": [],
      "source": [
        "df2 = df_all[['lemma', 'pos', 'sent2', 'ind2', 'dataset']]\n",
        "df2.columns =  ['lemma','pos', 'context_tokenized','ind', 'dataset']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "A4nAuBb7Kbmi"
      },
      "outputs": [],
      "source": [
        "df_final_uses = pd.concat([df1, df2])\n",
        "df_final_uses = df_final_uses.sort_values(by = ['lemma'], ascending = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "6s47rUQm873_"
      },
      "outputs": [],
      "source": [
        "df_final_uses = df_final_uses.reset_index(drop =True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_uses = df_final_uses.drop_duplicates()"
      ],
      "metadata": {
        "id": "12wMoPe6QfGp"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "unW1QgHvNMle"
      },
      "outputs": [],
      "source": [
        "def get_indice(sent, indice):\n",
        "  tag = ''\n",
        "  indice = int(indice)\n",
        "  tok = sent.split(\" \")\n",
        "  #print(tok)\n",
        "  for i in range(len(tok)):\n",
        "    if i == indice:\n",
        "      tag = tok[i]\n",
        "  return str(sent.find(tag))+\":\"+str(sent.find(tag)+len(tag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "bsgDiCA4VfBM"
      },
      "outputs": [],
      "source": [
        "df_final_uses[\"indexes_target_token\"] = df_final_uses.apply(lambda x: get_indice(x.context_tokenized, x.ind), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "KdfdHVEMtid9"
      },
      "outputs": [],
      "source": [
        "def get_indices_of_sent(sentence):\n",
        "    return \"0:\"+str(len(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "_5jXzydPujr9"
      },
      "outputs": [],
      "source": [
        "df_final_uses[\"indexes_target_sentence\"] = df_final_uses[\"context_tokenized\"].apply(get_indices_of_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "s6_TKjfTu_Xz"
      },
      "outputs": [],
      "source": [
        "def get_len_tok(sentence):\n",
        "  return \"0:\"+str(len(sentence.split(\" \")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "UR4qpS2vumQ2"
      },
      "outputs": [],
      "source": [
        "df_final_uses['indexes_target_sentence_tokenized'] = df_final_uses[\"context_tokenized\"].apply(get_len_tok)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "NxwyUqX0vS2t"
      },
      "outputs": [],
      "source": [
        "lem = ''\n",
        "def lemmatizr(sent):\n",
        "  doc = nlp(sent)\n",
        "  for i in doc:\n",
        "    lem += i.lemma_\n",
        "    return lem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "Ru8yyJVexlq1"
      },
      "outputs": [],
      "source": [
        "df_final_uses['context_lemmatized'] = df_final_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.lemma_ for w in nlp(row)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "id": "hw3iFPaxBl3h"
      },
      "outputs": [],
      "source": [
        "df_final_uses[\"indice\"] = df_final_uses.groupby(\"lemma\").cumcount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "S76RLldcZ1k4"
      },
      "outputs": [],
      "source": [
        "df_final_uses['context_pos'] = df_final_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.pos_ for w in nlp(row)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "MLQGcdXCRbzU"
      },
      "outputs": [],
      "source": [
        "df_final_uses['date'] = \" \"\n",
        "df_final_uses['grouping'] = 1\n",
        "df_final_uses['description'] = \" \"\n",
        "df_final_uses['context'] = df_final_uses['context_tokenized']\n",
        "#df_final_dev_uses['identifier'] = \"\"\n",
        "df_final_uses['indexes_target_token_tokenized'] = df_final_uses['ind']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "bY7whS1WtBqT"
      },
      "outputs": [],
      "source": [
        "def get_identifier(sent, dictionar):\n",
        "  for k, v in sent_to_id.items():\n",
        "    for i in v:\n",
        "      if sent == k:\n",
        "        return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "aPgfAYTpte65"
      },
      "outputs": [],
      "source": [
        "sents = df_final_uses.context.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "SrkY9tgzt2Kd"
      },
      "outputs": [],
      "source": [
        "aggre = []\n",
        "for i in sents:\n",
        "  aggre.append(get_identifier(i, sent_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "-VNTzpM3uHLK"
      },
      "outputs": [],
      "source": [
        "df_final_uses['identifier'] = aggre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "2O9FfJ9yagcw"
      },
      "outputs": [],
      "source": [
        "final_dfs = df_final_uses[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'context_tokenized', 'indexes_target_token_tokenized', 'indexes_target_sentence_tokenized', 'context_lemmatized', 'context_pos', 'dataset']]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = final_dfs.reset_index(drop= True)"
      ],
      "metadata": {
        "id": "8_Ezo4YBRxMq"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "lYeQa_mEJxyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b629b1d1-6af6-4bfe-ba90-38bfb3be89df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'WUGs' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Garrafao/WUGs.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "wueVeCgDKKWm"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/WUGs/scripts/misc/data/dwug_en/data/*/', exist_ok=True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "ZtFEzco-JCuA"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "final_df.to_csv('/content/WUGs/scripts/misc/data/dwug_en/data/*/uses.csv', sep='\\t', encoding='utf-8', quoting = csv.QUOTE_NONE, quotechar='')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl5-d216I5dd"
      },
      "outputs": [],
      "source": [
        "%run /content/WUGs/scripts/misc/use2normalize.py /content/WUGs/scripts/misc/data/dwug_en/data/*/uses.csv dwug_en output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "Oqvk7yD_KsHN"
      },
      "outputs": [],
      "source": [
        "final_uses = pd.read_csv('/content/output', delimiter = '\\t',quoting =3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "UCY5M8-ALP_f"
      },
      "outputs": [],
      "source": [
        "final_uses['context_tokenized'] = final_df['context_tokenized']\n",
        "final_uses['pos'] = final_df['pos']\n",
        "final_uses['dataset'] = final_df['dataset']\n",
        "final_uses['grouping'] = final_df['grouping']\n",
        "final_uses['lemma'] = final_df['lemma']\n",
        "final_uses['indexes_target_token_tokenized'] = final_df['indexes_target_token_tokenized']\n",
        "final_uses['indexes_target_sentence_tokenized'] = final_df['indexes_target_sentence_tokenized']\n",
        "final_uses['date'] = \" \"\n",
        "final_uses['description'] = \" \"\n",
        "final_uses['context_lemmatized'] = final_df['context_lemmatized']\n",
        "final_uses['context_pos'] = final_df['context_pos']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "k3m86CLlMgpR"
      },
      "outputs": [],
      "source": [
        "final_uses = final_uses[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'context_tokenized', 'indexes_target_token_tokenized', 'indexes_target_sentence_tokenized', 'context_lemmatized', 'context_pos', 'dataset']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "yGZVOY-FIRyh"
      },
      "outputs": [],
      "source": [
        "for i in list(final_uses[\"dataset\"].value_counts().index):\n",
        "    df_temp = final_uses[final_uses[\"dataset\"]==i]\n",
        "    if not os.path.exists(i):\n",
        "        os.mkdir(i)\n",
        "    df_temp.to_csv(path +'/'+ i +'/uses.csv',index = False, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, quotechar = '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "9G6ip5jEJEc1"
      },
      "outputs": [],
      "source": [
        "for i in list(df_judgments[\"dataset\"].value_counts().index):\n",
        "    df_temp = df_judgments[df_judgments[\"dataset\"]==i]\n",
        "    if not os.path.exists(i):\n",
        "        os.mkdir(i)\n",
        "    df_temp.to_csv(path + '/' + i +'/judgments.csv',index = False, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, quotechar = '')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpfPAy1xkfiC3iCetCNmMW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}